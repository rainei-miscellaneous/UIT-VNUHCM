{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s9F0puZbYlso"
   },
   "source": [
    "# TASK - XÁC ĐỊNH HIỆU XE Ô TÔ TỪ ẢNH\n",
    "\n",
    "Công ty Nguyên Phong muốn phát triển một hệ thống phân loại xe ô tô từ ảnh để tổng hợp thị trường xe hơi của các hãng như Honda, Suzuki, Toyota, Mitsubishi, Mazda, Huyndai, KIA, Peugeot, Volvo, Volkswagen, LandRover, Nissan, Mercedes, VinFast\n",
    "Thành phần cốt lõi của hệ thống phân loại này là module\n",
    "- Input: ảnh chụp xe ô tô\n",
    "- Output: nhãn thuộc một trong các loại: Honda, Suzuki, Toyota, Mitsubishi, Mazda, Huyndai, KIA, Peugeot, Volvo, Volkswagen, LandRover, Nissan, Mercedes, VinFast, không có ô tô, ô tô khác\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gCvM61VHiYBH"
   },
   "source": [
    "## Ví dụ:\n",
    "- Input: <IMG SRC='https://i1-vnexpress.vnecdn.net/2023/05/10/Vios-2023-10_1683690128.jpg?w=2400&h=0&q=100&dpr=1&fit=crop&s=LPsTjgivZ2T5xKJYQiVjHg&t=image'>\n",
    "\n",
    "\n",
    "- Output: Toyota"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3rab3QbWYCk8"
   },
   "source": [
    "## Dữ liệu\n",
    "Mỗi SV/nhóm SV thu thập dữ liệu theo yêu cầu sau:\n",
    "- Đặt tên thư mục theo cấu trúc\n",
    "    + Honda (các ảnh của xe ô tô hiệu Honda)\n",
    "    + Mazda\n",
    "    + Mitsubishi\n",
    "    + Suzuki\n",
    "    + Toyota\n",
    "    + Hyundai\n",
    "    + KIA\n",
    "    + VinFast\n",
    "    + Others (các ảnh của xe ô tô loại khác)\n",
    "- Mỗi SV cần thu thập trung bình 10 ảnh khác nhau/loại, thu thập từ Internet (Google Images Search, Bing Images Search, tự chụp thực tế)\n",
    "- Tên ảnh đặt theo quy ước: <DS MSSV cách nhau bằng ->.<Tên hiệu xe>.<Số TT ảnh>\n",
    "    + 20221234-20222345.Honda.1\n",
    "- Độ đa dạng (variations)\n",
    "    + Góc nhìn: đầu xe hướng về trái, về phải, về trước, về sau\n",
    "    + Có người ngồi, hoặc không có người ngồi\n",
    "    + Màu sắc\n",
    "    + Chủng loại - ví dụ Toyota Vios, Toyota Innova, Toyota Corolla Cross\n",
    "- Thư mục upload: https://drive.google.com/drive/u/1/folders/1Uj0V9URNHpzSHeXHSB89AoGCjGki8Yra\n",
    "- Deadline ??/??/2024\n",
    "- Các nhóm sẽ được cung cấp các tập tin gồm:\n",
    "    + train.txt - danh sách các ảnh dùng cho trainining\n",
    "    + test.txt - danh sách các ảnh dùng cho testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RXru9YZ1i4Ed"
   },
   "source": [
    "## Code\n",
    "\n",
    "- Các nhóm sẽ được cung cấp notebook về khung của chương trình trong đó có các chức năng gồm\n",
    "    + train: đọc thông tin từ file train.txt và thực hiện training để output ra model.\n",
    "    + test: đọc thông tin từ file test.txt và thực hiện prediction bằng cách load model lên và output ra category/label thương ứng.\n",
    "- Hệ thống sẽ tự động tính performance và hiển thị lên ScoreBoard\n",
    "- Thư mục để cập nhật code: sẽ thông báo sau\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "piixfWKfi9Mt"
   },
   "source": [
    "## ScoreBoard\n",
    "\n",
    "- Tiếp tục cập nhật"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "45ljoKrfbgb_"
   },
   "source": [
    "## Thảo luận\n",
    "\n",
    "- Các SV tham gia nhóm Zalo của lớp CS114.P11 để có thông tin cập nhật"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Thông tin của tác giả, ngày cập nhật**\n",
    "\n",
    "<hr>\n",
    "\n",
    "**Thành viên nhóm**:\n",
    "- **Trần Đình Khánh Đăng - 22520195**\n",
    "- **Tăng Nhất - 22521027**\n",
    "- **Lê Minh Nhựt - 22521060**\n",
    "\n",
    "**Ngày cập nhật**: 22/01/2025"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **PHẦN THỰC NGHIỆM**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Install và Import thư viện cần thiết**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-22T02:42:51.620775Z",
     "iopub.status.busy": "2025-01-22T02:42:51.620454Z",
     "iopub.status.idle": "2025-01-22T02:42:56.135260Z",
     "shell.execute_reply": "2025-01-22T02:42:56.134148Z",
     "shell.execute_reply.started": "2025-01-22T02:42:51.620746Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install \\\n",
    "    --extra-index-url=https://pypi.nvidia.com \\\n",
    "    \"cudf-cu12==24.12.*\" \"dask-cudf-cu12==24.12.*\" \"cuml-cu12==24.12.*\" \\\n",
    "    \"cugraph-cu12==24.12.*\" \"nx-cugraph-cu12==24.12.*\" \"cuspatial-cu12==24.12.*\" \\\n",
    "    \"cuproj-cu12==24.12.*\" \"cuxfilter-cu12==24.12.*\" \"cucim-cu12==24.12.*\" \\\n",
    "    \"pylibraft-cu12==24.12.*\" \"raft-dask-cu12==24.12.*\" \"cuvs-cu12==24.12.*\" \\\n",
    "    \"nx-cugraph-cu12==24.12.*\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-22T02:42:56.136896Z",
     "iopub.status.busy": "2025-01-22T02:42:56.136620Z",
     "iopub.status.idle": "2025-01-22T02:42:56.145395Z",
     "shell.execute_reply": "2025-01-22T02:42:56.144658Z",
     "shell.execute_reply.started": "2025-01-22T02:42:56.136874Z"
    },
    "id": "k0wPXy88MZ_V",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import re\n",
    "import cv2\n",
    "import sys\n",
    "import csv\n",
    "import time\n",
    "import math\n",
    "import random\n",
    "import warnings\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import patches\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "\n",
    "from cuml.svm import SVC as cuSVC\n",
    "from cuml.ensemble import RandomForestClassifier as cuRFClassifier\n",
    "from cuml.neighbors import KNeighborsClassifier as cuKNNClassifier\n",
    "\n",
    "from skimage.io import imread\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "\n",
    "from PIL import Image\n",
    "from imagehash import phash\n",
    "from scipy.spatial.distance import cdist, euclidean\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.cluster import (KMeans, DBSCAN, AgglomerativeClustering, \n",
    "                             MeanShift, Birch, SpectralClustering)\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import learning_curve\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.utils import save_image\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from tensorflow.keras.applications import (MobileNet, MobileNetV2, MobileNetV3Small, MobileNetV3Large, \n",
    "                                           ResNet50, ResNet101, ResNet152,\n",
    "                                           VGG16, VGG19,\n",
    "                                           EfficientNetB0, EfficientNetB1, EfficientNetB7,\n",
    "                                           InceptionV3, Xception)\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.mobilenet import preprocess_input\n",
    "\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Khởi tạo đường dẫn**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-22T02:48:14.327630Z",
     "iopub.status.busy": "2025-01-22T02:48:14.327329Z",
     "iopub.status.idle": "2025-01-22T02:48:14.334168Z",
     "shell.execute_reply": "2025-01-22T02:48:14.333187Z",
     "shell.execute_reply.started": "2025-01-22T02:48:14.327606Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "dataset_dir = '/kaggle/working/dataset'\n",
    "\n",
    "cropped_file_name = 'cropped_dataset.csv'\n",
    "cropped_dropdup_file_name = 'dropdup_dataset.csv'\n",
    "\n",
    "categories = ['Others', 'Honda', 'Hyundai', 'KIA', 'Mazda', 'Mitsubishi', 'Suzuki', 'Toyota', 'VinFast']\n",
    "\n",
    "base_dir = '/kaggle/input/cs114-final-project-full-dataset'\n",
    "dataset_name = 'CarDataset.csv'\n",
    "file_name_cars = 'CarDataset-1.csv'\n",
    "file_name_categories = 'CarDataset-2.csv'\n",
    "extracted_features_file_name='extracted_features.npz'\n",
    "\n",
    "cropped_base_dir= '/kaggle/input/cs114-cropped-full-dataset/dataset'\n",
    "cropped_dataset_name = 'cropped_CarDataset.csv'\n",
    "cropped_file_name_cars = 'cropped_CarDataset-1.csv'\n",
    "cropped_file_name_categories = 'cropped_CarDataset-2.csv'\n",
    "cropped_extracted_features_file_name='cropped_extracted_features.npz'\n",
    "\n",
    "cropped_dropdup_base_dir = '/kaggle/input/cs114-cropped-full-dataset/dataset'\n",
    "cropped_dropdup_dataset_name = 'cropped_dropdup_CarDataset.csv'\n",
    "cropped_dropdup_file_name_cars = 'cropped_dropdup_CarDataset-1.csv'\n",
    "cropped_dropdup_file_name_categories = 'cropped_dropdup_CarDataset-2.csv'\n",
    "cropped_dropdup_extracted_features_file_name='dropdup_extracted_features.npz'\n",
    "cropped_dropdup_extracted_features_csv = 'dropdup_extracted_features.csv'\n",
    "\n",
    "augmented_base_dir='/kaggle/input/cs114-augmented-dataset/augmented_images'\n",
    "augmented_dataset_name = 'augmented_CarDataset.csv'\n",
    "augmented_file_name_cars = 'augmented_CarDataset-1.csv'\n",
    "augmented_file_name_categories = 'augmented_CarDataset-2.csv'\n",
    "augmented_extracted_features_file_name='augmented_extracted_features.npz'\n",
    "\n",
    "full_augmented_base_dir='/kaggle/input/cs114-full-augmented-dataset/full_augmented_dataset'\n",
    "full_augmented_dataset_name = 'full_augmented_CarDataset.csv'\n",
    "full_augmented_file_name_cars = 'full_augmented_CarDataset-1.csv'\n",
    "full_augmented_file_name_categories = 'full_augmented_CarDataset-2.csv'\n",
    "full_augmented_extracted_features_file_name='full_augmented_extracted_features.npz'\n",
    "\n",
    "def get_indexing(categories):\n",
    "    indexing = {category: idx for idx, category in enumerate(categories)}\n",
    "    invert_indexing = {idx: category for category, idx in indexing.items()}\n",
    "    return indexing, invert_indexing\n",
    "\n",
    "indexing, invert_indexing = get_indexing(categories)\n",
    "\n",
    "num_splits = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-22T02:42:56.168981Z",
     "iopub.status.busy": "2025-01-22T02:42:56.168718Z",
     "iopub.status.idle": "2025-01-22T02:42:56.185632Z",
     "shell.execute_reply": "2025-01-22T02:42:56.184909Z",
     "shell.execute_reply.started": "2025-01-22T02:42:56.168961Z"
    },
    "id": "rPohUgy9MxUg",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def create_dataframe(data, sort=False, sort_value=None) -> pd.DataFrame:\n",
    "    \n",
    "    df = pd.DataFrame(data)\n",
    "    if sort and sort_value:\n",
    "        df = df.sort_values(by=sort_value, ascending=False).reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "def get_image_count(base_dir='./',\n",
    "                   categories=['Others', 'Honda', 'Hyundai', 'KIA', 'Mazda', 'Mitsubishi', 'Suzuki', 'Toyota', 'VinFast'],\n",
    "                   take_average=False,\n",
    "                   ) -> defaultdict:\n",
    "    \n",
    "    # Tạo biến tạm để lưu số lượng ảnh theo MSSV\n",
    "    image_count = defaultdict(lambda: defaultdict(float))  # Có tình trạng có MSSV không đóng góp ảnh (?)\n",
    "\n",
    "    student_ids_pattern = r'(\\d{8}(?:-\\d{8})*)' # Lấy MSSV hợp lệ (đủ 8 số)\n",
    "    categories_pattern = '|'.join(categories) # Lấy hiệu xe hợp lệ\n",
    "    file_extension_pattern = r'\\.\\d+\\.(jpg|jpeg|png)$' # Lấy extension hợp lệ (chỉ chấp nhận file .jpg, .jpeg và .png)\n",
    "    # Regex lấy tên file hợp lệ\n",
    "    accepted_filename = re.compile(fr'{student_ids_pattern}\\.({categories_pattern}){file_extension_pattern}')\n",
    "\n",
    "    # accepted_filename_2 = re.compile(fr'(\\d{{8}}(?:-\\d{{8}})*)\\.({categories_pattern})\\.\\d+\\.(jpg|jpeg|png)$')\n",
    "    for category in tqdm(categories, desc=\"Processing categories\"): # Duyệt qua các hiệu xe\n",
    "        category_path = os.path.join(base_dir, category)\n",
    "        if os.path.isdir(category_path): # Kiểm tra nếu thư mục tồn tại\n",
    "            for filename in os.listdir(category_path):\n",
    "                match = accepted_filename.match(filename)\n",
    "                if match: # Chỉ xử lý file có tên hợp lệ\n",
    "                    student_ids, car_category, img_idx = match.groups()\n",
    "                    student_ids_list = student_ids.split('-')\n",
    "                    num_members = len(student_ids_list)\n",
    "                    # Đếm ảnh theo MSSV\n",
    "                    for student_id in student_ids_list:\n",
    "                        image_count[student_id][car_category] += 1 / num_members if take_average else 1\n",
    "\n",
    "    return image_count\n",
    "\n",
    "def write_csv(base_dir='./',\n",
    "              dataset_dir='./',\n",
    "              categories=['Honda', 'Hyundai', 'KIA', 'Mazda', 'Mitsubishi', 'Others', 'Suzuki', 'Toyota', 'VinFast'],\n",
    "              file_name_cars='CarDataset-1.csv',\n",
    "              file_name_categories='CarDataset-2.csv',\n",
    "              save_csv=False,\n",
    "              take_average=False,\n",
    "              sort=False\n",
    "              ) -> tuple:\n",
    "    \n",
    "    os.makedirs(dataset_dir, exist_ok=True) # Tạo thư mục đầu ra nếu chưa tồn tại\n",
    "    image_count = get_image_count(base_dir=base_dir, categories=categories, take_average=take_average) # Lấy số lượng ảnh theo MSSV và loại xe\n",
    "    cars_list = [] # Danh sách tổng số lượng ảnh của mỗi MSSV\n",
    "    categories_list = [] # Danh sách số lượng ảnh theo hiệu xe của mỗi MSSV\n",
    "\n",
    "    for student_id, car_data in image_count.items():\n",
    "        total_images = 0\n",
    "        for car_category, count in car_data.items():\n",
    "            total_images += count\n",
    "            categories_list.append({'MSSV': student_id, 'Hiệu xe': car_category, 'Số lượng': round(count, 2)})\n",
    "        cars_list.append({'MSSV': student_id, 'All': 'All', 'Số lượng': round(total_images, 2)})\n",
    "\n",
    "    # Chuyển danh sách thành DataFrame\n",
    "    df_cars = create_dataframe(cars_list, sort=sort, sort_value='Số lượng')\n",
    "    df_categories = create_dataframe(categories_list, sort=sort, sort_value='Số lượng')\n",
    "\n",
    "    # Lấy đường dẫn file CSV\n",
    "    file_path_categories = os.path.join(dataset_dir, file_name_categories)\n",
    "    file_path_cars = os.path.join(dataset_dir, file_name_cars)\n",
    "\n",
    "    # Lưu CSV nếu cần\n",
    "    if save_csv:\n",
    "        df_categories.to_csv(file_path_categories, index=False)\n",
    "        df_cars.to_csv(file_path_cars, index=False)\n",
    "\n",
    "        print(f'{file_name_cars} saved to: {file_path_cars}')\n",
    "        print(f'{file_name_categories} saved to: {file_path_categories}')\n",
    "\n",
    "    return df_cars, df_categories\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-22T02:42:56.186513Z",
     "iopub.status.busy": "2025-01-22T02:42:56.186327Z",
     "iopub.status.idle": "2025-01-22T02:42:58.334593Z",
     "shell.execute_reply": "2025-01-22T02:42:58.333472Z",
     "shell.execute_reply.started": "2025-01-22T02:42:56.186497Z"
    },
    "id": "kRGFf5-vMyUD",
    "outputId": "334e5fc8-20c8-4ebc-c7ed-4842ba926343",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df_cars, df_categories = write_csv(base_dir=base_dir,\n",
    "                                   dataset_dir=dataset_dir,\n",
    "                                   categories=categories,\n",
    "                                   file_name_cars=file_name_cars,\n",
    "                                   file_name_categories=file_name_categories,\n",
    "                                   save_csv=True,\n",
    "                                   take_average=False,\n",
    "                                   sort=True)\n",
    "print(f'{file_name_cars}:\\n{df_cars}')\n",
    "print(f'{file_name_categories}:\\n{df_categories}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize dữ liệu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-22T02:42:58.335950Z",
     "iopub.status.busy": "2025-01-22T02:42:58.335656Z",
     "iopub.status.idle": "2025-01-22T02:42:58.347679Z",
     "shell.execute_reply": "2025-01-22T02:42:58.346821Z",
     "shell.execute_reply.started": "2025-01-22T02:42:58.335918Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Nhóm dữ liệu theo 'Hiệu xe' và tính tổng 'Số lượng'\n",
    "brand_summary = df_categories.groupby('Hiệu xe')['Số lượng'].sum().reset_index()\n",
    "\n",
    "# Sắp xếp theo số lượng giảm dần để dễ quan sát\n",
    "brand_summary = brand_summary.sort_values('Số lượng', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-22T02:42:58.348625Z",
     "iopub.status.busy": "2025-01-22T02:42:58.348361Z",
     "iopub.status.idle": "2025-01-22T02:42:58.917316Z",
     "shell.execute_reply": "2025-01-22T02:42:58.916409Z",
     "shell.execute_reply.started": "2025-01-22T02:42:58.348604Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Thiết lập style cho biểu đồ\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "# Tạo histogram\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(df_cars['Số lượng'], bins=30, kde=True)\n",
    "plt.title('Phân phối tổng số lượng xe đóng góp theo sinh viên')\n",
    "plt.xlabel('Tổng số lượng xe')\n",
    "plt.ylabel('Số lượng sinh viên')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-22T02:42:58.919849Z",
     "iopub.status.busy": "2025-01-22T02:42:58.919613Z",
     "iopub.status.idle": "2025-01-22T02:42:59.222882Z",
     "shell.execute_reply": "2025-01-22T02:42:59.222179Z",
     "shell.execute_reply.started": "2025-01-22T02:42:58.919829Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "brand_summary.sort_values('Số lượng', ascending=True, inplace=True)\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(x='Hiệu xe', y='Số lượng', data=brand_summary)\n",
    "plt.title('Tổng số lượng xe theo hiệu xe')\n",
    "plt.xlabel('Hiệu xe')\n",
    "plt.ylabel('Tổng số lượng xe')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-22T02:42:59.224624Z",
     "iopub.status.busy": "2025-01-22T02:42:59.224410Z",
     "iopub.status.idle": "2025-01-22T02:42:59.441532Z",
     "shell.execute_reply": "2025-01-22T02:42:59.440083Z",
     "shell.execute_reply.started": "2025-01-22T02:42:59.224605Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "colors = sns.color_palette('pastel')[0:len(brand_summary)]\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.pie(brand_summary['Số lượng'], labels=brand_summary['Hiệu xe'], autopct='%1.1f%%', startangle=140, colors=colors)\n",
    "plt.title('Tỷ lệ phần trăm số lượng xe theo hiệu xe')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-22T02:42:59.443484Z",
     "iopub.status.busy": "2025-01-22T02:42:59.442992Z",
     "iopub.status.idle": "2025-01-22T02:42:59.459188Z",
     "shell.execute_reply": "2025-01-22T02:42:59.458171Z",
     "shell.execute_reply.started": "2025-01-22T02:42:59.443439Z"
    },
    "id": "z3wpwa_MQOxG",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def get_dataset(base_dir='./',\n",
    "                dataset_dir='/',\n",
    "                categories=['Others', 'Honda', 'Hyundai', 'KIA', 'Mazda', 'Mitsubishi', 'Suzuki', 'Toyota', 'VinFast'],\n",
    "                save_csv=False,\n",
    "                file_name='CarDataset.csv',\n",
    "                ) -> pd.DataFrame:\n",
    "    \n",
    "    os.makedirs(dataset_dir, exist_ok=True)  # Tạo thư mục đầu ra nếu chưa tồn tại\n",
    "\n",
    "    path_list = []  # Lưu đường dẫn đầy đủ của hình ảnh\n",
    "    categoryid_list = []  # Lưu mã danh mục tương ứng với từng hình ảnh\n",
    "\n",
    "\n",
    "    student_ids_pattern = r'(\\d{8}(?:-\\d{8})*)' # Lấy MSSV hợp lệ (đủ 8 số)\n",
    "    categories_pattern = '|'.join(categories) # Lấy hiệu xe hợp lệ\n",
    "    file_extension_pattern = r'\\.\\d+\\.(jpg|jpeg|png)$' # Lấy extension hợp lệ (chỉ chấp nhận file .jpg, .jpeg và .png)\n",
    "    # Regex lấy tên file hợp lệ\n",
    "    accepted_filename = re.compile(fr'{student_ids_pattern}\\.({categories_pattern}){file_extension_pattern}')\n",
    "\n",
    "    for category in tqdm(categories, desc=\"Processing categories\"): # Duyệt qua các hiệu xe\n",
    "        category_path = os.path.join(base_dir, category)\n",
    "        if os.path.isdir(category_path): # Kiểm tra nếu thư mục tồn tại\n",
    "            for filename in os.listdir(category_path):\n",
    "                match = accepted_filename.match(filename)\n",
    "                if match: # Chỉ xử lý file có tên hợp lệ\n",
    "                    _, car_category, _ = match.groups()\n",
    "                    if car_category in categories:\n",
    "                        full_path = os.path.join(car_category, filename)\n",
    "                        path_list.append(full_path)\n",
    "                        categoryid_list.append(indexing[car_category])\n",
    "    # Tạo DataFrame từ danh sách đường dẫn và mã hiệu xe\n",
    "    df = pd.DataFrame({\n",
    "        'ImageFullPath': path_list,\n",
    "        'CategoryID': categoryid_list\n",
    "    })\n",
    "\n",
    "    # Lưu CSV nếu cần\n",
    "    if save_csv:\n",
    "        output_file = os.path.join(dataset_dir, file_name)\n",
    "        df.to_csv(output_file, index=False)\n",
    "        print(f\"{file_name} saved to {output_file}\")\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-22T02:42:59.460306Z",
     "iopub.status.busy": "2025-01-22T02:42:59.459958Z",
     "iopub.status.idle": "2025-01-22T02:42:59.474742Z",
     "shell.execute_reply": "2025-01-22T02:42:59.473919Z",
     "shell.execute_reply.started": "2025-01-22T02:42:59.460273Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df = get_dataset(base_dir=base_dir,\n",
    "                 dataset_dir=dataset_dir,\n",
    "                 categories=categories,\n",
    "                 save_csv=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "71BZw3Sok3_X"
   },
   "source": [
    "# Bước 1: Dùng object detection để crop ảnh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-22T02:42:59.475830Z",
     "iopub.status.busy": "2025-01-22T02:42:59.475546Z",
     "iopub.status.idle": "2025-01-22T02:43:08.888521Z",
     "shell.execute_reply": "2025-01-22T02:43:08.887851Z",
     "shell.execute_reply.started": "2025-01-22T02:42:59.475809Z"
    },
    "id": "WCTFKaIYkukc",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model_url = \"https://tfhub.dev/tensorflow/faster_rcnn/resnet50_v1_640x640/1\"\n",
    "detector = hub.load(model_url)\n",
    "\n",
    "def save_cropped_image(cropped_image, original_image_path, dataset_dir='./'):\n",
    "    base_dir, img_name = os.path.split(original_image_path)\n",
    "    class_name = os.path.basename(os.path.dirname(original_image_path))\n",
    "    new_dir = os.path.join(dataset_dir, class_name)\n",
    "    os.makedirs(new_dir, exist_ok=True)\n",
    "    cropped_image_path = os.path.join(new_dir, img_name)\n",
    "    cv2.imwrite(cropped_image_path, cv2.cvtColor(cropped_image, cv2.COLOR_RGB2BGR))\n",
    "    return cropped_image_path\n",
    "\n",
    "def load_and_preprocess_image(base_dir, image_path, max_image_size):\n",
    "    image_path = os.path.join(base_dir, image_path)\n",
    "    img = cv2.imread(image_path)\n",
    "    if img is None:\n",
    "        print(f\"Cannot load image from {image_path}\")\n",
    "        return None, None\n",
    "    \n",
    "    if max_image_size is not None:\n",
    "        img = cv2.resize(img, max_image_size)\n",
    "    \n",
    "    original_img = img.copy()\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    return img, original_img\n",
    "\n",
    "def detect_car(image, detector, score_threshold=0.5):\n",
    "    input_tensor = tf.convert_to_tensor(image)\n",
    "    input_tensor = tf.expand_dims(input_tensor, axis=0)\n",
    "    detections = detector.signatures['serving_default'](input_tensor)\n",
    "\n",
    "    boxes = detections['detection_boxes'].numpy()[0]\n",
    "    class_ids = detections['detection_classes'].numpy()[0].astype(np.int64)\n",
    "    scores = detections['detection_scores'].numpy()[0]\n",
    "\n",
    "    return {\"boxes\": boxes, \"class_ids\": class_ids, \"scores\": scores}\n",
    "\n",
    "def process_chunk(data_chunk, base_dir, dataset_dir, detector, class_index, score_threshold, save_images, none_list_file, max_image_size):\n",
    "    batch_results = []\n",
    "    for idx, row in tqdm(data_chunk.iterrows(), total=data_chunk.shape[0]):\n",
    "        image_path = row['ImageFullPath']\n",
    "        image_np, original_image = load_and_preprocess_image(base_dir, image_path, max_image_size)\n",
    "\n",
    "        if image_np is None:\n",
    "            batch_results.append((image_path, None, None, None))\n",
    "            continue\n",
    "\n",
    "        detection_results = detect_car(image_np, detector, score_threshold)\n",
    "\n",
    "        boxes = detection_results[\"boxes\"]\n",
    "        class_ids = detection_results[\"class_ids\"]\n",
    "        scores = detection_results[\"scores\"]\n",
    "\n",
    "        img_h, img_w, _ = original_image.shape\n",
    "\n",
    "        max_area = 0\n",
    "        prioritized_box = None\n",
    "        best_score = 0\n",
    "\n",
    "        for box, score, label in zip(boxes, scores, class_ids):\n",
    "            if score < score_threshold or label != class_index:\n",
    "                continue\n",
    "            ymin, xmin, ymax, xmax = box\n",
    "            area = (xmax - xmin) * (ymax - ymin)\n",
    "\n",
    "            if area > max_area:\n",
    "                max_area = area\n",
    "                prioritized_box = (xmin, ymin, xmax, ymax)\n",
    "                best_score = score\n",
    "\n",
    "        cropped_image_path = None\n",
    "        prioritized_box_pixels = None\n",
    "\n",
    "        if prioritized_box is not None:\n",
    "            xmin, ymin, xmax, ymax = prioritized_box\n",
    "            left = int(xmin * img_w)\n",
    "            right = int(xmax * img_w)\n",
    "            top = int(ymin * img_h)\n",
    "            bottom = int(ymax * img_h)\n",
    "\n",
    "            cropped_image = original_image[top:bottom, left:right]\n",
    "            if save_images:\n",
    "                cropped_image_path = save_cropped_image(cropped_image, image_path, dataset_dir)\n",
    "            prioritized_box_pixels = (left, right, top, bottom)\n",
    "        else:\n",
    "            if save_images:\n",
    "                cropped_image = original_image \n",
    "                cropped_image_path = save_cropped_image(cropped_image, image_path, dataset_dir)\n",
    "            with open(os.path.join(dataset_dir, none_list_file), 'a') as f:\n",
    "                f.write(f\"{image_path}, No_Car_Detected\\n\")\n",
    "\n",
    "        batch_results.append((image_path, cropped_image_path, prioritized_box_pixels, best_score))\n",
    "\n",
    "    return batch_results\n",
    "\n",
    "def process_car_detection(base_dir='./',\n",
    "                          dataset_dir='./',\n",
    "                          data=None,\n",
    "                          file_name='CarDataset.csv',\n",
    "                          detector=None,\n",
    "                          partition=False,\n",
    "                          partition_size=1000,\n",
    "                          batch_size=10,\n",
    "                          chunk_size=100,  # Chunk size for reading CSV\n",
    "                          class_index=3,\n",
    "                          score_threshold=0.5,\n",
    "                          save_images=True,\n",
    "                          none_list_file='NoneList.csv',\n",
    "                          max_image_size=(640, 640)\n",
    "                          ):\n",
    "    data_path = os.path.join(dataset_dir, file_name)\n",
    "    results_list = []\n",
    "\n",
    "    total_rows = sum(1 for row in open(data_path)) -1 \n",
    "    num_chunks = math.ceil(total_rows / chunk_size)\n",
    "\n",
    "    print(f\"Total number of chunks: {num_chunks}\")\n",
    "\n",
    "    chunk_num = 0 \n",
    "    for chunk in pd.read_csv(data_path, chunksize=chunk_size):\n",
    "        chunk_num += 1\n",
    "        print(f\"Processing chunk {chunk_num} out of {num_chunks} (Size: {len(chunk)} rows)\")\n",
    "\n",
    "        if partition:\n",
    "            chunk = chunk.sample(n=min(partition_size, len(chunk)), random_state=42).reset_index(drop=True)\n",
    "            print(f\"  - Processing {len(chunk)} images after partitioning...\")\n",
    "\n",
    "        total_batches = math.ceil(len(chunk) / batch_size)\n",
    "        print(f\"  - Total batches in this chunk: {total_batches}\")\n",
    "\n",
    "        for i in range(0, len(chunk), batch_size):\n",
    "            batch_data = chunk[i:i + batch_size]\n",
    "            batch_results = process_chunk(batch_data, base_dir, dataset_dir, detector, class_index, score_threshold, save_images, none_list_file, max_image_size)\n",
    "            results_list.extend(batch_results)\n",
    "\n",
    "            del batch_data\n",
    "            del batch_results\n",
    "            gc.collect()\n",
    "\n",
    "    return results_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-22T02:43:08.889609Z",
     "iopub.status.busy": "2025-01-22T02:43:08.889353Z",
     "iopub.status.idle": "2025-01-22T02:43:08.892822Z",
     "shell.execute_reply": "2025-01-22T02:43:08.892073Z",
     "shell.execute_reply.started": "2025-01-22T02:43:08.889587Z"
    },
    "id": "fmNCbjKV250b",
    "outputId": "6b68bd01-b517-410f-b9ea-6cfbfcd248c1",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "results_list = process_car_detection(base_dir=base_dir,\n",
    "                                     dataset_dir=dataset_dir,\n",
    "                                     data=df,\n",
    "                                     detector=detector,\n",
    "                                     batch_size = 128,\n",
    "                                     chunk_size = 1024,\n",
    "                                     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Visualize Kết quả**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-22T02:43:08.893844Z",
     "iopub.status.busy": "2025-01-22T02:43:08.893606Z",
     "iopub.status.idle": "2025-01-22T02:43:08.908782Z",
     "shell.execute_reply": "2025-01-22T02:43:08.908141Z",
     "shell.execute_reply.started": "2025-01-22T02:43:08.893810Z"
    },
    "id": "L_FINhcq4Z-o",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def visualize_results(results_list,\n",
    "                      data=None,\n",
    "                      base_dir='./',\n",
    "                      dataset_dir='./',\n",
    "                      file_name='CarDataset.csv',\n",
    "                      partition=False,\n",
    "                      partition_size=10,\n",
    "                      ):\n",
    "    \n",
    "    if data is None:\n",
    "        data_path = os.path.join(dataset_dir, file_name)\n",
    "        data = pd.read_csv(data_path)\n",
    "    if partition:\n",
    "        start_index = (partition - 1) * partition_size\n",
    "        end_index = min(start_index + partition_size, len(results_list))\n",
    "        results_list = results_list[start_index:end_index]\n",
    "\n",
    "    for i, (image_path, cropped_image_path, bbox, score) in tqdm(enumerate(results_list), total=len(results_list), desc=\"Processing images: \"):\n",
    "        image_path = os.path.join(base_dir, image_path)\n",
    "        try:\n",
    "            original_image = cv2.imread(image_path)\n",
    "            original_image = cv2.resize(original_image, (640, 640))\n",
    "            original_image = cv2.cvtColor(original_image, cv2.COLOR_BGR2RGB)\n",
    "            if original_image is None:\n",
    "                print(f\"Warning: Could not load image at {image_path}. Skipping.\")\n",
    "                continue\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading image {image_path}: {e}\")\n",
    "            continue\n",
    "\n",
    "        fig, ax = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "        # Turn off the grid for both subplots\n",
    "        ax[0].grid(False)\n",
    "        ax[1].grid(False)\n",
    "\n",
    "        ax[0].imshow(original_image)\n",
    "        ax[0].set_title(f\"Original Image: {os.path.basename(image_path)}\")\n",
    "\n",
    "        if bbox:\n",
    "            left, right, top, bottom = bbox\n",
    "            rect = patches.Rectangle((left, top), right - left, bottom - top,\n",
    "                                     linewidth=2, edgecolor='r', facecolor='none')\n",
    "            ax[0].add_patch(rect)\n",
    "            ax[0].text(left, top - 5, f\"Car (Score: {score:.2f})\", color='red', fontsize=10)\n",
    "\n",
    "        if cropped_image_path is not None:\n",
    "            cropped_image = cv2.imread(cropped_image_path)\n",
    "            ax[1].imshow(cropped_image)\n",
    "            ax[1].set_title(\"Cropped Car\")\n",
    "        else:\n",
    "            ax[1].set_title(\"No Car Detected Above Threshold\")\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-22T02:43:08.909573Z",
     "iopub.status.busy": "2025-01-22T02:43:08.909389Z",
     "iopub.status.idle": "2025-01-22T02:43:08.922788Z",
     "shell.execute_reply": "2025-01-22T02:43:08.922152Z",
     "shell.execute_reply.started": "2025-01-22T02:43:08.909556Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "visualize_results(base_dir=base_dir,\n",
    "                  dataset_dir = dataset_dir,\n",
    "                    results_list = results_list,\n",
    "                    data=df,\n",
    "                    partition=True,\n",
    "                    partition_size=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vve-dmfARfCm"
   },
   "source": [
    "# Bước 2: Loại bỏ ảnh trùng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-22T02:43:08.923811Z",
     "iopub.status.busy": "2025-01-22T02:43:08.923564Z",
     "iopub.status.idle": "2025-01-22T02:43:08.936272Z",
     "shell.execute_reply": "2025-01-22T02:43:08.935356Z",
     "shell.execute_reply.started": "2025-01-22T02:43:08.923779Z"
    },
    "id": "5aI3laRQRknP",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def extract_feature_one_img(image_path, model, input_shape=(224, 224)):\n",
    "    img = image.load_img(image_path, target_size=input_shape)\n",
    "    if img.mode != 'RGB':\n",
    "        img = img.convert('RGB')\n",
    "    x = image.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    x = preprocess_input(x)\n",
    "    features = model.predict(x, verbose=0)\n",
    "    return features.flatten()\n",
    "\n",
    "def extract_features(data=None,\n",
    "                     base_dir='./',\n",
    "                     dataset_dir='./',\n",
    "                     file_csv='CarDataset-Splits-1-Train.csv',\n",
    "                     model_name='MobileNet',\n",
    "                     input_shape=(224, 224),\n",
    "                     partition=False,\n",
    "                     partition_size=1000,\n",
    "                     random_state=42,\n",
    "                     save_result=False,\n",
    "                     save_name='extracted_features-Splits-1.npz'):\n",
    "    models = {\n",
    "        'MobileNet': MobileNet,\n",
    "        'MobileNetV2': MobileNetV2,\n",
    "        'MobileNetV3Small': MobileNetV3Small,\n",
    "        'MobileNetV3Large': MobileNetV3Large,\n",
    "        'ResNet50': ResNet50,\n",
    "        'ResNet101': ResNet101,\n",
    "        'ResNet152': ResNet152,\n",
    "        'VGG16': VGG16,\n",
    "        'VGG19': VGG19,\n",
    "        'EfficientNetB0': EfficientNetB0,\n",
    "        'EfficientNetB1': EfficientNetB1,\n",
    "        'EfficientNetB7': EfficientNetB7,\n",
    "        'InceptionV3': InceptionV3,\n",
    "        'Xception': Xception\n",
    "    }\n",
    "\n",
    "    if model_name not in models:\n",
    "        model_name = 'MobileNet'\n",
    "\n",
    "    device = '/device:GPU:0' if tf.config.list_physical_devices('GPU') else '/device:CPU:0'\n",
    "    with tf.device(device):\n",
    "        model = models[model_name](weights='imagenet', include_top=False, pooling='avg')\n",
    "\n",
    "    if data is None:\n",
    "        data = pd.read_csv(os.path.join(dataset_dir, file_csv))\n",
    "\n",
    "    if partition:\n",
    "        sampled_data = data.sample(n=min(partition_size, len(data)), random_state=random_state).reset_index(drop=True)\n",
    "        print(f\"Processing {len(sampled_data)} images out of {len(data)} available.\")\n",
    "    else:\n",
    "        sampled_data = data\n",
    "    print(\"Extracting features...\")\n",
    "\n",
    "    result = []\n",
    "    for _, row in tqdm(sampled_data.iterrows(), desc=\"Extracting Features\", total=len(sampled_data), file=sys.stdout, leave=True):\n",
    "        image_path = row[\"ImageFullPath\"]\n",
    "        categoryid = row[\"CategoryID\"]\n",
    "\n",
    "        full_path = os.path.join(base_dir, image_path)\n",
    "        try:\n",
    "            extracted_features = extract_feature_one_img(full_path, model, input_shape=input_shape)\n",
    "            result.append({'ImageFullPath': image_path, 'CategoryID': categoryid, 'Extracted Features': extracted_features})\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing image {full_path}: {e}. Skipping...\")\n",
    "\n",
    "    print(f\"Successfully processed {len(result)} images\")\n",
    "\n",
    "    if save_result:\n",
    "        save_path = os.path.join(dataset_dir, save_name)\n",
    "        np.savez(save_path, extracted_features=result)\n",
    "        print(f\"Extracted features saved to {save_path}\")\n",
    "\n",
    "    return result\n",
    "\n",
    "def load_features(file_path):\n",
    "    try:\n",
    "        # Tải file .npz và lấy dữ liệu 'extracted_features'\n",
    "        data = np.load(file_path, allow_pickle=True)\n",
    "        extracted_features = data['extracted_features']\n",
    "\n",
    "        # Đảm bảo định dạng giống như khi lưu\n",
    "        formatted_features = []\n",
    "        for item in extracted_features:\n",
    "            # Chuyển từng phần tử từ ndarray về dictionary với đúng format\n",
    "            formatted_features.append({\n",
    "                'ImageFullPath': item['ImageFullPath'],\n",
    "                'CategoryID': item['CategoryID'],\n",
    "                'Extracted Features': item['Extracted Features']\n",
    "            })\n",
    "\n",
    "        print(f\"Loaded extracted features from {file_path}\")\n",
    "        return formatted_features\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading features from {file_path}: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-22T02:43:08.937288Z",
     "iopub.status.busy": "2025-01-22T02:43:08.937037Z",
     "iopub.status.idle": "2025-01-22T02:43:08.950067Z",
     "shell.execute_reply": "2025-01-22T02:43:08.949438Z",
     "shell.execute_reply.started": "2025-01-22T02:43:08.937268Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df_cropped = get_dataset(base_dir=cropped_base_dir,\n",
    "                         dataset_dir=dataset_dir,\n",
    "                         categories=categories,\n",
    "                         file_name=cropped_file_name,\n",
    "                         save_csv=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-22T02:43:08.951146Z",
     "iopub.status.busy": "2025-01-22T02:43:08.950871Z",
     "iopub.status.idle": "2025-01-22T02:43:10.793575Z",
     "shell.execute_reply": "2025-01-22T02:43:10.792612Z",
     "shell.execute_reply.started": "2025-01-22T02:43:08.951114Z"
    },
    "id": "cFJ9K4pwRpqv",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# st = time.time()\n",
    "# extracted_features = extract_features(base_dir=cropped_base_dir,\n",
    "#                                       dataset_dir=dataset_dir,\n",
    "#                                       file_csv=cropped_file_name,\n",
    "#                                       model_name='XceptionNet',\n",
    "#                                       input_shape=(224, 224),\n",
    "#                                       partition=False,\n",
    "#                                       partition_size=1000,\n",
    "#                                       save_result=True,\n",
    "#                                       save_name=extracted_features_file_name\n",
    "#                                       )\n",
    "# print(f\"Total time: {(time.time()-st)/3600:.2f}h\")\n",
    "# Load extracted_features đã có từ trước\n",
    "extracted_features = load_features('/kaggle/input/cs114-cropped-full-dataset/dataset/cropped_extracted_features.npz')\n",
    "df_extracted_features = pd.DataFrame([feature for feature in tqdm(extracted_features, desc=\"Turning to DataFrame\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-22T02:43:10.795337Z",
     "iopub.status.busy": "2025-01-22T02:43:10.795071Z",
     "iopub.status.idle": "2025-01-22T02:43:10.811479Z",
     "shell.execute_reply": "2025-01-22T02:43:10.810758Z",
     "shell.execute_reply.started": "2025-01-22T02:43:10.795316Z"
    },
    "id": "yGjHNOSuSLul",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def to_grayscale(features_list):\n",
    "    processed_features = []\n",
    "    for feature in features_list:\n",
    "        if feature.ndim == 3:\n",
    "            gray_feature = rgb2gray(feature)\n",
    "        else:\n",
    "            gray_feature = feature\n",
    "        processed_features.append(gray_feature)\n",
    "    return np.array(processed_features)\n",
    "\n",
    "def find_duplicate(extracted_features=None,\n",
    "                   base_dir='./',  # Used for 'ssim'\n",
    "                   dataset_dir='./',\n",
    "                   extracted_file='extracted_features.npz',\n",
    "                   similarity_threshold=0.9,\n",
    "                   metric='cosine',\n",
    "                   save_result=False,\n",
    "                   save_name='duplicate_images.csv'):\n",
    "\n",
    "    if extracted_features is None:\n",
    "        file_path = os.path.join(dataset_dir, extracted_file)\n",
    "        data = np.load(file_path, allow_pickle=True)\n",
    "        extracted_features = data['extracted_features']\n",
    "\n",
    "    features_list = [x['Extracted Features'] for x in extracted_features]\n",
    "    image_path_list = [x['ImageFullPath'] for x in extracted_features]\n",
    "    categories_list = [x['CategoryID'] for x in extracted_features]\n",
    "    features_list = to_grayscale(features_list)\n",
    "\n",
    "    features_tensor = torch.tensor(np.array(features_list), device=device)\n",
    "\n",
    "    if metric == 'phash':\n",
    "        precomputed_hashes = {img_path: phash(Image.open(os.path.join(base_dir, img_path)))\n",
    "                              for img_path in tqdm(image_path_list, desc='Computing hashes', unit='image')}\n",
    "\n",
    "    duplicate_images = []\n",
    "    duplicate_indices = []\n",
    "    num_images = len(features_list)\n",
    "\n",
    "    for i in tqdm(range(num_images), desc=\"Processing images\", unit=\"image\"):\n",
    "        # Get the current feature and move it to GPU\n",
    "        current_feature = features_tensor[i].unsqueeze(0)  # Add batch dimension\n",
    "\n",
    "        # Compute similarities in batches\n",
    "        if metric == 'cosine':\n",
    "            # Compute cosine similarity using PyTorch\n",
    "            similarities = torch.nn.functional.cosine_similarity(\n",
    "                current_feature, features_tensor[i + 1:], dim=1\n",
    "            )\n",
    "            # Find indices where similarity > threshold\n",
    "            duplicate_mask = similarities > similarity_threshold\n",
    "            duplicate_indices_batch = torch.nonzero(duplicate_mask).squeeze(1) + i + 1\n",
    "\n",
    "        elif metric == 'euclidean':\n",
    "            # Compute Euclidean distance using PyTorch\n",
    "            distances = torch.cdist(current_feature, features_tensor[i + 1:], p=2).squeeze(0)\n",
    "            # Find indices where distance < (1 - threshold)\n",
    "            duplicate_mask = distances < (1.0 - similarity_threshold)\n",
    "            duplicate_indices_batch = torch.nonzero(duplicate_mask).squeeze(1) + i + 1\n",
    "\n",
    "        elif metric == 'ssim':\n",
    "            # SSIM is not easily parallelizable, so we fall back to CPU\n",
    "            for j in range(i + 1, num_images):\n",
    "                similarity = ssim(features_list[i].reshape(-1), features_list[j].reshape(-1), data_range=1)\n",
    "                if similarity > similarity_threshold:\n",
    "                    print(f\"Found duplicate images: {image_path_list[i]} and {image_path_list[j]} with SSIM {similarity}\")\n",
    "                    duplicate_images.append((image_path_list[i], image_path_list[j], similarity))\n",
    "                    duplicate_indices.append((i, j))\n",
    "\n",
    "        elif metric == 'phash':\n",
    "            # pHash is computed on CPU\n",
    "            hash1 = precomputed_hashes[image_path_list[i]]\n",
    "            for j in range(i + 1, num_images):\n",
    "                hash2 = precomputed_hashes[image_path_list[j]]\n",
    "                similarity = 1 - (hash1 - hash2) / len(hash1.hash)\n",
    "                if similarity > similarity_threshold:\n",
    "                    duplicate_images.append((image_path_list[i], image_path_list[j], similarity))\n",
    "                    duplicate_indices.append((i, j))\n",
    "                    print(f\"Found duplicate images: {image_path_list[i]} and {image_path_list[j]} with SSIM {similarity}\")\n",
    "\n",
    "        # For cosine and Euclidean, process the batch results\n",
    "        if metric in ['cosine', 'euclidean']:\n",
    "            for j in duplicate_indices_batch.cpu().numpy():\n",
    "                if metric == 'cosine':\n",
    "                    similarity = similarities[j - i - 1].item()\n",
    "                    print(f\"Found duplicate images: {image_path_list[i]} and {image_path_list[j]} with cosine similarity {similarity}\")\n",
    "                elif metric == 'euclidean':\n",
    "                    distance = distances[j - i - 1].item()\n",
    "                    print(f\"Found duplicate images: {image_path_list[i]} and {image_path_list[j]} with Euclidean distance {distance}\")\n",
    "                duplicate_images.append((image_path_list[i], image_path_list[j], similarity if metric == 'cosine' else distance))\n",
    "                duplicate_indices.append((i, j))\n",
    "\n",
    "    if save_result:\n",
    "        save_path = os.path.join(dataset_dir, save_name)\n",
    "        if metric in ['cosine', 'ssim', 'phash']:\n",
    "            df = pd.DataFrame(duplicate_images, columns=[\"Image1\", \"Image2\", \"Score\"])\n",
    "        else:\n",
    "            df = pd.DataFrame(duplicate_images, columns=[\"Image1\", \"Image2\", \"Distance\"])\n",
    "        df.to_csv(save_path, index=False)\n",
    "        print(f\"Saved to {save_path}\")\n",
    "\n",
    "    return duplicate_images, duplicate_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-22T02:43:10.812481Z",
     "iopub.status.busy": "2025-01-22T02:43:10.812200Z",
     "iopub.status.idle": "2025-01-22T02:43:10.866140Z",
     "shell.execute_reply": "2025-01-22T02:43:10.865263Z",
     "shell.execute_reply.started": "2025-01-22T02:43:10.812451Z"
    },
    "id": "SdufKvTBScbd",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# duplicate_images = find_duplicate(extracted_features=extracted_features,\n",
    "#                                   base_dir=base_dir,\n",
    "#                                   dataset_dir=dataset_dir,\n",
    "#                                   save_result = True,\n",
    "#                                   metric='cosine') # Xịn nhất nhưng lâu nhất\n",
    "# duplicate_images_2 = find_duplicate(extracted_features=extracted_features,\n",
    "#                                   base_dir=base_dir,\n",
    "#                                   dataset_dir=dataset_dir,\n",
    "#                                   save_result = True,\n",
    "#                                   metric='ssim') # Tàm tạm, không xịn\n",
    "# duplicate_images_3, duplicate_indices_3 = find_duplicate(extracted_features=extracted_features[:10000],\n",
    "#                                   base_dir=base_dir,\n",
    "#                                   dataset_dir=dataset_dir,\n",
    "#                                   save_result = True,\n",
    "#                                   metric='euclidean') # Phế, nhưng nhanh\n",
    "# duplicate_images_4 = find_duplicate(extracted_features=extracted_features,\n",
    "#                                   base_dir=base_dir,\n",
    "#                                   dataset_dir=dataset_dir,\n",
    "#                                   save_result = True,\n",
    "#                                   metric='phash') # Ổn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tiến hành loại bỏ ảnh trùng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-22T02:43:10.867247Z",
     "iopub.status.busy": "2025-01-22T02:43:10.866948Z",
     "iopub.status.idle": "2025-01-22T02:43:10.878178Z",
     "shell.execute_reply": "2025-01-22T02:43:10.877365Z",
     "shell.execute_reply.started": "2025-01-22T02:43:10.867219Z"
    },
    "id": "bDpJgdFwSdWA",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "all_duplicate_images = []\n",
    "all_duplicate_indices = []\n",
    "\n",
    "# Automate processing in chunks of 1000\n",
    "num_images = len(extracted_features)\n",
    "chunk_size = 36740\n",
    "\n",
    "for i in tqdm(range(0, num_images, chunk_size), desc='Processing Batches', unit='batch'):\n",
    "    start_idx = i\n",
    "    end_idx = min(i + chunk_size, num_images)  # Ensure the last chunk doesn't exceed the list\n",
    "    chunk = extracted_features[start_idx:end_idx]\n",
    "    \n",
    "    # Find duplicates in the current chunk\n",
    "    duplicate_images, duplicate_indices = find_duplicate(\n",
    "        extracted_features=chunk,\n",
    "        base_dir=cropped_base_dir,\n",
    "        dataset_dir=dataset_dir,\n",
    "        save_result=True,\n",
    "        save_name=f'duplicate_images_{start_idx + 1}_{end_idx}.csv',\n",
    "        metric='cosine',\n",
    "        similarity_threshold=0.95\n",
    "    )\n",
    "    \n",
    "    # Append the results to the combined lists\n",
    "    all_duplicate_images.extend(duplicate_images)\n",
    "    all_duplicate_indices.extend(duplicate_indices)\n",
    "    \n",
    "    print(f\"Processed images {start_idx + 1} to {end_idx}\")\n",
    "\n",
    "# Create a combined DataFrame\n",
    "df_combined = pd.DataFrame(all_duplicate_images, columns=[\"Image1\", \"Image2\", \"Distance\"])\n",
    "\n",
    "# Add the indices to the DataFrame\n",
    "df_combined['Index1'] = [idx[0] for idx in all_duplicate_indices]\n",
    "df_combined['Index2'] = [idx[1] for idx in all_duplicate_indices]\n",
    "\n",
    "# Save the combined results to a CSV file\n",
    "combined_save_path = os.path.join(dataset_dir, \"cosine_combined_duplicate_images.csv\")\n",
    "df_combined.to_csv(combined_save_path, index=False)\n",
    "print(f\"Combined duplicate image results saved to {combined_save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-22T02:43:10.879252Z",
     "iopub.status.busy": "2025-01-22T02:43:10.879017Z",
     "iopub.status.idle": "2025-01-22T02:43:10.892641Z",
     "shell.execute_reply": "2025-01-22T02:43:10.891897Z",
     "shell.execute_reply.started": "2025-01-22T02:43:10.879233Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "all_duplicate_images = []\n",
    "all_duplicate_indices = []\n",
    "\n",
    "# Automate processing in chunks of 1000\n",
    "num_images = len(extracted_features)\n",
    "chunk_size = 36740\n",
    "\n",
    "for i in tqdm(range(0, num_images, chunk_size), desc='Processing Batches', unit='batch'):\n",
    "    start_idx = i\n",
    "    end_idx = min(i + chunk_size, num_images)  # Ensure the last chunk doesn't exceed the list\n",
    "    chunk = extracted_features[start_idx:end_idx]\n",
    "    \n",
    "    # Find duplicates in the current chunk\n",
    "    duplicate_images, duplicate_indices = find_duplicate(\n",
    "        extracted_features=chunk,\n",
    "        base_dir=cropped_base_dir,\n",
    "        dataset_dir=dataset_dir,\n",
    "        save_result=True,\n",
    "        save_name=f'duplicate_images_{start_idx + 1}_{end_idx}.csv',\n",
    "        metric='euclidean',\n",
    "        similarity_threshold=0.95\n",
    "    )\n",
    "    \n",
    "    # Append the results to the combined lists\n",
    "    all_duplicate_images.extend(duplicate_images)\n",
    "    all_duplicate_indices.extend(duplicate_indices)\n",
    "    \n",
    "    print(f\"Processed images {start_idx + 1} to {end_idx}\")\n",
    "\n",
    "# Create a combined DataFrame\n",
    "df_combined = pd.DataFrame(all_duplicate_images, columns=[\"Image1\", \"Image2\", \"Distance\"])\n",
    "\n",
    "# Add the indices to the DataFrame\n",
    "df_combined['Index1'] = [idx[0] for idx in all_duplicate_indices]\n",
    "df_combined['Index2'] = [idx[1] for idx in all_duplicate_indices]\n",
    "\n",
    "# Save the combined results to a CSV file\n",
    "combined_save_path = os.path.join(dataset_dir, \"euclidean_combined_duplicate_images.csv\")\n",
    "df_combined.to_csv(combined_save_path, index=False)\n",
    "print(f\"Combined duplicate image results saved to {combined_save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-22T02:43:10.897212Z",
     "iopub.status.busy": "2025-01-22T02:43:10.897006Z",
     "iopub.status.idle": "2025-01-22T02:43:10.913538Z",
     "shell.execute_reply": "2025-01-22T02:43:10.912813Z",
     "shell.execute_reply.started": "2025-01-22T02:43:10.897195Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def remove_duplicates(df_extracted_features,\n",
    "                      duplicate_indices,\n",
    "                      removal_strategy='keep_first',\n",
    "                      dataset_dir='./',\n",
    "                      save_results=False,\n",
    "                      extracted_features_name='extracted_features.npz',\n",
    "                      extracted_dataframe_name='dropdup_extracted_features.csv'):\n",
    "    indices_to_remove = set()\n",
    "    removed_image_paths = []  # List to store removed image paths\n",
    "\n",
    "    for i, j in duplicate_indices:\n",
    "        if removal_strategy == 'keep_first':\n",
    "            indices_to_remove.add(j)\n",
    "            removed_image_paths.append(df_extracted_features['ImageFullPath'].iloc[j])  # Add removed image path\n",
    "        elif removal_strategy == 'keep_second':\n",
    "            indices_to_remove.add(i)\n",
    "            removed_image_paths.append(df_extracted_features['ImageFullPath'].iloc[i])  # Add removed image path\n",
    "        elif removal_strategy == 'keep_smaller':\n",
    "            if 'ImageFullPath' not in df_extracted_features.columns:\n",
    "                print(\"Warning: 'ImageFullPath' column not found. Defaulting to 'keep_first'.\")\n",
    "                indices_to_remove.add(j)\n",
    "                removed_image_paths.append(df_extracted_features['ImageFullPath'].iloc[j])  # Add removed image path\n",
    "            else:\n",
    "                path_i = os.path.join(dataset_dir, df_extracted_features['ImageFullPath'].iloc[i])\n",
    "                path_j = os.path.join(dataset_dir, df_extracted_features['ImageFullPath'].iloc[j])\n",
    "                try:\n",
    "                    size_i = os.path.getsize(path_i)\n",
    "                    size_j = os.path.getsize(path_j)\n",
    "\n",
    "                    if size_i <= size_j:\n",
    "                        indices_to_remove.add(j)\n",
    "                        removed_image_paths.append(df_extracted_features['ImageFullPath'].iloc[j])  # Add removed image path\n",
    "                    else:\n",
    "                        indices_to_remove.add(i)\n",
    "                        removed_image_paths.append(df_extracted_features['ImageFullPath'].iloc[i])  # Add removed image path\n",
    "                except FileNotFoundError:\n",
    "                    print(f\"Warning: One or both files not found: {path_i}, {path_j}. Defaulting to 'keep_first'.\")\n",
    "                    indices_to_remove.add(j)\n",
    "                    removed_image_paths.append(df_extracted_features['ImageFullPath'].iloc[j])  # Add removed image path\n",
    "        else:\n",
    "            raise ValueError(f\"Invalid removal_strategy: {removal_strategy}\")\n",
    "\n",
    "    indices_to_remove = sorted(\n",
    "        [df_extracted_features.index[idx] for idx in indices_to_remove if idx < len(df_extracted_features.index)],\n",
    "        reverse=True\n",
    "    )\n",
    "    new_df_extracted_features = df_extracted_features.drop(indices_to_remove)\n",
    "\n",
    "    extracted_features_list = []\n",
    "    # Duyet qua tung dong dataframe\n",
    "    for _, row in tqdm(new_df_extracted_features.iterrows(), desc=\"Extracting Features\", total=len(new_df_extracted_features), file=sys.stdout, leave=True):\n",
    "        image_path = row[\"ImageFullPath\"]\n",
    "        categoryid = row[\"CategoryID\"]\n",
    "        extracted_feature = row[\"Extracted Features\"]\n",
    "        # Lay duong dan full\n",
    "        full_path = os.path.join(dataset_dir, image_path)\n",
    "        try:\n",
    "            extracted_features_list.append({'ImageFullPath': image_path, 'CategoryID': categoryid, 'Extracted Features': extracted_feature})\n",
    "        except Exception as e:\n",
    "            print(f\"Error at image {full_path}: {e}. Skipping...\")\n",
    "\n",
    "    print(f\"Successfully processed {len(extracted_features_list)} images\")\n",
    "    new_df_extracted_features['Extracted Features'] = [entry['Extracted Features'] for entry in extracted_features_list]\n",
    "    new_extracted_features = new_df_extracted_features.reset_index().drop('index', axis=1)\n",
    "    if save_results:\n",
    "        df_file_path = os.path.join(dataset_dir, extracted_dataframe_name)\n",
    "        features_file_path = os.path.join(dataset_dir, extracted_features_name)\n",
    "\n",
    "        new_df_extracted_features.to_csv(df_file_path, index=False)\n",
    "        print(f\"Saved DataFrame to: {df_file_path}\")\n",
    "\n",
    "        np.savez(features_file_path, extracted_features=extracted_features_list)\n",
    "        print(f\"Saved extracted features to: {features_file_path}\")\n",
    "\n",
    "    return new_df_extracted_features, extracted_features_list, removed_image_paths  # Return removed image paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-22T02:43:10.916205Z",
     "iopub.status.busy": "2025-01-22T02:43:10.915961Z",
     "iopub.status.idle": "2025-01-22T02:43:10.929015Z",
     "shell.execute_reply": "2025-01-22T02:43:10.928248Z",
     "shell.execute_reply.started": "2025-01-22T02:43:10.916185Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "new_df_extracted_features, extracted_features_list, indices_to_remove = remove_duplicates(\n",
    "    df_extracted_features=df_extracted_features,\n",
    "    duplicate_indices=all_duplicate_indices,\n",
    "    removal_strategy='keep_first', \n",
    "    dataset_dir=dataset_dir,\n",
    "    save_results=True,\n",
    "    extracted_features_name=cropped_dropdup_extracted_features_file_name,\n",
    "    extracted_dataframe_name=cropped_dropdup_extracted_features_csv\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Visualize Kết quả**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-22T02:43:10.930078Z",
     "iopub.status.busy": "2025-01-22T02:43:10.929867Z",
     "iopub.status.idle": "2025-01-22T02:43:10.943579Z",
     "shell.execute_reply": "2025-01-22T02:43:10.942706Z",
     "shell.execute_reply.started": "2025-01-22T02:43:10.930058Z"
    },
    "id": "nEjMC66aSfsH",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def plot_duplicate_images(image_pairs, base_dir):\n",
    "    rows = len(image_pairs)\n",
    "    fig, axes = plt.subplots(rows, 2, figsize=(10, rows * 3))\n",
    "\n",
    "    if rows == 1:\n",
    "        axes = [axes]\n",
    "\n",
    "    for i, (image_path1, image_path2, scores) in tqdm(enumerate(image_pairs), desc=\"Displaying images\", total=len(image_pairs), unit='image'):\n",
    "        full_path1 = os.path.join(base_dir, image_path1)\n",
    "        full_path2 = os.path.join(base_dir, image_path2)\n",
    "\n",
    "        img1 = Image.open(full_path1)\n",
    "        img2 = Image.open(full_path2)\n",
    "\n",
    "        axes[i][0].imshow(img1)\n",
    "        axes[i][0].axis('off')\n",
    "        axes[i][0].set_title(image_path1.split('/')[-1])\n",
    "\n",
    "        axes[i][1].imshow(img2)\n",
    "        axes[i][1].axis('off')\n",
    "        axes[i][1].set_title(image_path2.split('/')[-1])\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-22T02:43:10.944623Z",
     "iopub.status.busy": "2025-01-22T02:43:10.944406Z",
     "iopub.status.idle": "2025-01-22T02:43:10.955147Z",
     "shell.execute_reply": "2025-01-22T02:43:10.954428Z",
     "shell.execute_reply.started": "2025-01-22T02:43:10.944605Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "plot_duplicate_images(all_duplicate_images[:10], base_dir=cropped_base_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bước 3: Data Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **TorchVision**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-22T02:43:10.956187Z",
     "iopub.status.busy": "2025-01-22T02:43:10.955901Z",
     "iopub.status.idle": "2025-01-22T02:43:10.969287Z",
     "shell.execute_reply": "2025-01-22T02:43:10.968525Z",
     "shell.execute_reply.started": "2025-01-22T02:43:10.956166Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, csv_file, base_dir, transform=None):\n",
    "        self.data_frame = pd.read_csv(csv_file)\n",
    "        self.base_dir = base_dir\n",
    "        self.transform = transform\n",
    "\n",
    "        # Duyệt thư mục lớn để tạo từ điển map từ folder đến ảnh\n",
    "        self.image_paths = self._find_image_paths()\n",
    "\n",
    "    def _find_image_paths(self):\n",
    "        # Tạo từ điển chứa tên folder và đường dẫn đầy đủ tới ảnh trong folder đó\n",
    "        image_paths = {}\n",
    "        \n",
    "        # Use tqdm to show progress while iterating through folders\n",
    "        for folder_name in tqdm(self.data_frame.iloc[:, 0].values, desc=\"Scanning folders\"):\n",
    "            folder_path = os.path.join(self.base_dir, folder_name)\n",
    "            if os.path.isdir(folder_path):  # Kiểm tra nếu folder tồn tại\n",
    "                for img_file in os.listdir(folder_path):\n",
    "                    # Thêm ảnh vào từ điển với key là tên folder và value là đường dẫn ảnh\n",
    "                    img_path = os.path.join(folder_path, img_file)\n",
    "                    if img_file.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "                        image_paths[img_file] = img_path\n",
    "        return image_paths\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_frame)  # Corrected from self.data_frames to self.data_frame\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Lấy tên folder từ file CSV\n",
    "        folder_name = self.data_frame.iloc[idx, 0]\n",
    "\n",
    "        # Lấy class tương ứng từ file CSV\n",
    "        label = int(self.data_frame.iloc[idx, 1])\n",
    "\n",
    "        # Lấy ảnh đầu tiên từ folder tương ứng\n",
    "        img_path = None\n",
    "        img_path = os.path.join(self.base_dir, folder_name)  # Corrected from base_dir to self.base_dir\n",
    "\n",
    "        if img_path is None:\n",
    "            raise FileNotFoundError(f\"Không tìm thấy ảnh trong thư mục {folder_name}\")\n",
    "\n",
    "        # Mở ảnh bằng PIL\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "\n",
    "        # Áp dụng các phép biến đổi ảnh nếu có\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label, img_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-22T02:44:40.325238Z",
     "iopub.status.busy": "2025-01-22T02:44:40.324898Z",
     "iopub.status.idle": "2025-01-22T02:45:58.947639Z",
     "shell.execute_reply": "2025-01-22T02:45:58.946747Z",
     "shell.execute_reply.started": "2025-01-22T02:44:40.325208Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "csv_file = \"/kaggle/input/cs114-extracted-features/dropdup_extracted_features.csv\"\n",
    "\n",
    "# Phép biến đổi ảnh (resize, chuyển thành tensor, normalize)\n",
    "img_size = 640\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((img_size, img_size)),   # Thay đổi kích thước ảnh\n",
    "    transforms.ToTensor(),         # Chuyển thành tensor\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # Normalize ảnh\n",
    "])\n",
    "\n",
    "# Tạo dataset từ file CSV và thư mục ảnh\n",
    "train_dataset = CustomImageDataset(csv_file=csv_file,\n",
    "                                   base_dir=cropped_base_dir,\n",
    "                                   transform=transform)\n",
    "\n",
    "# Tạo DataLoader để load dữ liệu\n",
    "dataloader = DataLoader(train_dataset, batch_size=5, shuffle=True)\n",
    "\n",
    "# Hàm hiển thị ảnh với khả năng điều chỉnh kích thước figure\n",
    "def imshow(img, figsize=(30, 30)):  # figsize là kích thước (width, height) của figure\n",
    "    # Đảo ngược chuẩn hóa ảnh\n",
    "    img = img / 2 + 0.5  # Đảo ngược chuẩn hóa (vì đã chuẩn hóa với mean=0.5, std=0.5)\n",
    "    npimg = img.numpy()  # Chuyển tensor thành numpy\n",
    "    plt.figure(figsize=figsize)  # Thiết lập kích thước figure\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))  # Đảo chiều từ (C, H, W) -> (H, W, C)\n",
    "    plt.grid(False)\n",
    "    plt.show()\n",
    "\n",
    "# Kiểm tra dữ liệu bằng cách in ra 1 batch và hiển thị ảnh\n",
    "for images, labels, _ in tqdm(dataloader, total=dataloader.__len__(), desc=\"Processing batches\"):  # Thêm tqdm ở đây\n",
    "    print(f\"Image batch shape: {images.shape}\")\n",
    "    print(f\"Label batch shape: {labels.shape}\")\n",
    "\n",
    "    # Hiển thị batch ảnh đầu tiên (với kích thước lớn hơn)\n",
    "    imshow(torchvision.utils.make_grid(images), figsize=(12, 12))  # Kích thước lớn hơn (width=12, height=12)\n",
    "\n",
    "    break  # Hiển thị 1 batch thôi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-22T02:46:25.817531Z",
     "iopub.status.busy": "2025-01-22T02:46:25.817220Z",
     "iopub.status.idle": "2025-01-22T02:46:25.830195Z",
     "shell.execute_reply": "2025-01-22T02:46:25.829429Z",
     "shell.execute_reply.started": "2025-01-22T02:46:25.817505Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def pytorch_to_numpy(image_tensor):\n",
    "    return image_tensor.cpu().permute(1, 2, 0).numpy()  # Chuyển từ (C, H, W) thành (H, W, C)\n",
    "\n",
    "# Hàm hiển thị ảnh\n",
    "def plot_images(original_img, augmented_imgs, n_samples=5, figsize=(15, 5)):\n",
    "    plt.figure(figsize=figsize)\n",
    "\n",
    "    # Vẽ ảnh gốc ở vị trí đầu tiên\n",
    "    plt.subplot(1, n_samples + 1, 1)\n",
    "    plt.imshow(original_img)\n",
    "    plt.axis('off')\n",
    "    plt.title(\"Original Image\")\n",
    "\n",
    "    # Vẽ các ảnh augmented ở các vị trí còn lại\n",
    "    for i in range(n_samples):\n",
    "        plt.subplot(1, n_samples + 1, i + 2)\n",
    "        plt.imshow(augmented_imgs[i])\n",
    "        plt.axis('off')\n",
    "        plt.title(f\"Augmented {i+1}\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# Hàm áp dụng data augmentation bằng PyTorch\n",
    "def apply_augmentations_with_pytorch(dataloader,\n",
    "                                     n_samples=7, \n",
    "                                     output_dir=\"/kaggle/working/augmented_images\", \n",
    "                                     plot_images=True,\n",
    "                                     verbose=True):\n",
    "    # Tạo thư mục đầu ra nếu chưa tồn tại\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Lấy một ảnh mẫu để có kích thước ảnh\n",
    "    for images, _, img_paths in dataloader:  # Thêm img_paths vào vòng lặp\n",
    "        img_size = images[0].shape[1]  # Lấy chiều cao hoặc chiều rộng vì ảnh là vuông\n",
    "        break\n",
    "\n",
    "    # Khởi tạo các phép biến đổi sử dụng torchvision.transforms\n",
    "    transform = transforms.Compose([\n",
    "        transforms.RandomRotation(30),         # Quay ngẫu nhiên ảnh trong phạm vi 30 độ\n",
    "        transforms.RandomHorizontalFlip(),     # Lật ngang ngẫu nhiên\n",
    "        transforms.RandomResizedCrop(img_size, scale=(0.8, 1.0)),  # Cắt và thay đổi kích thước ngẫu nhiên\n",
    "        transforms.ColorJitter(\n",
    "            brightness=random.uniform(0, 0.1),\n",
    "            contrast=random.uniform(0.5, 0.7),\n",
    "            saturation=random.uniform(0.5, 0.7),\n",
    "            hue=random.uniform(0, 0.2)\n",
    "        )  # Điều chỉnh thông số ColorJitter hợp lý hơn\n",
    "    ])\n",
    "\n",
    "    # Lặp qua dữ liệu trong dataloader với tqdm\n",
    "    for batch_idx, (images, _, img_paths) in enumerate(tqdm(dataloader, total=dataloader.__len__(), desc=\"Processing batches\")):\n",
    "        # Chuyển mỗi batch ảnh từ tensor sang numpy array\n",
    "        for image_tensor, img_path in zip(images, img_paths):  # Lặp qua từng ảnh và đường dẫn\n",
    "            # In ra đường dẫn ảnh\n",
    "            print(f\"Image Path: {img_path}\") if verbose else None\n",
    "            image_tensor = image_tensor.to(device)\n",
    "\n",
    "            # Ảnh gốc\n",
    "            original_image_np = pytorch_to_numpy(image_tensor)\n",
    "            original_image_np = (original_image_np * 0.5 + 0.5).clip(0, 1)  # Đảo ngược chuẩn hóa\n",
    "\n",
    "            # Áp dụng augmentations\n",
    "            augmented_imgs = []\n",
    "            for aug_idx in range(n_samples):\n",
    "                # Áp dụng phép biến đổi cho mỗi ảnh\n",
    "                augmented_image_tensor = transform(image_tensor * 0.5 + 0.5)\n",
    "                augmented_image_np = pytorch_to_numpy(augmented_image_tensor)\n",
    "                augmented_image_np = (augmented_image_np).clip(0, 1)  # Đảm bảo ảnh sau augment nằm trong khoảng [0, 1]\n",
    "                augmented_imgs.append(augmented_image_np)\n",
    "\n",
    "                # Lấy tên folder từ đường dẫn ảnh\n",
    "                folder_name = img_path.split('/')[-2]  # Lấy tên folder từ đường dẫn (ví dụ: \"Honda\")\n",
    "                folder_output_dir = os.path.join(output_dir, folder_name)  # Thư mục đầu ra cho folder này\n",
    "                os.makedirs(folder_output_dir, exist_ok=True)  # Tạo thư mục nếu chưa tồn tại\n",
    "\n",
    "                # Lưu ảnh đã augment\n",
    "                img_name = os.path.basename(img_path)  # Lấy tên file từ đường dẫn\n",
    "                img_name_without_ext = os.path.splitext(img_name)[0]  # Bỏ phần mở rộng\n",
    "                output_path = os.path.join(folder_output_dir, f\"{img_name_without_ext}_augmented_{aug_idx + 1}.jpg\")\n",
    "                save_image(augmented_image_tensor.cpu(), output_path)  # Lưu ảnh (chuyển lại về CPU trước khi lưu)\n",
    "\n",
    "            # Plot ảnh gốc và các ảnh augmented nếu plot_images=True\n",
    "            if plot_images:\n",
    "                plot_images(original_image_np, augmented_imgs, n_samples=n_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-22T02:46:50.725228Z",
     "iopub.status.busy": "2025-01-22T02:46:50.724887Z",
     "iopub.status.idle": "2025-01-22T02:46:50.728582Z",
     "shell.execute_reply": "2025-01-22T02:46:50.727675Z",
     "shell.execute_reply.started": "2025-01-22T02:46:50.725197Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "apply_augmentations_with_pytorch(dataloader,\n",
    "                                 n_samples=5,\n",
    "                                 plot_images=False,\n",
    "                                 verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bước 4: Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-22T02:46:56.763703Z",
     "iopub.status.busy": "2025-01-22T02:46:56.763360Z",
     "iopub.status.idle": "2025-01-22T02:46:56.771575Z",
     "shell.execute_reply": "2025-01-22T02:46:56.770631Z",
     "shell.execute_reply.started": "2025-01-22T02:46:56.763673Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def split_kfold_datasets(data=None,\n",
    "                        num_splits=5,\n",
    "                        base_dir='./',\n",
    "                        dataset_dir='./',\n",
    "                        save_csv=False,\n",
    "                        file_name='CarDataset.csv',\n",
    "                        prefix=None,\n",
    "                        random_state=42,\n",
    "                        ):\n",
    "    os.makedirs(dataset_dir, exist_ok=True)  # Tạo thư mục đầu ra nếu chưa tồn tại\n",
    "    if data == None:\n",
    "      # Đọc dữ liệu từ file CSV ban đầu\n",
    "      data_path = os.path.join(dataset_dir, file_name)\n",
    "      data = pd.read_csv(data_path)\n",
    "\n",
    "    path_list = data['ImageFullPath'].values # Danh sách đường dẫn hình ảnh\n",
    "    categoryid_list = data['CategoryID'].values # Danh sách mã hiệu xe tương ứng\n",
    "\n",
    "    train_splits = []  # Danh sách chứa các DataFrame tập train\n",
    "    test_splits = []  # Danh sách chứa các DataFrame tập test\n",
    "\n",
    "    # Khởi tạo đối tượng KFold\n",
    "    kfold = KFold(n_splits=num_splits, shuffle=True, random_state=random_state)\n",
    "\n",
    "    for i, (train_index, test_index) in enumerate(kfold.split(path_list)):\n",
    "        # Đường dẫn file train/test cho từng tập con\n",
    "        if prefix is not None:\n",
    "            train_file_path = os.path.join(dataset_dir, f'{prefix}_CarDataset-Splits-{i + 1}-Train.csv')\n",
    "            test_file_path = os.path.join(dataset_dir, f'{prefix}_CarDataset-Splits-{i + 1}-Test.csv')\n",
    "        else:\n",
    "            train_file_path = os.path.join(dataset_dir, f'CarDataset-Splits-{i + 1}-Train.csv')\n",
    "            test_file_path = os.path.join(dataset_dir, f'CarDataset-Splits-{i + 1}-Test.csv')\n",
    "        # Tạo DataFrame cho tập train và test\n",
    "        train_data = pd.DataFrame({\n",
    "            'ImageFullPath': [path_list[idx] for idx in train_index],\n",
    "            'CategoryID': [categoryid_list[idx] for idx in train_index]\n",
    "        })\n",
    "        test_data = pd.DataFrame({\n",
    "            'ImageFullPath': [path_list[idx] for idx in test_index],\n",
    "            'CategoryID': [categoryid_list[idx] for idx in test_index]\n",
    "        })\n",
    "\n",
    "        if save_csv:\n",
    "            # Lưu DataFrame ra file CSV\n",
    "            train_data.to_csv(train_file_path, index=False)\n",
    "            test_data.to_csv(test_file_path, index=False)\n",
    "\n",
    "            print(f\"Train fold {i + 1} saved to {train_file_path}\")\n",
    "            print(f\"Test fold {i + 1} saved to {test_file_path}\")\n",
    "\n",
    "        train_splits.append(train_data)\n",
    "        test_splits.append(test_data)\n",
    "\n",
    "    return train_splits, test_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-22T02:46:56.923849Z",
     "iopub.status.busy": "2025-01-22T02:46:56.923638Z",
     "iopub.status.idle": "2025-01-22T02:46:56.928842Z",
     "shell.execute_reply": "2025-01-22T02:46:56.927958Z",
     "shell.execute_reply.started": "2025-01-22T02:46:56.923829Z"
    },
    "id": "Zl_6fyS8QkcS",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def display_splits(train_splits, test_splits, max_files=5):\n",
    "    for i, (train_data, test_data) in enumerate(zip(train_splits, test_splits)):\n",
    "        print(f\"\\n=================== Split {i + 1} ===================\")\n",
    "\n",
    "        print(\"Train Files:\")\n",
    "        train_files = train_data['ImageFullPath'].tolist()\n",
    "        for file in train_files[:max_files]:\n",
    "            print(file)\n",
    "        if len(train_files) > max_files:\n",
    "            print(f\"... and {len(train_files) - max_files} more\")\n",
    "\n",
    "        print(\"\\nTest Files:\")\n",
    "        test_files = test_data['ImageFullPath'].tolist()\n",
    "        for file in test_files[:max_files]:\n",
    "            print(file)\n",
    "        if len(test_files) > max_files:\n",
    "            print(f\"... and {len(test_files) - max_files} more\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-22T02:46:57.116680Z",
     "iopub.status.busy": "2025-01-22T02:46:57.116480Z",
     "iopub.status.idle": "2025-01-22T02:46:57.121477Z",
     "shell.execute_reply": "2025-01-22T02:46:57.120664Z",
     "shell.execute_reply.started": "2025-01-22T02:46:57.116662Z"
    },
    "id": "yTPer4Z5Qo-V",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def plot_class_distributions(splits, mode='train'):\n",
    "    num_splits = len(splits)\n",
    "\n",
    "    fig, axes = plt.subplots(1, num_splits, figsize=(5 * num_splits, 5), sharey=True)\n",
    "    title = f\"Class Distributions Across {'Training' if mode == 'train' else 'Testing'} Splits\"\n",
    "    fig.suptitle(title)\n",
    "\n",
    "    for i, ax in enumerate(axes):\n",
    "        class_counts = splits[i]['CategoryID'].value_counts().sort_index()\n",
    "        class_counts.plot(kind='bar', ax=ax)\n",
    "        ax.set_title(f'Car-Splits-{i + 1}-Train' if mode == 'train' else f'Car-Splits-{i + 1}-Test')\n",
    "        ax.set_xlabel('CategoryID')\n",
    "        if i == 0:\n",
    "            ax.set_ylabel('Số lượng ảnh')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-22T02:46:57.247877Z",
     "iopub.status.busy": "2025-01-22T02:46:57.247644Z",
     "iopub.status.idle": "2025-01-22T02:46:57.254666Z",
     "shell.execute_reply": "2025-01-22T02:46:57.253955Z",
     "shell.execute_reply.started": "2025-01-22T02:46:57.247857Z"
    },
    "id": "xYKDNFaKPfsr",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def display_images(csv_file='CarDataset-Splits-1-Train.csv',\n",
    "                   base_dir='./',\n",
    "                   dataset_dir='./',\n",
    "                   num_imgs_per_row=10,\n",
    "                   img_height=150,\n",
    "                   img_width=150,):\n",
    "    # Đọc file CSV\n",
    "    csv_path = os.path.join(dataset_dir, csv_file)\n",
    "    df = pd.read_csv(csv_path)\n",
    "\n",
    "    # Lấy danh sách các CategoryID\n",
    "    categories = df['CategoryID'].unique()\n",
    "\n",
    "    # Thiết lập vùng visualize/Điều chỉnh figsize cho phù hợp với số lượng ảnh\n",
    "    fig_height = len(categories) * (img_height / 100)\n",
    "    fig_width = num_imgs_per_row * (img_width / 100)\n",
    "    plt.figure(figsize=(fig_height, fig_width))\n",
    "\n",
    "    for i, category in enumerate(tqdm(categories, desc=\"Displaying images\")):\n",
    "        # Lấy ảnh thuộc category hiện tại\n",
    "        category_imgs = df[df['CategoryID'] == category]['ImageFullPath'].tolist()\n",
    "\n",
    "        # Chọn ngẫu nhiên ảnh\n",
    "        selected_imgs = random.sample(category_imgs, min(len(category_imgs), num_imgs_per_row))\n",
    "\n",
    "        # Tạo subplot cho CategoryID (đặt nó ở cột đầu tiên mỗi hàng)\n",
    "        ax = plt.subplot(len(categories), num_imgs_per_row + 1, i * (num_imgs_per_row + 1) + 1)\n",
    "        ax.text(0.5, 0.5, invert_indexing[category],\n",
    "                ha='center', va='center', fontsize=12, fontweight='bold')\n",
    "        ax.axis(\"off\")\n",
    "\n",
    "        # Hiển thị các ảnh trong hàng\n",
    "        for j, img_path in enumerate(selected_imgs):\n",
    "            ax = plt.subplot(len(categories), num_imgs_per_row + 1, i * (num_imgs_per_row + 1) + j + 2)\n",
    "            try:\n",
    "                img = Image.open(os.path.join(base_dir, img_path))\n",
    "                img = img.resize((img_width, img_height))\n",
    "                ax.imshow(img)\n",
    "                ax.axis(\"off\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading image {img_path}: {e}\")\n",
    "                ax.axis(\"off\")\n",
    "\n",
    "    # Điều chỉnh layout\n",
    "    plt.subplots_adjust(wspace=0.2, hspace=0.4)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-22T02:46:58.664035Z",
     "iopub.status.busy": "2025-01-22T02:46:58.663707Z",
     "iopub.status.idle": "2025-01-22T02:46:58.667493Z",
     "shell.execute_reply": "2025-01-22T02:46:58.666548Z",
     "shell.execute_reply.started": "2025-01-22T02:46:58.664005Z"
    },
    "id": "8zSdbi9dPjRi",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "display_images(csv_file='CarDataset-Splits-1-Train.csv',\n",
    "               base_dir=augmented_base_dir,\n",
    "               dataset_dir=dataset_dir,\n",
    "               num_imgs_per_row=10,\n",
    "               img_height=150,\n",
    "               img_width=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-22T02:47:00.798400Z",
     "iopub.status.busy": "2025-01-22T02:47:00.798061Z",
     "iopub.status.idle": "2025-01-22T02:47:00.801693Z",
     "shell.execute_reply": "2025-01-22T02:47:00.800932Z",
     "shell.execute_reply.started": "2025-01-22T02:47:00.798373Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "st = time.time()\n",
    "augmented_extracted_features = extract_features(base_dir=augmented_base_dir,\n",
    "                                      dataset_dir=dataset_dir,\n",
    "                                      file_csv='AugmentedCarDataset.csv',\n",
    "                                      model_name='XceptionNet',\n",
    "                                      input_shape=(224, 224),\n",
    "                                      partition=False,\n",
    "                                      partition_size=1000,\n",
    "                                      save_result=True,\n",
    "                                      save_name=augmented_extracted_features_file_name,\n",
    "                                      )\n",
    "print(f\"Total time: {(time.time()-st)/3600:.2f}h\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-22T02:47:01.997389Z",
     "iopub.status.busy": "2025-01-22T02:47:01.997038Z",
     "iopub.status.idle": "2025-01-22T02:47:02.004364Z",
     "shell.execute_reply": "2025-01-22T02:47:02.003576Z",
     "shell.execute_reply.started": "2025-01-22T02:47:01.997360Z"
    },
    "id": "48dClV_WRtpl",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def perform_clustering(extracted_features=None,\n",
    "                       dataset_dir='./',\n",
    "                       extracted_file='augmented_extracted_features.npz',\n",
    "                       n_clusters=5,\n",
    "                       random_state=42,\n",
    "                       save_file=False,\n",
    "                       save_name='augmented_clustering_Results.csv',\n",
    "                       clustering_algorithm='KMeans'\n",
    "                       ):\n",
    "    if extracted_features is None:\n",
    "        data = np.load(os.path.join(dataset_dir, extracted_file), allow_pickle=True)\n",
    "        extracted_features = data['extracted_features']\n",
    "    features_list = [x['Extracted Features'] for x in tqdm(extracted_features)]\n",
    "    image_path_list = [x['ImageFullPath'] for x in tqdm(extracted_features)]\n",
    "    category_id_list = [x['CategoryID'] for x in tqdm(extracted_features)]\n",
    "\n",
    "    if clustering_algorithm == 'KMeans':\n",
    "        clustering = KMeans(n_clusters=n_clusters, random_state=random_state).fit(features_list)\n",
    "    elif clustering_algorithm == 'DBSCAN':\n",
    "        clustering = DBSCAN(eps=0.5, min_samples=5).fit(features_list)\n",
    "    elif clustering_algorithm == 'AgglomerativeClustering':\n",
    "        clustering = AgglomerativeClustering(n_clusters=n_clusters).fit(features_list)\n",
    "    elif clustering_algorithm == 'MeanShift':\n",
    "        clustering = MeanShift().fit(features_list)\n",
    "    elif clustering_algorithm == 'Birch':\n",
    "        clustering = Birch(n_clusters=n_clusters).fit(features_list)\n",
    "    elif clustering_algorithm == 'SpectralClustering':\n",
    "        clustering = SpectralClustering(n_clusters=n_clusters, affinity='nearest_neighbors').fit(features_list)\n",
    "    else:\n",
    "        print(f\"Clustering algorithm {clustering_algorithm} is not supported\")\n",
    "        return None\n",
    "\n",
    "    df = pd.DataFrame({'ImageFullPath': image_path_list, 'ClusterID': clustering.labels_})\n",
    "    if save_file:\n",
    "      save_path = os.path.join(dataset_dir, save_name)\n",
    "      df.to_csv(save_path, index=False)\n",
    "      print(f\"Clustering result saved to {save_path}\")\n",
    "\n",
    "    return df, clustering, features_list, image_path_list, category_id_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-22T02:47:02.147305Z",
     "iopub.status.busy": "2025-01-22T02:47:02.147062Z",
     "iopub.status.idle": "2025-01-22T02:47:02.150326Z",
     "shell.execute_reply": "2025-01-22T02:47:02.149620Z",
     "shell.execute_reply.started": "2025-01-22T02:47:02.147285Z"
    },
    "id": "vVNRYg_QRyBG",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df, clustering, features_list, image_path_list, category_id_list = perform_clustering(dataset_dir=dataset_dir,\n",
    "                                                                    extracted_file='/kaggle/input/cs114-augmented-features/augmented_extracted_features.npz',\n",
    "                                                                    n_clusters=5,\n",
    "                                                                    save_file=True,\n",
    "                                                                    save_name='augmented_clustering_results.csv',\n",
    "                                                                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GKyT9zh1R4oT"
   },
   "source": [
    " ## **Visualize kết quả**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-22T02:47:03.873523Z",
     "iopub.status.busy": "2025-01-22T02:47:03.873196Z",
     "iopub.status.idle": "2025-01-22T02:47:03.879996Z",
     "shell.execute_reply": "2025-01-22T02:47:03.879186Z",
     "shell.execute_reply.started": "2025-01-22T02:47:03.873495Z"
    },
    "id": "0uJysNsCR7HE",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def visualize_clustering(features_list, clustering, n_components=2):\n",
    "    # Lay nhan cua cluster\n",
    "    unique_clusters = np.unique(clustering.labels_)\n",
    "\n",
    "    if n_components == 2:\n",
    "        # Dung PCA de giam so chieu con 2\n",
    "        pca = PCA(n_components=2)\n",
    "        features_2d = pca.fit_transform(features_list)\n",
    "\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        scatter = plt.scatter(features_2d[:, 0], features_2d[:, 1], c=clustering.labels_, cmap='gist_rainbow', alpha=1.0)\n",
    "        plt.xlabel('PCA Component 1')\n",
    "        plt.ylabel('PCA Component 2')\n",
    "        plt.title(f'K-Means Clustering of Car Features on {len(features_list)} Images')\n",
    "\n",
    "        colorbar = plt.colorbar(scatter, label='Cluster ID')\n",
    "        colorbar.set_ticks(unique_clusters)\n",
    "        colorbar.set_ticklabels([str(label) for label in unique_clusters])\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "    elif n_components == 3:\n",
    "        pca = PCA(n_components=3)\n",
    "        features_3d = pca.fit_transform(features_list)\n",
    "\n",
    "        df = pd.DataFrame(features_3d, columns=['PCA Component 1', 'PCA Component 2', 'PCA Component 3'])\n",
    "        df['Cluster ID'] = clustering.labels_.astype(str)  # Convert to string for discrete color mapping\n",
    "\n",
    "        fig = px.scatter_3d(df, x='PCA Component 1', y='PCA Component 2', z='PCA Component 3',\n",
    "                            color='Cluster ID',\n",
    "                            title=f'K-Means Clustering of Car Features on {len(features_list)} Images (3D Plot)',)\n",
    "\n",
    "        fig.update_layout(scene=dict(xaxis_title='PCA Component 1', yaxis_title='PCA Component 2', zaxis_title='PCA Component 3'))\n",
    "        fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-22T02:47:04.031001Z",
     "iopub.status.busy": "2025-01-22T02:47:04.030791Z",
     "iopub.status.idle": "2025-01-22T02:47:04.034236Z",
     "shell.execute_reply": "2025-01-22T02:47:04.033396Z",
     "shell.execute_reply.started": "2025-01-22T02:47:04.030982Z"
    },
    "id": "NTz6-lmoSA9P",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "visualize_clustering(features_list, clustering, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-22T02:47:05.545922Z",
     "iopub.status.busy": "2025-01-22T02:47:05.545607Z",
     "iopub.status.idle": "2025-01-22T02:47:05.553714Z",
     "shell.execute_reply": "2025-01-22T02:47:05.552830Z",
     "shell.execute_reply.started": "2025-01-22T02:47:05.545894Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def display_clustering(df=None,\n",
    "                   csv_file='Clustering_results.csv',\n",
    "                   base_dir='./',\n",
    "                   dataset_dir='./',\n",
    "                   num_imgs_per_row=10,\n",
    "                   img_height=150,\n",
    "                   img_width=150):\n",
    "    # Đọc file CSV\n",
    "    csv_path = os.path.join(dataset_dir, csv_file)\n",
    "    if df is None:\n",
    "        df = pd.read_csv(csv_path)\n",
    "\n",
    "    # Lấy danh sách các ClusterID\n",
    "    clusters = df['ClusterID'].unique()\n",
    "\n",
    "    # Thiết lập vùng visualize/Điều chỉnh figsize cho phù hợp với số lượng ảnh\n",
    "    fig_height = len(clusters) * (img_height / 100) * 1.2\n",
    "    fig_width = num_imgs_per_row * (img_width / 100) * 1.2\n",
    "    plt.figure(figsize=(fig_width, fig_height))\n",
    "\n",
    "    for i, cluster in enumerate(tqdm(clusters, desc=\"Processing clusters\", unit=\"cluster\")):\n",
    "        # Lấy ảnh thuộc cluster hiện tại\n",
    "        cluster_imgs = df[df['ClusterID'] == cluster]['ImageFullPath'].tolist()\n",
    "        # Chọn ngẫu nhiên ảnh\n",
    "        selected_imgs = random.sample(cluster_imgs, min(len(cluster_imgs), num_imgs_per_row))\n",
    "\n",
    "        # Tạo subplot cho ClusterID (đặt nó ở cột đầu tiên mỗi hàng)\n",
    "        ax = plt.subplot(len(clusters), num_imgs_per_row + 1, i * (num_imgs_per_row + 1) + 1)\n",
    "        ax.text(0.5, 0.5, f\"Cluster {cluster}\",\n",
    "                ha='center', va='center', fontsize=10, fontweight='bold')\n",
    "        ax.axis(\"off\")\n",
    "\n",
    "        # Hiển thị các ảnh trong hàng\n",
    "        for j, img_path in enumerate(selected_imgs):\n",
    "            ax = plt.subplot(len(clusters), num_imgs_per_row + 1, i * (num_imgs_per_row + 1) + j + 2)\n",
    "            try:\n",
    "                img = Image.open(os.path.join(base_dir, img_path))\n",
    "                img = img.resize((img_width, img_height))\n",
    "                ax.imshow(img)\n",
    "                ax.axis(\"off\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading image {img_path}: {e}\")\n",
    "                ax.axis(\"off\")\n",
    "\n",
    "    # Điều chỉnh layout\n",
    "    plt.subplots_adjust(wspace=0.1, hspace=0.3)  # Reduce whitespace\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-22T02:47:05.696487Z",
     "iopub.status.busy": "2025-01-22T02:47:05.696287Z",
     "iopub.status.idle": "2025-01-22T02:47:05.699525Z",
     "shell.execute_reply": "2025-01-22T02:47:05.698796Z",
     "shell.execute_reply.started": "2025-01-22T02:47:05.696469Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# display_clustering(csv_file='/kaggle/working/dataset/augmented_clustering_results.csv', base_dir=augmented_base_dir, dataset_dir=dataset_dir, num_imgs_per_row=10, img_height=150, img_width=150)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bước 5: Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-22T02:47:06.023641Z",
     "iopub.status.busy": "2025-01-22T02:47:06.023422Z",
     "iopub.status.idle": "2025-01-22T02:47:06.027583Z",
     "shell.execute_reply": "2025-01-22T02:47:06.026675Z",
     "shell.execute_reply.started": "2025-01-22T02:47:06.023623Z"
    },
    "id": "A1IJ2FSBTEZn",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def load_split_with_features(csv_file,\n",
    "                             features_df):\n",
    "    split_df = pd.read_csv(csv_file)\n",
    "    merged_df = pd.merge(split_df, features_df, on='ImageFullPath')\n",
    "    merged_df = merged_df[['ImageFullPath', 'CategoryID', 'Extracted Features']]\n",
    "    \n",
    "    return merged_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Load các đặc trưng đã được trích xuất**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-22T02:47:08.547184Z",
     "iopub.status.busy": "2025-01-22T02:47:08.546830Z",
     "iopub.status.idle": "2025-01-22T02:47:09.418794Z",
     "shell.execute_reply": "2025-01-22T02:47:09.418144Z",
     "shell.execute_reply.started": "2025-01-22T02:47:08.547146Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "extracted_features = load_features('/kaggle/input/cs114-extracted-features/fulldata_extracted_features.npz')\n",
    "df_extracted_features = pd.DataFrame([feature for feature in tqdm(extracted_features)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-22T02:47:09.420277Z",
     "iopub.status.busy": "2025-01-22T02:47:09.419950Z",
     "iopub.status.idle": "2025-01-22T02:47:10.266043Z",
     "shell.execute_reply": "2025-01-22T02:47:10.265285Z",
     "shell.execute_reply.started": "2025-01-22T02:47:09.420245Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "cropped_extracted_features = load_features('/kaggle/input/cs114-cropped-full-dataset/dataset/cropped_extracted_features.npz')\n",
    "df_cropped_extracted_features = pd.DataFrame([feature for feature in tqdm(cropped_extracted_features)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-22T02:47:10.267847Z",
     "iopub.status.busy": "2025-01-22T02:47:10.267625Z",
     "iopub.status.idle": "2025-01-22T02:47:12.043693Z",
     "shell.execute_reply": "2025-01-22T02:47:12.042966Z",
     "shell.execute_reply.started": "2025-01-22T02:47:10.267828Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "cropped_dropdup_extracted_features = load_features('/kaggle/input/cs114-extracted-features/dropdup_extracted_features.npz')\n",
    "df_cropped_dropdup_extracted_features = pd.DataFrame([feature for feature in tqdm(cropped_dropdup_extracted_features)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-22T02:47:12.044843Z",
     "iopub.status.busy": "2025-01-22T02:47:12.044535Z",
     "iopub.status.idle": "2025-01-22T02:47:20.892747Z",
     "shell.execute_reply": "2025-01-22T02:47:20.892028Z",
     "shell.execute_reply.started": "2025-01-22T02:47:12.044809Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "augmented_extracted_features = load_features('/kaggle/input/cs114-augmented-dataset/augmented_images/augmented_extracted_features.npz')\n",
    "df_augmented_extracted_features = pd.DataFrame([feature for feature in tqdm(augmented_extracted_features)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-22T02:47:20.894045Z",
     "iopub.status.busy": "2025-01-22T02:47:20.893834Z",
     "iopub.status.idle": "2025-01-22T02:47:30.555593Z",
     "shell.execute_reply": "2025-01-22T02:47:30.554609Z",
     "shell.execute_reply.started": "2025-01-22T02:47:20.894027Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "full_augmented_extracted_features = load_features('/kaggle/input/cs114-full-augmented-dataset/full_augmented_extracted_features.npz')\n",
    "df_full_augmented_extracted_features = pd.DataFrame([feature for feature in tqdm(full_augmented_extracted_features)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-22T02:47:37.029688Z",
     "iopub.status.busy": "2025-01-22T02:47:37.029360Z",
     "iopub.status.idle": "2025-01-22T02:47:37.036340Z",
     "shell.execute_reply": "2025-01-22T02:47:37.035490Z",
     "shell.execute_reply.started": "2025-01-22T02:47:37.029663Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def augmented_get_dataset(base_dir='./',\n",
    "                dataset_dir='/',\n",
    "                categories=['Others', 'Honda', 'Hyundai', 'KIA', 'Mazda', 'Mitsubishi', 'Suzuki', 'Toyota', 'VinFast'],\n",
    "                save_csv=False,\n",
    "                file_name='augmented_CarDataset.csv',\n",
    "                ) -> pd.DataFrame:\n",
    "\n",
    "    os.makedirs(dataset_dir, exist_ok=True)\n",
    "\n",
    "    path_list = []\n",
    "    categoryid_list = []\n",
    "\n",
    "    student_ids_pattern = r'(\\d{8}(?:-\\d{8})*)'\n",
    "    categories_pattern = '|'.join(categories)\n",
    "    file_extension_pattern = r'\\.(jpg|jpeg|png)$'\n",
    "    \n",
    "    # Updated regex to handle files like \"20520918.Mitsubishi.10_augmented_1.jpg\"\n",
    "    accepted_filename = re.compile(fr'{student_ids_pattern}\\.({categories_pattern})\\.[\\w-]+{file_extension_pattern}')\n",
    "\n",
    "    for category in tqdm(categories, desc=\"Processing categories\"):\n",
    "        category_path = os.path.join(base_dir, category)\n",
    "        if os.path.isdir(category_path):\n",
    "            for filename in os.listdir(category_path):\n",
    "                match = accepted_filename.match(filename)\n",
    "                if match:\n",
    "                    _, car_category, _ = match.groups()\n",
    "                    if car_category in categories:\n",
    "                        full_path = os.path.join(category, filename)  # Relative path within base_dir\n",
    "                        path_list.append(full_path)\n",
    "                        categoryid_list.append(indexing[car_category])\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "        'ImageFullPath': path_list,\n",
    "        'CategoryID': categoryid_list\n",
    "    })\n",
    "\n",
    "    if save_csv:\n",
    "        output_file = os.path.join(dataset_dir, file_name)\n",
    "        df.to_csv(output_file, index=False)\n",
    "        print(f\"{file_name} saved to {output_file}\")\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Tạo các Dataframe để tiến hành Split dữ liệu**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-22T02:49:16.731511Z",
     "iopub.status.busy": "2025-01-22T02:49:16.731192Z",
     "iopub.status.idle": "2025-01-22T02:49:18.874018Z",
     "shell.execute_reply": "2025-01-22T02:49:18.873017Z",
     "shell.execute_reply.started": "2025-01-22T02:49:16.731484Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "data = get_dataset(base_dir=cropped_base_dir,\n",
    "                            dataset_dir=dataset_dir,\n",
    "                            file_name=dataset_name,\n",
    "                            save_csv=True)\n",
    "cropped_data = get_dataset(base_dir=cropped_base_dir,\n",
    "                            dataset_dir=dataset_dir,\n",
    "                            file_name=cropped_dataset_name,\n",
    "                            save_csv=True)\n",
    "cropped_dropdup_data = get_dataset(base_dir=cropped_base_dir,\n",
    "                            dataset_dir=dataset_dir,\n",
    "                            file_name=cropped_dropdup_dataset_name,\n",
    "                            save_csv=True)\n",
    "augmented_data = augmented_get_dataset(base_dir=augmented_base_dir,\n",
    "                            dataset_dir=dataset_dir,\n",
    "                            file_name=augmented_dataset_name,\n",
    "                            save_csv=True)\n",
    "full_augmented_data = augmented_get_dataset(base_dir=full_augmented_base_dir,\n",
    "                            dataset_dir=dataset_dir,\n",
    "                            file_name=full_augmented_dataset_name,\n",
    "                            save_csv=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-22T02:49:21.346308Z",
     "iopub.status.busy": "2025-01-22T02:49:21.345987Z",
     "iopub.status.idle": "2025-01-22T02:49:30.136414Z",
     "shell.execute_reply": "2025-01-22T02:49:30.135651Z",
     "shell.execute_reply.started": "2025-01-22T02:49:21.346284Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_splits, test_splits = split_kfold_datasets(num_splits=num_splits,\n",
    "                                                 dataset_dir=dataset_dir,\n",
    "                                                 file_name=dataset_name,\n",
    "                                                 save_csv=True,\n",
    "                                                 random_state=42)\n",
    "cropped_train_splits, cropped_test_splits = split_kfold_datasets(num_splits=num_splits,\n",
    "                                                 dataset_dir=dataset_dir,\n",
    "                                                 file_name=cropped_dataset_name,\n",
    "                                                 save_csv=True,\n",
    "                                                 prefix='cropped',\n",
    "                                                 random_state=42)\n",
    "cropped_dropdup_train_splits, cropped_dropdup_test_splits = split_kfold_datasets(num_splits=num_splits,\n",
    "                                                 dataset_dir=dataset_dir,\n",
    "                                                 file_name=cropped_dropdup_dataset_name,\n",
    "                                                 save_csv=True,\n",
    "                                                 prefix='cropped_dropdup',                                                                              \n",
    "                                                 random_state=42)\n",
    "augmented_train_splits, augmented_test_splits = split_kfold_datasets(num_splits=num_splits,\n",
    "                                                 dataset_dir=dataset_dir,\n",
    "                                                 file_name=augmented_dataset_name,\n",
    "                                                 prefix='augmented',\n",
    "                                                 save_csv=True,\n",
    "                                                 random_state=42)\n",
    "full_augmented_train_splits, full_augmented_test_splits = split_kfold_datasets(num_splits=num_splits,\n",
    "                                                 dataset_dir=dataset_dir,\n",
    "                                                 file_name=full_augmented_dataset_name,\n",
    "                                                 prefix='full_augmented',\n",
    "                                                 save_csv=True,\n",
    "                                                 random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-22T02:49:34.824766Z",
     "iopub.status.busy": "2025-01-22T02:49:34.824373Z",
     "iopub.status.idle": "2025-01-22T02:49:34.844093Z",
     "shell.execute_reply": "2025-01-22T02:49:34.843436Z",
     "shell.execute_reply.started": "2025-01-22T02:49:34.824725Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "display_splits(train_splits, test_splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-22T02:49:36.942435Z",
     "iopub.status.busy": "2025-01-22T02:49:36.942153Z",
     "iopub.status.idle": "2025-01-22T02:49:39.406950Z",
     "shell.execute_reply": "2025-01-22T02:49:39.406064Z",
     "shell.execute_reply.started": "2025-01-22T02:49:36.942412Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "plot_class_distributions(train_splits, mode='train')\n",
    "plot_class_distributions(test_splits, mode='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-22T02:49:39.408317Z",
     "iopub.status.busy": "2025-01-22T02:49:39.408006Z",
     "iopub.status.idle": "2025-01-22T02:49:39.427275Z",
     "shell.execute_reply": "2025-01-22T02:49:39.426532Z",
     "shell.execute_reply.started": "2025-01-22T02:49:39.408293Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "display_splits(cropped_train_splits, cropped_test_splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-22T02:49:39.429197Z",
     "iopub.status.busy": "2025-01-22T02:49:39.428946Z",
     "iopub.status.idle": "2025-01-22T02:49:41.930969Z",
     "shell.execute_reply": "2025-01-22T02:49:41.930129Z",
     "shell.execute_reply.started": "2025-01-22T02:49:39.429175Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "plot_class_distributions(cropped_train_splits, mode='train')\n",
    "plot_class_distributions(cropped_test_splits, mode='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-22T02:49:41.932604Z",
     "iopub.status.busy": "2025-01-22T02:49:41.932286Z",
     "iopub.status.idle": "2025-01-22T02:49:41.953317Z",
     "shell.execute_reply": "2025-01-22T02:49:41.952579Z",
     "shell.execute_reply.started": "2025-01-22T02:49:41.932571Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "display_splits(cropped_dropdup_train_splits, cropped_dropdup_test_splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-22T02:49:41.954427Z",
     "iopub.status.busy": "2025-01-22T02:49:41.954143Z",
     "iopub.status.idle": "2025-01-22T02:49:44.187241Z",
     "shell.execute_reply": "2025-01-22T02:49:44.186319Z",
     "shell.execute_reply.started": "2025-01-22T02:49:41.954396Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "plot_class_distributions(cropped_dropdup_train_splits, mode='train')\n",
    "plot_class_distributions(cropped_dropdup_test_splits, mode='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-22T02:49:44.188495Z",
     "iopub.status.busy": "2025-01-22T02:49:44.188142Z",
     "iopub.status.idle": "2025-01-22T02:49:44.221142Z",
     "shell.execute_reply": "2025-01-22T02:49:44.220417Z",
     "shell.execute_reply.started": "2025-01-22T02:49:44.188447Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "display_splits(augmented_train_splits, augmented_test_splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-22T02:49:44.222174Z",
     "iopub.status.busy": "2025-01-22T02:49:44.221909Z",
     "iopub.status.idle": "2025-01-22T02:49:46.997802Z",
     "shell.execute_reply": "2025-01-22T02:49:46.997034Z",
     "shell.execute_reply.started": "2025-01-22T02:49:44.222139Z"
    },
    "id": "6Llx583fQq9q",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "plot_class_distributions(augmented_train_splits, mode='train')\n",
    "plot_class_distributions(augmented_test_splits, mode='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-22T02:49:46.999665Z",
     "iopub.status.busy": "2025-01-22T02:49:46.999450Z",
     "iopub.status.idle": "2025-01-22T02:49:47.033997Z",
     "shell.execute_reply": "2025-01-22T02:49:47.033326Z",
     "shell.execute_reply.started": "2025-01-22T02:49:46.999646Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "display_splits(full_augmented_train_splits, full_augmented_test_splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-22T02:49:47.035169Z",
     "iopub.status.busy": "2025-01-22T02:49:47.034924Z",
     "iopub.status.idle": "2025-01-22T02:49:49.241920Z",
     "shell.execute_reply": "2025-01-22T02:49:49.241050Z",
     "shell.execute_reply.started": "2025-01-22T02:49:47.035148Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "plot_class_distributions(full_augmented_train_splits, mode='train')\n",
    "plot_class_distributions(full_augmented_test_splits, mode='test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Đưa dữ liệu từ các splits vào các biến**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-22T02:50:18.984344Z",
     "iopub.status.busy": "2025-01-22T02:50:18.984023Z",
     "iopub.status.idle": "2025-01-22T02:50:18.989480Z",
     "shell.execute_reply": "2025-01-22T02:50:18.988713Z",
     "shell.execute_reply.started": "2025-01-22T02:50:18.984318Z"
    },
    "id": "KFhPC7HYjpM3",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def load_and_prepare_data(train_files, test_files, features_df):\n",
    "    train_splits = []\n",
    "    test_splits = []\n",
    "\n",
    "    def load_split_with_features(csv_file, features_df):\n",
    "        split_df = pd.read_csv(csv_file)\n",
    "        merged_df = pd.merge(split_df, features_df, on='ImageFullPath')\n",
    "        merged_df = merged_df[['ImageFullPath', 'CategoryID', 'Extracted Features']]\n",
    "        return merged_df\n",
    "\n",
    "    for train_file in train_files:\n",
    "      train_split_df = load_split_with_features(train_file, features_df)\n",
    "      train_splits.append(train_split_df)\n",
    "\n",
    "    for test_file in test_files:\n",
    "      test_split_df = load_split_with_features(test_file, features_df)\n",
    "      test_splits.append(test_split_df)\n",
    "\n",
    "    return train_splits, test_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-22T02:50:26.644850Z",
     "iopub.status.busy": "2025-01-22T02:50:26.644569Z",
     "iopub.status.idle": "2025-01-22T02:50:26.673152Z",
     "shell.execute_reply": "2025-01-22T02:50:26.672482Z",
     "shell.execute_reply.started": "2025-01-22T02:50:26.644826Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df_features = df_extracted_features.drop('CategoryID', axis=1)\n",
    "df_cropped_features = df_cropped_extracted_features.drop('CategoryID', axis=1)\n",
    "df_cropped_dropdup_features = df_cropped_dropdup_extracted_features.drop('CategoryID', axis=1)\n",
    "df_augmented_features = df_augmented_extracted_features.drop('CategoryID', axis=1)\n",
    "df_full_augmented_features = df_full_augmented_extracted_features.drop('CategoryID', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-22T02:50:34.564741Z",
     "iopub.status.busy": "2025-01-22T02:50:34.564448Z",
     "iopub.status.idle": "2025-01-22T02:50:39.017835Z",
     "shell.execute_reply": "2025-01-22T02:50:39.017048Z",
     "shell.execute_reply.started": "2025-01-22T02:50:34.564718Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Original Dataset\n",
    "train_files = [f'{dataset_dir}/CarDataset-Splits-{i + 1}-Train.csv' for i in tqdm(range(num_splits), desc=\"Generating Original Train File\")]\n",
    "test_files = [f'{dataset_dir}/CarDataset-Splits-{i + 1}-Test.csv' for i in tqdm(range(num_splits), desc=\"Generating Original Test File\")]\n",
    "train_splits_with_features, test_splits_with_features = load_and_prepare_data(train_files, test_files, df_features)\n",
    "\n",
    "# Cropped Dataset\n",
    "cropped_train_files = [f'{dataset_dir}/cropped_CarDataset-Splits-{i + 1}-Train.csv' for i in tqdm(range(num_splits), desc=\"Generating Cropped Train File\")]\n",
    "cropped_test_files = [f'{dataset_dir}/cropped_CarDataset-Splits-{i + 1}-Test.csv' for i in tqdm(range(num_splits), desc=\"Generating Cropped Test File\")]\n",
    "cropped_train_splits_with_features, cropped_test_splits_with_features = load_and_prepare_data(cropped_train_files, cropped_test_files, df_cropped_features)\n",
    "\n",
    "# Cropped and Deduplicated Dataset\n",
    "cropped_dropdup_train_files = [f'{dataset_dir}/cropped_dropdup_CarDataset-Splits-{i + 1}-Train.csv' for i in tqdm(range(num_splits), desc=\"Generating Cropped Dropdup Train File\")]\n",
    "cropped_dropdup_test_files = [f'{dataset_dir}/cropped_dropdup_CarDataset-Splits-{i + 1}-Test.csv' for i in tqdm(range(num_splits), desc=\"Generating Cropped Dropdup Test File\")]\n",
    "cropped_dropdup_train_splits_with_features, cropped_dropdup_test_splits_with_features = load_and_prepare_data(cropped_dropdup_train_files, cropped_dropdup_test_files, df_cropped_dropdup_features)\n",
    "\n",
    "# Augmented Dataset\n",
    "augmented_train_files = [f'{dataset_dir}/augmented_CarDataset-Splits-{i + 1}-Train.csv' for i in tqdm(range(num_splits), desc=\"Generating Augmented Train File\")]\n",
    "augmented_test_files = [f'{dataset_dir}/augmented_CarDataset-Splits-{i + 1}-Test.csv' for i in tqdm(range(num_splits), desc=\"Generating Augmented Test File\")]\n",
    "augmented_train_splits_with_features, augmented_test_splits_with_features = load_and_prepare_data(augmented_train_files, augmented_test_files, df_augmented_features)\n",
    "\n",
    "# Full Augmented Dataset\n",
    "full_augmented_train_files = [f'{dataset_dir}/full_augmented_CarDataset-Splits-{i + 1}-Train.csv' for i in tqdm(range(num_splits), desc=\"Generating Full Augmented Train File\")]\n",
    "full_augmented_test_files = [f'{dataset_dir}/full_augmented_CarDataset-Splits-{i + 1}-Test.csv' for i in tqdm(range(num_splits), desc=\"Generating Full Augmented Test File\")]\n",
    "full_augmented_train_splits_with_features, full_augmented_test_splits_with_features = load_and_prepare_data(full_augmented_train_files, augmented_test_files, df_augmented_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-22T02:50:40.492457Z",
     "iopub.status.busy": "2025-01-22T02:50:40.492135Z",
     "iopub.status.idle": "2025-01-22T02:50:40.500475Z",
     "shell.execute_reply": "2025-01-22T02:50:40.499708Z",
     "shell.execute_reply.started": "2025-01-22T02:50:40.492431Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Full Dataset\n",
    "train_df_1 = train_splits_with_features[0]\n",
    "train_df_2 = train_splits_with_features[1]\n",
    "train_df_3 = train_splits_with_features[2]\n",
    "train_df_4 = train_splits_with_features[3]\n",
    "train_df_5 = train_splits_with_features[4]\n",
    "\n",
    "test_df_1 = test_splits_with_features[0]\n",
    "test_df_2 = test_splits_with_features[1]\n",
    "test_df_3 = test_splits_with_features[2]\n",
    "test_df_4 = test_splits_with_features[3]\n",
    "test_df_5 = test_splits_with_features[4]\n",
    "\n",
    "# Cropped Dataset\n",
    "cropped_train_df_1 = cropped_train_splits_with_features[0]\n",
    "cropped_train_df_2 = cropped_train_splits_with_features[1]\n",
    "cropped_train_df_3 = cropped_train_splits_with_features[2]\n",
    "cropped_train_df_4 = cropped_train_splits_with_features[3]\n",
    "cropped_train_df_5 = cropped_train_splits_with_features[4]\n",
    "\n",
    "cropped_test_df_1 = cropped_test_splits_with_features[0]\n",
    "cropped_test_df_2 = cropped_test_splits_with_features[1]\n",
    "cropped_test_df_3 = cropped_test_splits_with_features[2]\n",
    "cropped_test_df_4 = cropped_test_splits_with_features[3]\n",
    "cropped_test_df_5 = cropped_test_splits_with_features[4]\n",
    "\n",
    "# Cropped + Drop Duplicate Dataset\n",
    "cropped_dropdup_train_df_1 = cropped_dropdup_train_splits_with_features[0]\n",
    "cropped_dropdup_train_df_2 = cropped_dropdup_train_splits_with_features[1]\n",
    "cropped_dropdup_train_df_3 = cropped_dropdup_train_splits_with_features[2]\n",
    "cropped_dropdup_train_df_4 = cropped_dropdup_train_splits_with_features[3]\n",
    "cropped_dropdup_train_df_5 = cropped_dropdup_train_splits_with_features[4]\n",
    "\n",
    "cropped_dropdup_test_df_1 = cropped_dropdup_test_splits_with_features[0]\n",
    "cropped_dropdup_test_df_2 = cropped_dropdup_test_splits_with_features[1]\n",
    "cropped_dropdup_test_df_3 = cropped_dropdup_test_splits_with_features[2]\n",
    "cropped_dropdup_test_df_4 = cropped_dropdup_test_splits_with_features[3]\n",
    "cropped_dropdup_test_df_5 = cropped_dropdup_test_splits_with_features[4]\n",
    "\n",
    "# Augmented Dataset\n",
    "augmented_train_df_1 = augmented_train_splits_with_features[0]\n",
    "augmented_train_df_2 = augmented_train_splits_with_features[1]\n",
    "augmented_train_df_3 = augmented_train_splits_with_features[2]\n",
    "augmented_train_df_4 = augmented_train_splits_with_features[3]\n",
    "augmented_train_df_5 = augmented_train_splits_with_features[4]\n",
    "\n",
    "augmented_test_df_1 = augmented_test_splits_with_features[0]\n",
    "augmented_test_df_2 = augmented_test_splits_with_features[1]\n",
    "augmented_test_df_3 = augmented_test_splits_with_features[2]\n",
    "augmented_test_df_4 = augmented_test_splits_with_features[3]\n",
    "augmented_test_df_5 = augmented_test_splits_with_features[4]\n",
    "\n",
    "# Full Augmented Dataset\n",
    "full_augmented_train_df_1 = full_augmented_train_splits_with_features[0]\n",
    "full_augmented_train_df_2 = full_augmented_train_splits_with_features[1]\n",
    "full_augmented_train_df_3 = full_augmented_train_splits_with_features[2]\n",
    "full_augmented_train_df_4 = full_augmented_train_splits_with_features[3]\n",
    "full_augmented_train_df_5 = full_augmented_train_splits_with_features[4]\n",
    "\n",
    "full_augmented_test_df_1 = full_augmented_test_splits_with_features[0]\n",
    "full_augmented_test_df_2 = full_augmented_test_splits_with_features[1]\n",
    "full_augmented_test_df_3 = full_augmented_test_splits_with_features[2]\n",
    "full_augmented_test_df_4 = full_augmented_test_splits_with_features[3]\n",
    "full_augmented_test_df_5 = full_augmented_test_splits_with_features[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-22T02:50:45.386671Z",
     "iopub.status.busy": "2025-01-22T02:50:45.386353Z",
     "iopub.status.idle": "2025-01-22T02:50:46.271288Z",
     "shell.execute_reply": "2025-01-22T02:50:46.270190Z",
     "shell.execute_reply.started": "2025-01-22T02:50:45.386645Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "X_train_1 = np.array(train_df_1['Extracted Features'].apply(lambda x: x).tolist())\n",
    "X_train_2 = np.array(train_df_2['Extracted Features'].apply(lambda x: x).tolist())\n",
    "X_train_3 = np.array(train_df_3['Extracted Features'].apply(lambda x: x).tolist())\n",
    "X_train_4 = np.array(train_df_4['Extracted Features'].apply(lambda x: x).tolist())\n",
    "X_train_5 = np.array(train_df_5['Extracted Features'].apply(lambda x: x).tolist())\n",
    "\n",
    "X_test_1 = np.array(test_df_1['Extracted Features'].apply(lambda x: x).tolist())\n",
    "X_test_2 = np.array(test_df_2['Extracted Features'].apply(lambda x: x).tolist())\n",
    "X_test_3 = np.array(test_df_3['Extracted Features'].apply(lambda x: x).tolist())\n",
    "X_test_4 = np.array(test_df_4['Extracted Features'].apply(lambda x: x).tolist())\n",
    "X_test_5 = np.array(test_df_5['Extracted Features'].apply(lambda x: x).tolist())\n",
    "\n",
    "y_train_1 = np.array(train_df_1['CategoryID'].tolist())\n",
    "y_train_2 = np.array(train_df_2['CategoryID'].tolist())\n",
    "y_train_3 = np.array(train_df_3['CategoryID'].tolist())\n",
    "y_train_4 = np.array(train_df_4['CategoryID'].tolist())\n",
    "y_train_5 = np.array(train_df_5['CategoryID'].tolist())\n",
    "\n",
    "y_test_1 = np.array(test_df_1['CategoryID'].tolist())\n",
    "y_test_2 = np.array(test_df_2['CategoryID'].tolist())\n",
    "y_test_3 = np.array(test_df_3['CategoryID'].tolist())\n",
    "y_test_4 = np.array(test_df_4['CategoryID'].tolist())\n",
    "y_test_5 = np.array(test_df_5['CategoryID'].tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-22T02:50:46.272777Z",
     "iopub.status.busy": "2025-01-22T02:50:46.272488Z",
     "iopub.status.idle": "2025-01-22T02:50:47.011022Z",
     "shell.execute_reply": "2025-01-22T02:50:47.010079Z",
     "shell.execute_reply.started": "2025-01-22T02:50:46.272755Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "cropped_X_train_1 = np.array(cropped_train_df_1['Extracted Features'].apply(lambda x: x).tolist())\n",
    "cropped_X_train_2 = np.array(cropped_train_df_2['Extracted Features'].apply(lambda x: x).tolist())\n",
    "cropped_X_train_3 = np.array(cropped_train_df_3['Extracted Features'].apply(lambda x: x).tolist())\n",
    "cropped_X_train_4 = np.array(cropped_train_df_4['Extracted Features'].apply(lambda x: x).tolist())\n",
    "cropped_X_train_5 = np.array(cropped_train_df_5['Extracted Features'].apply(lambda x: x).tolist())\n",
    "\n",
    "cropped_X_test_1 = np.array(cropped_test_df_1['Extracted Features'].apply(lambda x: x).tolist())\n",
    "cropped_X_test_2 = np.array(cropped_test_df_2['Extracted Features'].apply(lambda x: x).tolist())\n",
    "cropped_X_test_3 = np.array(cropped_test_df_3['Extracted Features'].apply(lambda x: x).tolist())\n",
    "cropped_X_test_4 = np.array(cropped_test_df_4['Extracted Features'].apply(lambda x: x).tolist())\n",
    "cropped_X_test_5 = np.array(cropped_test_df_5['Extracted Features'].apply(lambda x: x).tolist())\n",
    "\n",
    "cropped_y_train_1 = np.array(cropped_train_df_1['CategoryID'].tolist())\n",
    "cropped_y_train_2 = np.array(cropped_train_df_2['CategoryID'].tolist())\n",
    "cropped_y_train_3 = np.array(cropped_train_df_3['CategoryID'].tolist())\n",
    "cropped_y_train_4 = np.array(cropped_train_df_4['CategoryID'].tolist())\n",
    "cropped_y_train_5 = np.array(cropped_train_df_5['CategoryID'].tolist())\n",
    "\n",
    "cropped_y_test_1 = np.array(cropped_test_df_1['CategoryID'].tolist())\n",
    "cropped_y_test_2 = np.array(cropped_test_df_2['CategoryID'].tolist())\n",
    "cropped_y_test_3 = np.array(cropped_test_df_3['CategoryID'].tolist())\n",
    "cropped_y_test_4 = np.array(cropped_test_df_4['CategoryID'].tolist())\n",
    "cropped_y_test_5 = np.array(cropped_test_df_5['CategoryID'].tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-22T02:50:47.013068Z",
     "iopub.status.busy": "2025-01-22T02:50:47.012756Z",
     "iopub.status.idle": "2025-01-22T02:50:47.754155Z",
     "shell.execute_reply": "2025-01-22T02:50:47.753471Z",
     "shell.execute_reply.started": "2025-01-22T02:50:47.013037Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "cropped_dropdup_X_train_1 = np.array(cropped_dropdup_train_df_1['Extracted Features'].apply(lambda x: x).tolist())\n",
    "cropped_dropdup_X_train_2 = np.array(cropped_dropdup_train_df_2['Extracted Features'].apply(lambda x: x).tolist())\n",
    "cropped_dropdup_X_train_3 = np.array(cropped_dropdup_train_df_3['Extracted Features'].apply(lambda x: x).tolist())\n",
    "cropped_dropdup_X_train_4 = np.array(cropped_dropdup_train_df_4['Extracted Features'].apply(lambda x: x).tolist())\n",
    "cropped_dropdup_X_train_5 = np.array(cropped_dropdup_train_df_5['Extracted Features'].apply(lambda x: x).tolist())\n",
    "\n",
    "cropped_dropdup_X_test_1 = np.array(cropped_dropdup_test_df_1['Extracted Features'].apply(lambda x: x).tolist())\n",
    "cropped_dropdup_X_test_2 = np.array(cropped_dropdup_test_df_2['Extracted Features'].apply(lambda x: x).tolist())\n",
    "cropped_dropdup_X_test_3 = np.array(cropped_dropdup_test_df_3['Extracted Features'].apply(lambda x: x).tolist())\n",
    "cropped_dropdup_X_test_4 = np.array(cropped_dropdup_test_df_4['Extracted Features'].apply(lambda x: x).tolist())\n",
    "cropped_dropdup_X_test_5 = np.array(cropped_dropdup_test_df_5['Extracted Features'].apply(lambda x: x).tolist())\n",
    "\n",
    "cropped_dropdup_y_train_1 = np.array(cropped_dropdup_train_df_1['CategoryID'].tolist())\n",
    "cropped_dropdup_y_train_2 = np.array(cropped_dropdup_train_df_2['CategoryID'].tolist())\n",
    "cropped_dropdup_y_train_3 = np.array(cropped_dropdup_train_df_3['CategoryID'].tolist())\n",
    "cropped_dropdup_y_train_4 = np.array(cropped_dropdup_train_df_4['CategoryID'].tolist())\n",
    "cropped_dropdup_y_train_5 = np.array(cropped_dropdup_train_df_5['CategoryID'].tolist())\n",
    "\n",
    "cropped_dropdup_y_test_1 = np.array(cropped_dropdup_test_df_1['CategoryID'].tolist())\n",
    "cropped_dropdup_y_test_2 = np.array(cropped_dropdup_test_df_2['CategoryID'].tolist())\n",
    "cropped_dropdup_y_test_3 = np.array(cropped_dropdup_test_df_3['CategoryID'].tolist())\n",
    "cropped_dropdup_y_test_4 = np.array(cropped_dropdup_test_df_4['CategoryID'].tolist())\n",
    "cropped_dropdup_y_test_5 = np.array(cropped_dropdup_test_df_5['CategoryID'].tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-22T02:50:47.755415Z",
     "iopub.status.busy": "2025-01-22T02:50:47.755094Z",
     "iopub.status.idle": "2025-01-22T02:50:52.221630Z",
     "shell.execute_reply": "2025-01-22T02:50:52.220921Z",
     "shell.execute_reply.started": "2025-01-22T02:50:47.755386Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "augmented_X_train_1 = np.array(augmented_train_df_1['Extracted Features'].apply(lambda x: x).tolist())\n",
    "augmented_X_train_2 = np.array(augmented_train_df_2['Extracted Features'].apply(lambda x: x).tolist())\n",
    "augmented_X_train_3 = np.array(augmented_train_df_3['Extracted Features'].apply(lambda x: x).tolist())\n",
    "augmented_X_train_4 = np.array(augmented_train_df_4['Extracted Features'].apply(lambda x: x).tolist())\n",
    "augmented_X_train_5 = np.array(augmented_train_df_5['Extracted Features'].apply(lambda x: x).tolist())\n",
    "\n",
    "augmented_X_test_1 = np.array(augmented_test_df_1['Extracted Features'].apply(lambda x: x).tolist())\n",
    "augmented_X_test_2 = np.array(augmented_test_df_2['Extracted Features'].apply(lambda x: x).tolist())\n",
    "augmented_X_test_3 = np.array(augmented_test_df_3['Extracted Features'].apply(lambda x: x).tolist())\n",
    "augmented_X_test_4 = np.array(augmented_test_df_4['Extracted Features'].apply(lambda x: x).tolist())\n",
    "augmented_X_test_5 = np.array(augmented_test_df_5['Extracted Features'].apply(lambda x: x).tolist())\n",
    "\n",
    "augmented_y_train_1 = np.array(augmented_train_df_1['CategoryID'].tolist())\n",
    "augmented_y_train_2 = np.array(augmented_train_df_2['CategoryID'].tolist())\n",
    "augmented_y_train_3 = np.array(augmented_train_df_3['CategoryID'].tolist())\n",
    "augmented_y_train_4 = np.array(augmented_train_df_4['CategoryID'].tolist())\n",
    "augmented_y_train_5 = np.array(augmented_train_df_5['CategoryID'].tolist())\n",
    "\n",
    "augmented_y_test_1 = np.array(augmented_test_df_1['CategoryID'].tolist())\n",
    "augmented_y_test_2 = np.array(augmented_test_df_2['CategoryID'].tolist())\n",
    "augmented_y_test_3 = np.array(augmented_test_df_3['CategoryID'].tolist())\n",
    "augmented_y_test_4 = np.array(augmented_test_df_4['CategoryID'].tolist())\n",
    "augmented_y_test_5 = np.array(augmented_test_df_5['CategoryID'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-22T02:50:52.222515Z",
     "iopub.status.busy": "2025-01-22T02:50:52.222307Z",
     "iopub.status.idle": "2025-01-22T02:50:55.897761Z",
     "shell.execute_reply": "2025-01-22T02:50:55.896828Z",
     "shell.execute_reply.started": "2025-01-22T02:50:52.222496Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "full_augmented_X_train_1 = np.array(full_augmented_train_df_1['Extracted Features'].apply(lambda x: x).tolist())\n",
    "full_augmented_X_train_2 = np.array(full_augmented_train_df_2['Extracted Features'].apply(lambda x: x).tolist())\n",
    "full_augmented_X_train_3 = np.array(full_augmented_train_df_3['Extracted Features'].apply(lambda x: x).tolist())\n",
    "full_augmented_X_train_4 = np.array(full_augmented_train_df_4['Extracted Features'].apply(lambda x: x).tolist())\n",
    "full_augmented_X_train_5 = np.array(full_augmented_train_df_5['Extracted Features'].apply(lambda x: x).tolist())\n",
    "\n",
    "full_augmented_X_test_1 = np.array(full_augmented_test_df_1['Extracted Features'].apply(lambda x: x).tolist())\n",
    "full_augmented_X_test_2 = np.array(full_augmented_test_df_2['Extracted Features'].apply(lambda x: x).tolist())\n",
    "full_augmented_X_test_3 = np.array(full_augmented_test_df_3['Extracted Features'].apply(lambda x: x).tolist())\n",
    "full_augmented_X_test_4 = np.array(full_augmented_test_df_4['Extracted Features'].apply(lambda x: x).tolist())\n",
    "full_augmented_X_test_5 = np.array(full_augmented_test_df_5['Extracted Features'].apply(lambda x: x).tolist())\n",
    "\n",
    "full_augmented_y_train_1 = np.array(full_augmented_train_df_1['CategoryID'].tolist())\n",
    "full_augmented_y_train_2 = np.array(full_augmented_train_df_2['CategoryID'].tolist())\n",
    "full_augmented_y_train_3 = np.array(full_augmented_train_df_3['CategoryID'].tolist())\n",
    "full_augmented_y_train_4 = np.array(full_augmented_train_df_4['CategoryID'].tolist())\n",
    "full_augmented_y_train_5 = np.array(full_augmented_train_df_5['CategoryID'].tolist())\n",
    "\n",
    "full_augmented_y_test_1 = np.array(full_augmented_test_df_1['CategoryID'].tolist())\n",
    "full_augmented_y_test_2 = np.array(full_augmented_test_df_2['CategoryID'].tolist())\n",
    "full_augmented_y_test_3 = np.array(full_augmented_test_df_3['CategoryID'].tolist())\n",
    "full_augmented_y_test_4 = np.array(full_augmented_test_df_4['CategoryID'].tolist())\n",
    "full_augmented_y_test_5 = np.array(full_augmented_test_df_5['CategoryID'].tolist())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Tiến hành huấn luyện và đánh giá**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPU\n",
    "Chỉ hoạt động với T4 GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-22T02:50:55.904695Z",
     "iopub.status.busy": "2025-01-22T02:50:55.904380Z",
     "iopub.status.idle": "2025-01-22T02:50:55.923159Z",
     "shell.execute_reply": "2025-01-22T02:50:55.922516Z",
     "shell.execute_reply.started": "2025-01-22T02:50:55.904674Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "datasets = [\n",
    "    (X_train_1, y_train_1, X_test_1, y_test_1),\n",
    "    (X_train_2, y_train_2, X_test_2, y_test_2),\n",
    "    (X_train_3, y_train_3, X_test_3, y_test_3),\n",
    "    (X_train_4, y_train_4, X_test_4, y_test_4),\n",
    "    (X_train_5, y_train_5, X_test_5, y_test_5)\n",
    "]\n",
    "cropped_datasets = [\n",
    "    (cropped_X_train_1, cropped_y_train_1, cropped_X_test_1, cropped_y_test_1),\n",
    "    (cropped_X_train_2, cropped_y_train_2, cropped_X_test_2, cropped_y_test_2),\n",
    "    (cropped_X_train_3, cropped_y_train_3, cropped_X_test_3, cropped_y_test_3),\n",
    "    (cropped_X_train_4, cropped_y_train_4, cropped_X_test_4, cropped_y_test_4),\n",
    "    (cropped_X_train_5, cropped_y_train_5, cropped_X_test_5, cropped_y_test_5)\n",
    "]\n",
    "\n",
    "cropped_dropdup_datasets = [\n",
    "    (cropped_dropdup_X_train_1, cropped_dropdup_y_train_1, cropped_dropdup_X_test_1, cropped_dropdup_y_test_1),\n",
    "    (cropped_dropdup_X_train_2, cropped_dropdup_y_train_2, cropped_dropdup_X_test_2, cropped_dropdup_y_test_2),\n",
    "    (cropped_dropdup_X_train_3, cropped_dropdup_y_train_3, cropped_dropdup_X_test_3, cropped_dropdup_y_test_3),\n",
    "    (cropped_dropdup_X_train_4, cropped_dropdup_y_train_4, cropped_dropdup_X_test_4, cropped_dropdup_y_test_4),\n",
    "    (cropped_dropdup_X_train_5, cropped_dropdup_y_train_5, cropped_dropdup_X_test_5, cropped_dropdup_y_test_5)\n",
    "]\n",
    "\n",
    "augmented_datasets = [\n",
    "    (augmented_X_train_1, augmented_y_train_1, augmented_X_test_1, augmented_y_test_1),\n",
    "    (augmented_X_train_2, augmented_y_train_2, augmented_X_test_2, augmented_y_test_2),\n",
    "    (augmented_X_train_3, augmented_y_train_3, augmented_X_test_3, augmented_y_test_3),\n",
    "    (augmented_X_train_4, augmented_y_train_4, augmented_X_test_4, augmented_y_test_4),\n",
    "    (augmented_X_train_5, augmented_y_train_5, augmented_X_test_5, augmented_y_test_5)\n",
    "]\n",
    "\n",
    "full_augmented_datasets = [\n",
    "    (full_augmented_X_train_1, full_augmented_y_train_1, full_augmented_X_test_1, full_augmented_y_test_1),\n",
    "    (full_augmented_X_train_2, full_augmented_y_train_2, full_augmented_X_test_2, full_augmented_y_test_2),\n",
    "    (full_augmented_X_train_3, full_augmented_y_train_3, full_augmented_X_test_3, full_augmented_y_test_3),\n",
    "    (full_augmented_X_train_4, full_augmented_y_train_4, full_augmented_X_test_4, full_augmented_y_test_4),\n",
    "    (full_augmented_X_train_5, full_augmented_y_train_5, full_augmented_X_test_5, full_augmented_y_test_5)\n",
    "]\n",
    "\n",
    "def fitting_datasets(datasets, prefix, model_name):\n",
    "    results = []\n",
    "    if model_name == 'SVM':\n",
    "        model = cuSVC(kernel='rbf', random_state=42)\n",
    "    elif model_name == 'RF':\n",
    "        model = cuRFClassifier(random_state=42)\n",
    "    else:\n",
    "        model = cuKNNClassifier(random_state=42)\n",
    "    for i, (X_train, y_train, X_test, y_test) in enumerate(tqdm(datasets, desc=f\"Training {prefix} models\")):\n",
    "        with tqdm(total=2, desc=f\"Fitting {model_name} on {prefix} Dataset {i+1}\", leave=False) as pbar:\n",
    "            model.fit(X_train, y_train)\n",
    "            pbar.update(1)\n",
    "            \n",
    "            # Make predictions\n",
    "            y_pred = model.predict(X_test)\n",
    "            pbar.update(1)\n",
    "        \n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        results.append(accuracy)\n",
    "        print(f'{model_name} Accuracy for {prefix} dataset {i+1}: {accuracy:.6f}')\n",
    "    \n",
    "    average_accuracy = sum(results) / len(results)\n",
    "    print(f'Average {model_name} Accuracy for {prefix} datasets: {average_accuracy:.6f}')\n",
    "    \n",
    "    return model, results, average_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-22T02:50:55.924393Z",
     "iopub.status.busy": "2025-01-22T02:50:55.924084Z",
     "iopub.status.idle": "2025-01-22T02:56:18.527502Z",
     "shell.execute_reply": "2025-01-22T02:56:18.526532Z",
     "shell.execute_reply.started": "2025-01-22T02:50:55.924362Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "svm_original_model, svm_original_results, svm_average_accuracy = fitting_datasets(datasets, 'original', 'SVM')\n",
    "svm_cropped_model, svm_cropped_results, svm_cropped_average_accuracy = fitting_datasets(cropped_datasets, 'cropped', 'SVM')\n",
    "svm_cropped_dropdup_model, svm_cropped_dropdup_results, svm_cropped_dropdup_average_accuracy = fitting_datasets(cropped_dropdup_datasets, 'cropped_dropdup', 'SVM')\n",
    "svm_augmented_model, svm_augmented_results, svm_augmented_average_accuracy = fitting_datasets(augmented_datasets, 'augmented', 'SVM')\n",
    "svm_full_augmented_model, svm_full_augmented_results, svm_full_augmented_average_accuracy = fitting_datasets(full_augmented_datasets, 'full_augmented', 'SVM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-22T02:56:18.528499Z",
     "iopub.status.busy": "2025-01-22T02:56:18.528281Z",
     "iopub.status.idle": "2025-01-22T02:56:56.602560Z",
     "shell.execute_reply": "2025-01-22T02:56:56.601673Z",
     "shell.execute_reply.started": "2025-01-22T02:56:18.528471Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "rf_original_model, rf_original_results, rf_average_accuracy = fitting_datasets(datasets, 'original', 'RF')\n",
    "rf_cropped_model, rf_cropped_results, rf_cropped_average_accuracy = fitting_datasets(cropped_datasets, 'cropped', 'RF')\n",
    "rf_cropped_dropdup_model, rf_cropped_dropdup_results, rf_cropped_dropdup_average_accuracy = fitting_datasets(cropped_dropdup_datasets, 'cropped_dropdup', 'RF')\n",
    "rf_augmented_model, rf_augmented_results, rf_augmented_average_accuracy = fitting_datasets(augmented_datasets, 'augmented', 'RF')\n",
    "rf_full_augmented_model, rf_full_augmented_results, rf_full_augmented_average_accuracy = fitting_datasets(full_augmented_datasets, 'full_augmented', 'RF')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-22T02:56:56.603523Z",
     "iopub.status.busy": "2025-01-22T02:56:56.603299Z",
     "iopub.status.idle": "2025-01-22T02:58:11.747578Z",
     "shell.execute_reply": "2025-01-22T02:58:11.746601Z",
     "shell.execute_reply.started": "2025-01-22T02:56:56.603504Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "knn_original_model, knn_original_results, knn_average_accuracy = fitting_datasets(datasets, 'original', 'KNN')\n",
    "knn_cropped_model, knn_cropped_results, knn_cropped_average_accuracy = fitting_datasets(cropped_datasets, 'cropped', 'KNN')\n",
    "knn_cropped_dropdup_model, knn_cropped_dropdup_results, knn_cropped_dropdup_average_accuracy = fitting_datasets(cropped_dropdup_datasets, 'cropped_dropdup', 'KNN')\n",
    "knn_augmented_model, knn_augmented_results, knn_augmented_average_accuracy = fitting_datasets(augmented_datasets, 'augmented', 'KNN')\n",
    "knn_full_augmented_model, knn_full_augmented_results, knn_full_augmented_average_accuracy = fitting_datasets(full_augmented_datasets, 'full_augmented', 'KNN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Visualize Kết quả**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-22T02:58:11.750275Z",
     "iopub.status.busy": "2025-01-22T02:58:11.750020Z",
     "iopub.status.idle": "2025-01-22T02:58:11.755274Z",
     "shell.execute_reply": "2025-01-22T02:58:11.754524Z",
     "shell.execute_reply.started": "2025-01-22T02:58:11.750251Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(y_true,\n",
    "                          y_pred,\n",
    "                          labels,\n",
    "                          title,\n",
    "                          prefix=None):\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=labels)\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=labels, yticklabels=labels)\n",
    "    title = prefix + '_' + title if prefix is not None else prefix\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Predicted Label\")\n",
    "    plt.ylabel(\"True Label\")\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-22T02:58:11.756941Z",
     "iopub.status.busy": "2025-01-22T02:58:11.756527Z",
     "iopub.status.idle": "2025-01-22T02:58:11.768976Z",
     "shell.execute_reply": "2025-01-22T02:58:11.768276Z",
     "shell.execute_reply.started": "2025-01-22T02:58:11.756865Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "_, _, X_test, y_test = datasets[-1]\n",
    "svm_y_pred = svm_original_model.predict(X_test)\n",
    "rf_y_pred = rf_original_model.predict(X_test)\n",
    "knn_y_pred = knn_original_model.predict(X_test)\n",
    "\n",
    "plot_confusion_matrix(y_test,\n",
    "                      svm_y_pred,\n",
    "                      labels=[label for label in range(len(categories))],\n",
    "                      title='Confusion Matrix for SVM (Dataset 5)',\n",
    "                      prefix='full')\n",
    "\n",
    "plot_confusion_matrix(y_test,\n",
    "                      rf_y_pred,\n",
    "                      labels=[label for label in range(len(categories))],\n",
    "                      title='Confusion Matrix for Random Forest (Dataset 5)',\n",
    "                      prefix='full')\n",
    "\n",
    "plot_confusion_matrix(y_test,\n",
    "                      knn_y_pred,\n",
    "                      labels=[label for label in range(len(categories))],\n",
    "                      title='Confusion Matrix for KNN (Dataset 5)',\n",
    "                      prefix='full')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-22T02:58:11.769841Z",
     "iopub.status.busy": "2025-01-22T02:58:11.769613Z",
     "iopub.status.idle": "2025-01-22T02:58:11.783418Z",
     "shell.execute_reply": "2025-01-22T02:58:11.782651Z",
     "shell.execute_reply.started": "2025-01-22T02:58:11.769811Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "_, _, cropped_X_test, cropped_y_test = cropped_datasets[-1]\n",
    "svm_y_pred = svm_cropped_model.predict(cropped_X_test)\n",
    "rf_y_pred = rf_cropped_model.predict(cropped_X_test)\n",
    "knn_y_pred = knn_cropped_model.predict(cropped_X_test)\n",
    "\n",
    "plot_confusion_matrix(cropped_y_test,\n",
    "                      svm_y_pred,\n",
    "                      labels=[label for label in range(len(categories))],\n",
    "                      title='Confusion Matrix for SVM (Dataset 5)',\n",
    "                      prefix='cropped')\n",
    "\n",
    "plot_confusion_matrix(cropped_y_test,\n",
    "                      rf_y_pred,\n",
    "                      labels=[label for label in range(len(categories))],\n",
    "                      title='Confusion Matrix for Random Forest (Dataset 5)',\n",
    "                      prefix='cropped')\n",
    "\n",
    "plot_confusion_matrix(cropped_y_test,\n",
    "                      knn_y_pred,\n",
    "                      labels=[0, 1],\n",
    "                      title='Confusion Matrix for KNN (Dataset 5)',\n",
    "                      prefix='cropped')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-22T02:58:11.784521Z",
     "iopub.status.busy": "2025-01-22T02:58:11.784234Z",
     "iopub.status.idle": "2025-01-22T02:58:11.794109Z",
     "shell.execute_reply": "2025-01-22T02:58:11.793445Z",
     "shell.execute_reply.started": "2025-01-22T02:58:11.784492Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "_, _, cropped_dropdup_X_test, cropped_dropdup_y_test = cropped_dropdup_datasets[-1]\n",
    "svm_y_pred = svm_cropped_dropdup_model.predict(cropped_dropdup_X_test)\n",
    "rf_y_pred = rf_cropped_dropdup_model.predict(cropped_dropdup_X_test)\n",
    "knn_y_pred = knn_cropped_dropdup_model.predict(cropped_dropdup_X_test)\n",
    "\n",
    "plot_confusion_matrix(cropped_dropdup_y_test,\n",
    "                      svm_y_pred,\n",
    "                      labels=[label for label in range(len(categories))],\n",
    "                      title='Confusion Matrix for SVM (Dataset 5)',\n",
    "                      prefix='cropped_dropdup')\n",
    "\n",
    "plot_confusion_matrix(cropped_dropdup_y_test,\n",
    "                      rf_y_pred,\n",
    "                      labels=[label for label in range(len(categories))],\n",
    "                      title='Confusion Matrix for Random Forest (Dataset 5)',\n",
    "                      prefix='cropped_dropdup')\n",
    "\n",
    "plot_confusion_matrix(cropped_dropdup_y_test,\n",
    "                      knn_y_pred,\n",
    "                      labels=[label for label in range(len(categories))],\n",
    "                      title='Confusion Matrix for KNN (Dataset 5)',\n",
    "                      prefix='cropped_dropdup')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-22T02:58:11.795307Z",
     "iopub.status.busy": "2025-01-22T02:58:11.794976Z",
     "iopub.status.idle": "2025-01-22T02:58:11.807421Z",
     "shell.execute_reply": "2025-01-22T02:58:11.806656Z",
     "shell.execute_reply.started": "2025-01-22T02:58:11.795284Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "_, _, augmented_X_test, augmented_y_test = augmented_datasets[-1]\n",
    "svm_y_pred = svm_augmented_model.predict(augmented_X_test)\n",
    "rf_y_pred = rf_augmented_model.predict(augmented_X_test)\n",
    "knn_y_pred = knn_augmented_model.predict(augmented_X_test)\n",
    "\n",
    "plot_confusion_matrix(augmented_y_test,\n",
    "                      svm_y_pred,\n",
    "                      labels=[label for label in range(len(categories))],\n",
    "                      title='Confusion Matrix for SVM (Dataset 5)',\n",
    "                      prefix='augmented')\n",
    "\n",
    "plot_confusion_matrix(augmented_y_test,\n",
    "                      rf_y_pred,\n",
    "                      labels=[label for label in range(len(categories))],\n",
    "                      title='Confusion Matrix for Random Forest (Dataset 5)',\n",
    "                      prefix='augmented')\n",
    "\n",
    "plot_confusion_matrix(augmented_y_test,\n",
    "                      knn_y_pred,\n",
    "                      labels=[label for label in range(len(categories))],\n",
    "                      title='Confusion Matrix for KNN (Dataset 5)',\n",
    "                      prefix='augmented')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-22T02:58:11.808328Z",
     "iopub.status.busy": "2025-01-22T02:58:11.808124Z",
     "iopub.status.idle": "2025-01-22T02:58:57.835806Z",
     "shell.execute_reply": "2025-01-22T02:58:57.834790Z",
     "shell.execute_reply.started": "2025-01-22T02:58:11.808309Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "_, _, full_augmented_X_test, full_augmented_y_test = full_augmented_datasets[-1]\n",
    "svm_y_pred = svm_full_augmented_model.predict(full_augmented_X_test)\n",
    "rf_y_pred = rf_full_augmented_model.predict(full_augmented_X_test)\n",
    "knn_y_pred = knn_full_augmented_model.predict(full_augmented_X_test)\n",
    "\n",
    "plot_confusion_matrix(full_augmented_y_test,\n",
    "                      svm_y_pred,\n",
    "                      labels=[label for label in range(len(categories))],\n",
    "                      title='Confusion Matrix for SVM (Dataset 5)',\n",
    "                      prefix='full_augmented')\n",
    "\n",
    "plot_confusion_matrix(full_augmented_y_test,\n",
    "                      rf_y_pred,\n",
    "                      labels=[label for label in range(len(categories))],\n",
    "                      title='Confusion Matrix for Random Forest (Dataset 5)',\n",
    "                      prefix='full_augmented')\n",
    "\n",
    "plot_confusion_matrix(full_augmented_y_test,\n",
    "                      knn_y_pred,\n",
    "                      labels=[label for label in range(len(categories))],\n",
    "                      title='Confusion Matrix for KNN (Dataset 5)',\n",
    "                      prefix='full_augmented')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-22T02:58:57.836905Z",
     "iopub.status.busy": "2025-01-22T02:58:57.836664Z",
     "iopub.status.idle": "2025-01-22T02:58:57.843268Z",
     "shell.execute_reply": "2025-01-22T02:58:57.842282Z",
     "shell.execute_reply.started": "2025-01-22T02:58:57.836883Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def visualize_predictions(base_dir,\n",
    "                          image_paths,\n",
    "                          y_true,\n",
    "                          model,\n",
    "                          X_test,\n",
    "                          categories,\n",
    "                          num_images=5):\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    correct_indices = np.where(y_pred == y_true)[0]\n",
    "    incorrect_indices = np.where(y_pred != y_true)[0]\n",
    "\n",
    "    def display_images(indices, title):\n",
    "        plt.figure(figsize=(12, 5))\n",
    "        plt.suptitle(title, fontsize=16)\n",
    "        for i, idx in enumerate(random.sample(list(indices), min(num_images, len(indices)))):\n",
    "            plt.subplot(1, num_images, i + 1)\n",
    "            img_path = os.path.join(base_dir, image_paths[idx])\n",
    "            try:\n",
    "                img = Image.open(img_path)\n",
    "                plt.imshow(img)\n",
    "                plt.title(f\"True Label: {categories[y_true[idx]]}\\nPredicted Label: {categories[y_pred[idx]]}\")\n",
    "                plt.axis(\"off\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading image {img_path}: {e}\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    print(\"Visualizing Correctly Classified Images:\")\n",
    "    display_images(correct_indices, \"Correctly Classified Images\")\n",
    "\n",
    "    print(\"Visualizing Incorrectly Classified Images:\")\n",
    "    display_images(incorrect_indices, \"Incorrectly Classified Images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-22T02:58:57.844232Z",
     "iopub.status.busy": "2025-01-22T02:58:57.843998Z",
     "iopub.status.idle": "2025-01-22T02:58:57.857376Z",
     "shell.execute_reply": "2025-01-22T02:58:57.856517Z",
     "shell.execute_reply.started": "2025-01-22T02:58:57.844211Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "visualize_predictions(base_dir=base_dir,\n",
    "                      image_paths=test_df_1['ImageFullPath'].tolist(),\n",
    "                      y_true=y_test_1,\n",
    "                      model=svm_original_model,\n",
    "                      X_test=X_test_1,\n",
    "                      categories=categories,\n",
    "                      num_images=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-22T02:58:57.858564Z",
     "iopub.status.busy": "2025-01-22T02:58:57.858263Z",
     "iopub.status.idle": "2025-01-22T02:58:57.867647Z",
     "shell.execute_reply": "2025-01-22T02:58:57.866954Z",
     "shell.execute_reply.started": "2025-01-22T02:58:57.858533Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "visualize_predictions(base_dir=cropped_base_dir,\n",
    "                      image_paths=cropped_test_df_1['ImageFullPath'].tolist(),\n",
    "                      y_true=cropped_y_test_1,\n",
    "                      model=svm_cropped_model,\n",
    "                      X_test=cropped_X_test_1,\n",
    "                      categories=categories,\n",
    "                      num_images=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-22T02:58:57.868725Z",
     "iopub.status.busy": "2025-01-22T02:58:57.868432Z",
     "iopub.status.idle": "2025-01-22T02:58:57.879230Z",
     "shell.execute_reply": "2025-01-22T02:58:57.878495Z",
     "shell.execute_reply.started": "2025-01-22T02:58:57.868696Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "visualize_predictions(base_dir=cropped_dropdup_base_dir,\n",
    "                      image_paths=cropped_dropdup_test_df_1['ImageFullPath'].tolist(),\n",
    "                      y_true=cropped_dropdup_y_test_1,\n",
    "                      model=svm_cropped_dropdup_model,\n",
    "                      X_test=cropped_dropdup_X_test_1,\n",
    "                      categories=categories,\n",
    "                      num_images=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-22T02:58:57.880347Z",
     "iopub.status.busy": "2025-01-22T02:58:57.880065Z",
     "iopub.status.idle": "2025-01-22T02:58:57.888893Z",
     "shell.execute_reply": "2025-01-22T02:58:57.888142Z",
     "shell.execute_reply.started": "2025-01-22T02:58:57.880326Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "visualize_predictions(base_dir=augmented_base_dir,\n",
    "                      image_paths=augmented_test_df_1['ImageFullPath'].tolist(),\n",
    "                      y_true=augmented_y_test_1,\n",
    "                      model=svm_augmented_model,\n",
    "                      X_test=augmented_X_test_1,\n",
    "                      categories=categories,\n",
    "                      num_images=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-22T02:58:57.889974Z",
     "iopub.status.busy": "2025-01-22T02:58:57.889755Z",
     "iopub.status.idle": "2025-01-22T02:59:29.476546Z",
     "shell.execute_reply": "2025-01-22T02:59:29.475737Z",
     "shell.execute_reply.started": "2025-01-22T02:58:57.889955Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "visualize_predictions(base_dir=full_augmented_base_dir,\n",
    "                      image_paths=full_augmented_test_df_1['ImageFullPath'].tolist(),\n",
    "                      y_true=full_augmented_y_test_1,\n",
    "                      model=svm_full_augmented_model,\n",
    "                      X_test=full_augmented_X_test_1,\n",
    "                      categories=categories,\n",
    "                      num_images=5)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 6459626,
     "sourceId": 10421994,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6515574,
     "sourceId": 10528049,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6517995,
     "sourceId": 10534353,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6518043,
     "sourceId": 10534418,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6521965,
     "sourceId": 10544045,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30823,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "02ed56cd303b4f9ea17db04541491b72": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "099554bd6cae42049ebede2b005a8a73": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6dbed1c936834106b7ab3ccb87a8a8ce",
      "placeholder": "​",
      "style": "IPY_MODEL_34410098714046e1a0b8209814f06286",
      "value": " 9/9 [00:43&lt;00:00,  3.10s/it]"
     }
    },
    "1c763d7320124f578f1691f34edf3e88": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_e2ce636360e6433d8d37b5ab701d527d",
       "IPY_MODEL_b3eab0b98f724082b3583f27a7731986",
       "IPY_MODEL_c107294836a84ca591a01fbcba1492c0"
      ],
      "layout": "IPY_MODEL_dfc246e768ec4847aa932e5d30049f5e"
     }
    },
    "1cd4ec1fcd5a4bd69e2155841463e197": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "25d7fcb19e2843409eeb2315c240104e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2910581f3cc445b2a6f765d0e3136fed": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2982c2539fe74290bb3bb6c74e18999f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "34410098714046e1a0b8209814f06286": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4cdf1db74157476d9eb5fcea43c773c1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "62d6cc6e1970489c820b5d582eb814cb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2910581f3cc445b2a6f765d0e3136fed",
      "placeholder": "​",
      "style": "IPY_MODEL_cb116231ccca4714a07c4fcc38a4204f",
      "value": "Processing categories: 100%"
     }
    },
    "6dbed1c936834106b7ab3ccb87a8a8ce": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7253e213036e4df7a03ec703d7bf0a58": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "780b258a02294a37b4d4bace9b2f5b9b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7fe563eb4b6d4822ba6f92e72b0fa6b7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "8e9a51e201634b3bb3499f097f466e9b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_62d6cc6e1970489c820b5d582eb814cb",
       "IPY_MODEL_a74eb9d67e54408e957772ebd3e6df68",
       "IPY_MODEL_099554bd6cae42049ebede2b005a8a73"
      ],
      "layout": "IPY_MODEL_1cd4ec1fcd5a4bd69e2155841463e197"
     }
    },
    "a74eb9d67e54408e957772ebd3e6df68": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_25d7fcb19e2843409eeb2315c240104e",
      "max": 9,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_7fe563eb4b6d4822ba6f92e72b0fa6b7",
      "value": 9
     }
    },
    "a76c1ca71f7a4199844b072c9d670888": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "b3eab0b98f724082b3583f27a7731986": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_02ed56cd303b4f9ea17db04541491b72",
      "max": 9,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_a76c1ca71f7a4199844b072c9d670888",
      "value": 9
     }
    },
    "c107294836a84ca591a01fbcba1492c0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7253e213036e4df7a03ec703d7bf0a58",
      "placeholder": "​",
      "style": "IPY_MODEL_4cdf1db74157476d9eb5fcea43c773c1",
      "value": " 9/9 [00:01&lt;00:00,  4.32it/s]"
     }
    },
    "cb116231ccca4714a07c4fcc38a4204f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "dfc246e768ec4847aa932e5d30049f5e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e2ce636360e6433d8d37b5ab701d527d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_780b258a02294a37b4d4bace9b2f5b9b",
      "placeholder": "​",
      "style": "IPY_MODEL_2982c2539fe74290bb3bb6c74e18999f",
      "value": "Processing categories: 100%"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
