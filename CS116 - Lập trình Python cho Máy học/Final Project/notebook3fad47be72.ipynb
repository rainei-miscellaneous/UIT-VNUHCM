{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d22e3fa7",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-05-12T18:31:44.652847Z",
     "iopub.status.busy": "2024-05-12T18:31:44.652181Z",
     "iopub.status.idle": "2024-05-12T18:31:51.834552Z",
     "shell.execute_reply": "2024-05-12T18:31:51.833739Z"
    },
    "papermill": {
     "duration": 7.193542,
     "end_time": "2024-05-12T18:31:51.836875",
     "exception": false,
     "start_time": "2024-05-12T18:31:44.643333",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import subprocess\n",
    "import os\n",
    "import gc\n",
    "from glob import glob\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "from datetime import datetime\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "ROOT = '/kaggle/input/home-credit-credit-risk-model-stability'\n",
    "\n",
    "from sklearn.model_selection import TimeSeriesSplit, GroupKFold, StratifiedGroupKFold\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin, RegressorMixin\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.impute import KNNImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "faa0cc84",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-12T18:31:51.852350Z",
     "iopub.status.busy": "2024-05-12T18:31:51.851819Z",
     "iopub.status.idle": "2024-05-12T18:31:51.864024Z",
     "shell.execute_reply": "2024-05-12T18:31:51.863196Z"
    },
    "papermill": {
     "duration": 0.022216,
     "end_time": "2024-05-12T18:31:51.866218",
     "exception": false,
     "start_time": "2024-05-12T18:31:51.844002",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Pipeline:\n",
    "\n",
    "    def set_table_dtypes(df):\n",
    "        for col in df.columns:\n",
    "            if col in [\"case_id\", \"WEEK_NUM\", \"num_group1\", \"num_group2\"]:\n",
    "                df = df.with_columns(pl.col(col).cast(pl.Int64))\n",
    "            elif col in [\"date_decision\"]:\n",
    "                df = df.with_columns(pl.col(col).cast(pl.Date))\n",
    "            elif col[-1] in (\"P\", \"A\"):\n",
    "                df = df.with_columns(pl.col(col).cast(pl.Float64))\n",
    "            elif col[-1] in (\"M\",):\n",
    "                df = df.with_columns(pl.col(col).cast(pl.String))\n",
    "            elif col[-1] in (\"D\",):\n",
    "                df = df.with_columns(pl.col(col).cast(pl.Date))\n",
    "        return df\n",
    "\n",
    "    def handle_dates(df):\n",
    "        for col in df.columns:\n",
    "            if col[-1] in (\"D\",):\n",
    "                df = df.with_columns(pl.col(col) - pl.col(\"date_decision\"))  #!!?\n",
    "                df = df.with_columns(pl.col(col).dt.total_days()) # t - t-1\n",
    "        df = df.drop(\"date_decision\", \"MONTH\")\n",
    "        return df\n",
    "\n",
    "    def filter_cols(df):\n",
    "        for col in df.columns:\n",
    "            if col not in [\"target\", \"case_id\", \"WEEK_NUM\"]:\n",
    "                isnull = df[col].is_null().mean()\n",
    "                # Gad changes to 0.95\n",
    "                if isnull > 0.95:\n",
    "                    df = df.drop(col)\n",
    "        \n",
    "        for col in df.columns:\n",
    "            if (col not in [\"target\", \"case_id\", \"WEEK_NUM\"]) & (df[col].dtype == pl.String):\n",
    "                freq = df[col].n_unique()\n",
    "                if (freq == 1) | (freq > 200):\n",
    "                    df = df.drop(col)\n",
    "        \n",
    "        return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de499b1a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-12T18:31:51.881176Z",
     "iopub.status.busy": "2024-05-12T18:31:51.880395Z",
     "iopub.status.idle": "2024-05-12T18:31:51.898146Z",
     "shell.execute_reply": "2024-05-12T18:31:51.897208Z"
    },
    "papermill": {
     "duration": 0.027403,
     "end_time": "2024-05-12T18:31:51.900218",
     "exception": false,
     "start_time": "2024-05-12T18:31:51.872815",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "class Aggregator:\n",
    "    #Please add or subtract features yourself, be aware that too many features will take up too much space.\n",
    "    def num_expr(df):\n",
    "        cols = [col for col in df.columns if col[-1] in (\"P\", \"A\")]\n",
    "        expr_max = [pl.max(col).alias(f\"max_{col}\") for col in cols]\n",
    "        \n",
    "        expr_last = [pl.last(col).alias(f\"last_{col}\") for col in cols]\n",
    "        #expr_first = [pl.first(col).alias(f\"first_{col}\") for col in cols]\n",
    "        expr_mean = [pl.mean(col).alias(f\"mean_{col}\") for col in cols]\n",
    "        return expr_max +expr_last+expr_mean\n",
    "    \n",
    "    def date_expr(df):\n",
    "        cols = [col for col in df.columns if col[-1] in (\"D\")]\n",
    "        expr_max = [pl.max(col).alias(f\"max_{col}\") for col in cols]\n",
    "        #expr_min = [pl.min(col).alias(f\"min_{col}\") for col in cols]\n",
    "        expr_last = [pl.last(col).alias(f\"last_{col}\") for col in cols]\n",
    "        #expr_first = [pl.first(col).alias(f\"first_{col}\") for col in cols]\n",
    "        expr_mean = [pl.mean(col).alias(f\"mean_{col}\") for col in cols]\n",
    "        return  expr_max +expr_last+expr_mean\n",
    "    \n",
    "    def str_expr(df):\n",
    "        cols = [col for col in df.columns if col[-1] in (\"M\",)]\n",
    "        expr_max = [pl.max(col).alias(f\"max_{col}\") for col in cols]\n",
    "        #expr_min = [pl.min(col).alias(f\"min_{col}\") for col in cols]\n",
    "        expr_last = [pl.last(col).alias(f\"last_{col}\") for col in cols]\n",
    "        #expr_first = [pl.first(col).alias(f\"first_{col}\") for col in cols]\n",
    "        #expr_count = [pl.count(col).alias(f\"count_{col}\") for col in cols]\n",
    "        return  expr_max +expr_last#+expr_count\n",
    "    \n",
    "    def other_expr(df):\n",
    "        cols = [col for col in df.columns if col[-1] in (\"T\", \"L\")]\n",
    "        expr_max = [pl.max(col).alias(f\"max_{col}\") for col in cols]\n",
    "        #expr_min = [pl.min(col).alias(f\"min_{col}\") for col in cols]\n",
    "        expr_last = [pl.last(col).alias(f\"last_{col}\") for col in cols]\n",
    "        #expr_first = [pl.first(col).alias(f\"first_{col}\") for col in cols]\n",
    "        return  expr_max +expr_last\n",
    "    \n",
    "    def count_expr(df):\n",
    "        cols = [col for col in df.columns if \"num_group\" in col]\n",
    "        expr_max = [pl.max(col).alias(f\"max_{col}\") for col in cols] \n",
    "        #expr_min = [pl.min(col).alias(f\"min_{col}\") for col in cols]\n",
    "        expr_last = [pl.last(col).alias(f\"last_{col}\") for col in cols]\n",
    "        #expr_first = [pl.first(col).alias(f\"first_{col}\") for col in cols]\n",
    "        return  expr_max +expr_last\n",
    "    \n",
    "    def get_exprs(df):\n",
    "        exprs = Aggregator.num_expr(df) + \\\n",
    "                Aggregator.date_expr(df) + \\\n",
    "                Aggregator.str_expr(df) + \\\n",
    "                Aggregator.other_expr(df) + \\\n",
    "                Aggregator.count_expr(df)\n",
    "\n",
    "        return exprs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b820ffc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-12T18:31:51.917627Z",
     "iopub.status.busy": "2024-05-12T18:31:51.916725Z",
     "iopub.status.idle": "2024-05-12T18:31:51.927018Z",
     "shell.execute_reply": "2024-05-12T18:31:51.926363Z"
    },
    "papermill": {
     "duration": 0.020898,
     "end_time": "2024-05-12T18:31:51.928791",
     "exception": false,
     "start_time": "2024-05-12T18:31:51.907893",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def read_file(path, depth=None):\n",
    "    df = pl.read_parquet(path)\n",
    "    df = df.pipe(Pipeline.set_table_dtypes)\n",
    "    if depth in [1,2]:\n",
    "        df = df.group_by(\"case_id\").agg(Aggregator.get_exprs(df)) \n",
    "    return df\n",
    "\n",
    "def read_files(regex_path, depth=None):\n",
    "    chunks = []\n",
    "    \n",
    "    for path in glob(str(regex_path)):\n",
    "        df = pl.read_parquet(path)\n",
    "        df = df.pipe(Pipeline.set_table_dtypes)\n",
    "        if depth in [1, 2]:\n",
    "            df = df.group_by(\"case_id\").agg(Aggregator.get_exprs(df))\n",
    "        chunks.append(df)\n",
    "    \n",
    "    df = pl.concat(chunks, how=\"vertical_relaxed\")\n",
    "    df = df.unique(subset=[\"case_id\"])\n",
    "    return df\n",
    "\n",
    "def feature_eng(df_base, depth_0, depth_1, depth_2):\n",
    "    df_base = (\n",
    "        df_base\n",
    "        .with_columns(\n",
    "            month_decision = pl.col(\"date_decision\").dt.month(),\n",
    "            weekday_decision = pl.col(\"date_decision\").dt.weekday(),\n",
    "        )\n",
    "    )\n",
    "    for i, df in enumerate(depth_0 + depth_1 + depth_2):\n",
    "        df_base = df_base.join(df, how=\"left\", on=\"case_id\", suffix=f\"_{i}\")\n",
    "    df_base = df_base.pipe(Pipeline.handle_dates)\n",
    "    return df_base\n",
    "\n",
    "def to_pandas(df_data, cat_cols=None):\n",
    "    df_data = df_data.to_pandas()\n",
    "    if cat_cols is None:\n",
    "        cat_cols = list(df_data.select_dtypes(\"object\").columns)\n",
    "    df_data[cat_cols] = df_data[cat_cols].astype(\"category\")\n",
    "    return df_data, cat_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "33e57a71",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-12T18:31:51.943541Z",
     "iopub.status.busy": "2024-05-12T18:31:51.943280Z",
     "iopub.status.idle": "2024-05-12T18:31:51.955248Z",
     "shell.execute_reply": "2024-05-12T18:31:51.954441Z"
    },
    "papermill": {
     "duration": 0.021165,
     "end_time": "2024-05-12T18:31:51.957018",
     "exception": false,
     "start_time": "2024-05-12T18:31:51.935853",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def reduce_mem_usage(df):\n",
    "    \"\"\" iterate through all the columns of a dataframe and modify the data type\n",
    "        to reduce memory usage.        \n",
    "    \"\"\"\n",
    "    start_mem = df.memory_usage().sum() / 1024**2\n",
    "    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n",
    "    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtype\n",
    "        if str(col_type)==\"category\":\n",
    "            continue\n",
    "        \n",
    "        if col_type != object:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "        else:\n",
    "            continue\n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n",
    "    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fed84012",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-12T18:31:51.971088Z",
     "iopub.status.busy": "2024-05-12T18:31:51.970853Z",
     "iopub.status.idle": "2024-05-12T18:31:51.974867Z",
     "shell.execute_reply": "2024-05-12T18:31:51.974047Z"
    },
    "papermill": {
     "duration": 0.013207,
     "end_time": "2024-05-12T18:31:51.976702",
     "exception": false,
     "start_time": "2024-05-12T18:31:51.963495",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ROOT            = Path(\"/kaggle/input/home-credit-credit-risk-model-stability\")\n",
    "\n",
    "TRAIN_DIR       = ROOT / \"parquet_files\" / \"train\"\n",
    "TEST_DIR        = ROOT / \"parquet_files\" / \"test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "052ed187",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-12T18:18:08.133165Z",
     "iopub.status.busy": "2024-05-12T18:18:08.132886Z",
     "iopub.status.idle": "2024-05-12T18:20:24.811036Z",
     "shell.execute_reply": "2024-05-12T18:20:24.810049Z",
     "shell.execute_reply.started": "2024-05-12T18:18:08.133142Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": false,
     "start_time": "2024-05-12T18:31:51.983414",
     "status": "running"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "data_store = {\n",
    "    \"df_base\": read_file(TRAIN_DIR / \"train_base.parquet\"),\n",
    "    \"depth_0\": [\n",
    "        read_file(TRAIN_DIR / \"train_static_cb_0.parquet\"),\n",
    "        read_files(TRAIN_DIR / \"train_static_0_*.parquet\"),\n",
    "    ],\n",
    "    \"depth_1\": [\n",
    "        read_files(TRAIN_DIR / \"train_applprev_1_*.parquet\", 1),\n",
    "        read_file(TRAIN_DIR / \"train_tax_registry_a_1.parquet\", 1),\n",
    "        read_file(TRAIN_DIR / \"train_tax_registry_b_1.parquet\", 1),\n",
    "        read_file(TRAIN_DIR / \"train_tax_registry_c_1.parquet\", 1),\n",
    "        read_files(TRAIN_DIR / \"train_credit_bureau_a_1_*.parquet\", 1),\n",
    "        read_file(TRAIN_DIR / \"train_credit_bureau_b_1.parquet\", 1),\n",
    "        read_file(TRAIN_DIR / \"train_other_1.parquet\", 1),\n",
    "        read_file(TRAIN_DIR / \"train_person_1.parquet\", 1),\n",
    "        read_file(TRAIN_DIR / \"train_deposit_1.parquet\", 1),\n",
    "        read_file(TRAIN_DIR / \"train_debitcard_1.parquet\", 1),\n",
    "    ],\n",
    "    \"depth_2\": [\n",
    "        read_file(TRAIN_DIR / \"train_credit_bureau_b_2.parquet\", 2),\n",
    "        read_files(TRAIN_DIR / \"train_credit_bureau_a_2_*.parquet\", 2),\n",
    "        read_file(TRAIN_DIR / \"train_applprev_2.parquet\", 2),\n",
    "        read_file(TRAIN_DIR / \"train_person_2.parquet\", 2)\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d6c802c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-12T18:20:24.813975Z",
     "iopub.status.busy": "2024-05-12T18:20:24.813560Z",
     "iopub.status.idle": "2024-05-12T18:22:11.423955Z",
     "shell.execute_reply": "2024-05-12T18:22:11.423040Z",
     "shell.execute_reply.started": "2024-05-12T18:20:24.813935Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "df_train = feature_eng(**data_store)\n",
    "print(\"train data shape:\\t\", df_train.shape)\n",
    "del data_store\n",
    "gc.collect()\n",
    "df_train = df_train.pipe(Pipeline.filter_cols)\n",
    "df_train, cat_cols = to_pandas(df_train)\n",
    "df_train = reduce_mem_usage(df_train)\n",
    "print(\"train data shape:\\t\", df_train.shape)\n",
    "nums=df_train.select_dtypes(exclude='category').columns\n",
    "\n",
    "from itertools import combinations, permutations\n",
    "#df_train=df_train[nums]\n",
    "nans_df = df_train[nums].isna()\n",
    "nans_groups={}\n",
    "for col in nums:\n",
    "    cur_group = nans_df[col].sum()\n",
    "    try:\n",
    "        nans_groups[cur_group].append(col)\n",
    "    except:\n",
    "        nans_groups[cur_group]=[col]\n",
    "del nans_df; x=gc.collect()\n",
    "\n",
    "def reduce_group(grps):\n",
    "    use = []\n",
    "    for g in grps:\n",
    "        mx = 0; vx = g[0]\n",
    "        for gg in g:\n",
    "            n = df_train[gg].nunique()\n",
    "            if n>mx:\n",
    "                mx = n\n",
    "                vx = gg\n",
    "            #print(str(gg)+'-'+str(n),', ',end='')\n",
    "        use.append(vx)\n",
    "        #print()\n",
    "    print('Use these',use)\n",
    "    return use\n",
    "\n",
    "def group_columns_by_correlation(matrix, threshold=0.8):\n",
    "    # 计算列之间的相关性\n",
    "    correlation_matrix = matrix.corr()\n",
    "\n",
    "    # 分组列\n",
    "    groups = []\n",
    "    remaining_cols = list(matrix.columns)\n",
    "    while remaining_cols:\n",
    "        col = remaining_cols.pop(0)\n",
    "        group = [col]\n",
    "        correlated_cols = [col]\n",
    "        for c in remaining_cols:\n",
    "            if correlation_matrix.loc[col, c] >= threshold:\n",
    "                group.append(c)\n",
    "                correlated_cols.append(c)\n",
    "        groups.append(group)\n",
    "        remaining_cols = [c for c in remaining_cols if c not in correlated_cols]\n",
    "    \n",
    "    return groups\n",
    "\n",
    "uses=[]\n",
    "for k,v in nans_groups.items():\n",
    "    if len(v)>1:\n",
    "            Vs = nans_groups[k]\n",
    "            #cross_features=list(combinations(Vs, 2))\n",
    "            #make_corr(Vs)\n",
    "            grps= group_columns_by_correlation(df_train[Vs], threshold=0.8)\n",
    "            use=reduce_group(grps)\n",
    "            uses=uses+use\n",
    "            #make_corr(use)\n",
    "    else:\n",
    "        uses=uses+v\n",
    "    print('####### NAN count =',k)\n",
    "print(uses)\n",
    "print(len(uses))\n",
    "uses=uses+list(df_train.select_dtypes(include='category').columns)\n",
    "print(len(uses))\n",
    "df_train=df_train[uses]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c764f621",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-12T18:22:11.425729Z",
     "iopub.status.busy": "2024-05-12T18:22:11.425343Z",
     "iopub.status.idle": "2024-05-12T18:22:11.441049Z",
     "shell.execute_reply": "2024-05-12T18:22:11.440191Z",
     "shell.execute_reply.started": "2024-05-12T18:22:11.425696Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sample = pd.read_csv(\"/kaggle/input/home-credit-credit-risk-model-stability/sample_submission.csv\")\n",
    "device='gpu'\n",
    "#n_samples=200000\n",
    "n_est=6000\n",
    "DRY_RUN = True if sample.shape[0] == 10 else False   \n",
    "if DRY_RUN:\n",
    "    device='cpu'\n",
    "    df_train = df_train.iloc[:50000]\n",
    "    #n_samples=10000\n",
    "    n_est=600\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2005c7ac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-12T18:22:11.444345Z",
     "iopub.status.busy": "2024-05-12T18:22:11.444072Z",
     "iopub.status.idle": "2024-05-12T18:22:11.757274Z",
     "shell.execute_reply": "2024-05-12T18:22:11.756175Z",
     "shell.execute_reply.started": "2024-05-12T18:22:11.444322Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_store = {\n",
    "    \"df_base\": read_file(TEST_DIR / \"test_base.parquet\"),\n",
    "    \"depth_0\": [\n",
    "        read_file(TEST_DIR / \"test_static_cb_0.parquet\"),\n",
    "        read_files(TEST_DIR / \"test_static_0_*.parquet\"),\n",
    "    ],\n",
    "    \"depth_1\": [\n",
    "        read_files(TEST_DIR / \"test_applprev_1_*.parquet\", 1),\n",
    "        read_file(TEST_DIR / \"test_tax_registry_a_1.parquet\", 1),\n",
    "        read_file(TEST_DIR / \"test_tax_registry_b_1.parquet\", 1),\n",
    "        read_file(TEST_DIR / \"test_tax_registry_c_1.parquet\", 1),\n",
    "        read_files(TEST_DIR / \"test_credit_bureau_a_1_*.parquet\", 1),\n",
    "        read_file(TEST_DIR / \"test_credit_bureau_b_1.parquet\", 1),\n",
    "        read_file(TEST_DIR / \"test_other_1.parquet\", 1),\n",
    "        read_file(TEST_DIR / \"test_person_1.parquet\", 1),\n",
    "        read_file(TEST_DIR / \"test_deposit_1.parquet\", 1),\n",
    "        read_file(TEST_DIR / \"test_debitcard_1.parquet\", 1),\n",
    "    ],\n",
    "    \"depth_2\": [\n",
    "        read_file(TEST_DIR / \"test_credit_bureau_b_2.parquet\", 2),\n",
    "        read_files(TEST_DIR / \"test_credit_bureau_a_2_*.parquet\", 2),\n",
    "        read_file(TEST_DIR / \"test_applprev_2.parquet\", 2),\n",
    "        read_file(TEST_DIR / \"test_person_2.parquet\", 2)\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da2be2d5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-12T18:22:11.759351Z",
     "iopub.status.busy": "2024-05-12T18:22:11.758722Z",
     "iopub.status.idle": "2024-05-12T18:22:12.307307Z",
     "shell.execute_reply": "2024-05-12T18:22:12.306403Z",
     "shell.execute_reply.started": "2024-05-12T18:22:11.759318Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_test = feature_eng(**data_store)\n",
    "print(\"test data shape:\\t\", df_test.shape)\n",
    "del data_store\n",
    "gc.collect()\n",
    "df_test = df_test.select([col for col in df_train.columns if col != \"target\"])\n",
    "print(\"train data shape:\\t\", df_train.shape)\n",
    "print(\"test data shape:\\t\", df_test.shape)\n",
    "\n",
    "df_test, cat_cols = to_pandas(df_test, cat_cols)\n",
    "df_test = reduce_mem_usage(df_test)\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c1552b",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e57e445b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-12T18:22:12.308718Z",
     "iopub.status.busy": "2024-05-12T18:22:12.308456Z",
     "iopub.status.idle": "2024-05-12T18:22:12.463205Z",
     "shell.execute_reply": "2024-05-12T18:22:12.462128Z",
     "shell.execute_reply.started": "2024-05-12T18:22:12.308696Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "y = df_train[\"target\"]\n",
    "weeks = df_train[\"WEEK_NUM\"]\n",
    "df_train= df_train.drop(columns=[\"target\", \"case_id\"])\n",
    "cv = StratifiedGroupKFold(n_splits=6, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f9d05b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-12T18:22:12.464603Z",
     "iopub.status.busy": "2024-05-12T18:22:12.464332Z",
     "iopub.status.idle": "2024-05-12T18:22:12.774804Z",
     "shell.execute_reply": "2024-05-12T18:22:12.773775Z",
     "shell.execute_reply.started": "2024-05-12T18:22:12.464582Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_train[cat_cols] = df_train[cat_cols].astype(str)\n",
    "df_test[cat_cols] = df_test[cat_cols].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c2b131",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-12T18:22:12.776581Z",
     "iopub.status.busy": "2024-05-12T18:22:12.776172Z",
     "iopub.status.idle": "2024-05-12T18:22:12.783123Z",
     "shell.execute_reply": "2024-05-12T18:22:12.782105Z",
     "shell.execute_reply.started": "2024-05-12T18:22:12.776549Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"boosting_type\": \"gbdt\",\n",
    "    \"objective\": \"binary\",\n",
    "    \"metric\": \"auc\",\n",
    "    \"max_depth\": 10,  \n",
    "    \"learning_rate\": 0.05,\n",
    "    \"n_estimators\": 2000,  \n",
    "    \"colsample_bytree\": 0.8,\n",
    "    \"colsample_bynode\": 0.8,\n",
    "    \"random_state\": 42,\n",
    "    \"reg_alpha\": 0.1,\n",
    "    \"reg_lambda\": 10,\n",
    "    \"extra_trees\":True,\n",
    "    'num_leaves':64,\n",
    "    \"device\": device, \n",
    "    \"verbose\": -1,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba67c2c",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "fitted_models_cat = []\n",
    "fitted_models_lgb = []\n",
    "\n",
    "cv_scores_cat = []\n",
    "cv_scores_lgb = []\n",
    "\n",
    "\n",
    "for idx_train, idx_valid in cv.split(df_train, y, groups=weeks):#\n",
    "    X_train, y_train = df_train.iloc[idx_train], y.iloc[idx_train]# \n",
    "    X_valid, y_valid = df_train.iloc[idx_valid], y.iloc[idx_valid]\n",
    "    train_pool = Pool(X_train, y_train,cat_features=cat_cols)\n",
    "    val_pool = Pool(X_valid, y_valid,cat_features=cat_cols)\n",
    "    \n",
    "    clf = CatBoostClassifier(\n",
    "    eval_metric='AUC',\n",
    "    task_type='GPU',\n",
    "    learning_rate=0.03,\n",
    "    iterations=n_est)\n",
    "    random_seed=3107\n",
    "    \n",
    "    clf.fit(train_pool, eval_set=val_pool,verbose=300)\n",
    "    fitted_models_cat.append(clf)\n",
    "    y_pred_valid = clf.predict_proba(X_valid)[:,1]\n",
    "    auc_score = roc_auc_score(y_valid, y_pred_valid)\n",
    "    cv_scores_cat.append(auc_score)\n",
    "    \n",
    "    X_train[cat_cols] = X_train[cat_cols].astype(\"category\")\n",
    "    X_valid[cat_cols] = X_valid[cat_cols].astype(\"category\")\n",
    "    \n",
    "    model = lgb.LGBMClassifier(**params)\n",
    "    model.fit(\n",
    "        X_train, y_train,\n",
    "        eval_set = [(X_valid, y_valid)],\n",
    "        callbacks = [lgb.log_evaluation(200), lgb.early_stopping(100)] )\n",
    "    \n",
    "    fitted_models_lgb.append(model)\n",
    "    y_pred_valid = model.predict_proba(X_valid)[:,1]\n",
    "    auc_score = roc_auc_score(y_valid, y_pred_valid)\n",
    "    cv_scores_lgb.append(auc_score)\n",
    "    \n",
    "    \n",
    "print(\"CV AUC scores: \", cv_scores_cat)\n",
    "print(\"Maximum CV AUC score: \", max(cv_scores_cat))\n",
    "\n",
    "\n",
    "print(\"CV AUC scores: \", cv_scores_lgb)\n",
    "print(\"Maximum CV AUC score: \", max(cv_scores_lgb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e21098",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-12T18:30:17.175957Z",
     "iopub.status.busy": "2024-05-12T18:30:17.175651Z",
     "iopub.status.idle": "2024-05-12T18:30:17.184791Z",
     "shell.execute_reply": "2024-05-12T18:30:17.183872Z",
     "shell.execute_reply.started": "2024-05-12T18:30:17.175931Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class VotingModel(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, estimators):\n",
    "        super().__init__()\n",
    "        self.estimators = estimators\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        y_preds = [estimator.predict(X) for estimator in self.estimators]\n",
    "        return np.mean(y_preds, axis=0)\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        \n",
    "        y_preds = [estimator.predict_proba(X) for estimator in self.estimators[:5]]\n",
    "        \n",
    "        X[cat_cols] = X[cat_cols].astype(\"category\")\n",
    "        y_preds += [estimator.predict_proba(X) for estimator in self.estimators[5:]]\n",
    "        \n",
    "        return np.mean(y_preds, axis=0)\n",
    "\n",
    "model = VotingModel(fitted_models_cat+fitted_models_lgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee523e2f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-12T18:30:17.186715Z",
     "iopub.status.busy": "2024-05-12T18:30:17.186233Z",
     "iopub.status.idle": "2024-05-12T18:30:17.204759Z",
     "shell.execute_reply": "2024-05-12T18:30:17.203805Z",
     "shell.execute_reply.started": "2024-05-12T18:30:17.186684Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from sklearn.metrics import roc_auc_score\n",
    "# def gini_stability(base, w_fallingrate=88.0, w_resstd=-0.5):\n",
    "#     gini_in_time = base.loc[:, [\"WEEK_NUM\", \"target\", \"score\"]]\\\n",
    "#         .sort_values(\"WEEK_NUM\")\\\n",
    "#         .groupby(\"WEEK_NUM\")[[\"target\", \"score\"]]\\\n",
    "#         .apply(lambda x: 2*roc_auc_score(x[\"target\"], x[\"score\"])-1).tolist()\n",
    "    \n",
    "#     x = np.arange(len(gini_in_time))\n",
    "#     y = gini_in_time\n",
    "#     a, b = np.polyfit(x, y, 1)\n",
    "#     y_hat = a*x + b\n",
    "#     residuals = y - y_hat\n",
    "#     res_std = np.std(residuals)\n",
    "#     avg_gini = np.mean(gini_in_time)\n",
    "#     return avg_gini + w_fallingrate * min(0, a) + w_resstd * res_std\n",
    "\n",
    "# def stratified_sample(df, week_num_col='WEEK_NUM', target_col='target', n_samples=1000):\n",
    "#     \"\"\"\n",
    "#     Perform stratified sampling to ensure each combination of week number and target is represented.\n",
    "    \n",
    "#     Parameters:\n",
    "#     - df: pandas DataFrame containing the data.\n",
    "#     - week_num_col: Name of the column containing week numbers.\n",
    "#     - target_col: Name of the column containing target values.\n",
    "#     - n_samples: Total number of samples to return.\n",
    "    \n",
    "#     Returns:\n",
    "#     - A sampled pandas DataFrame with n_samples (if possible) ensuring representation of each group.\n",
    "#     \"\"\"\n",
    "    \n",
    "#     samples_per_group = max(1, n_samples // df.groupby([week_num_col, target_col]).ngroups)\n",
    "    \n",
    "#     sampled_df = df.groupby([week_num_col, target_col]).apply(\n",
    "#         lambda x: x.sample(n=min(samples_per_group, len(x)), replace=True if len(x) < samples_per_group else False)\n",
    "#     ).reset_index(drop=True)\n",
    "    \n",
    "#     if len(sampled_df) < n_samples:\n",
    "#         additional_samples = n_samples - len(sampled_df)\n",
    "#         additional_sampled_df = df.sample(n=additional_samples, replace=True)\n",
    "#         sampled_df = pd.concat([sampled_df, additional_sampled_df], ignore_index=True)\n",
    "    \n",
    "#     return sampled_df\n",
    "\n",
    "# class WeightedVotingModel(BaseEstimator, ClassifierMixin):\n",
    "#     def __init__(self, estimators, num_iters=100, scale=0.1):\n",
    "#         super().__init__()\n",
    "#         self.estimators = estimators\n",
    "#         self.weights = np.ones(len(self.estimators)) / len(self.estimators)\n",
    "        \n",
    "#         self.num_iters = num_iters\n",
    "#         self.scale = scale\n",
    "        \n",
    "#     def fit(self, X, y=None):\n",
    "        \n",
    "#         X[\"score\"] = self.predict_proba(X.drop(columns=[\"target\", \"WEEK_NUM\"]))[:, 1]\n",
    "#         last_gini = gini_stability(X)\n",
    "        \n",
    "#         for itr in range(self.num_iters):\n",
    "#             idx = np.random.randint(len(self.estimators))\n",
    "            \n",
    "#             new_weights = self.weights\n",
    "            \n",
    "#             # choose weight to change\n",
    "#             delta = np.random.normal(loc=0.0, scale=self.scale)\n",
    "#             if new_weights[idx] + delta >= 0:\n",
    "#                 new_weights[idx] += delta\n",
    "#             new_weights = new_weights / new_weights.sum()\n",
    "            \n",
    "#             old_weights = self.weights\n",
    "#             self.weights = new_weights\n",
    "            \n",
    "#             # compute new gini score\n",
    "#             X[\"score\"] = self.predict_proba(X.drop(columns=[\"target\",  \"WEEK_NUM\", \"score\"]))[:, 1]\n",
    "#             new_gini = gini_stability(X)\n",
    "            \n",
    "#             print(f\"Iteration {itr + 1}/{self.num_iters} || last_gini: {last_gini:.5f} || new_gini: {new_gini:.5f}\")\n",
    "            \n",
    "#             # choose to update the weights or not\n",
    "#             if new_gini < last_gini:\n",
    "#                 # return old weights because old gini was better\n",
    "#                 self.weights = old_weights\n",
    "#             else:\n",
    "#                 # accept new weights and change current gini\n",
    "#                 last_gini = new_gini\n",
    "            \n",
    "#         return self\n",
    "    \n",
    "#     def predict(self, X):\n",
    "#         y_preds = [estimator.predict(X) for estimator in self.estimators]\n",
    "#         return np.sum(y_preds * self.weights[:, None], axis=0)\n",
    "    \n",
    "#     def predict_proba(self, X):\n",
    "#         y_preds = [estimator.predict_proba(X) for estimator in self.estimators]\n",
    "#         #print(self.weights[:, None, None])\n",
    "#         return np.sum(y_preds * self.weights[:, None, None], axis=0)\n",
    "\n",
    "# weighted_model = WeightedVotingModel(fitted_models_cat+fitted_models_lgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a4ee61",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-12T18:30:17.206030Z",
     "iopub.status.busy": "2024-05-12T18:30:17.205740Z",
     "iopub.status.idle": "2024-05-12T18:30:17.218996Z",
     "shell.execute_reply": "2024-05-12T18:30:17.218214Z",
     "shell.execute_reply.started": "2024-05-12T18:30:17.206003Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# dt=pd.DataFrame()\n",
    "# dt[\"target\"]=y\n",
    "# dt[\"WEEK_NUM\"]=weeks\n",
    "# dt=dt.groupby(\"WEEK_NUM\").sum()\n",
    "# todrop=list(dt[dt['target']==0] .index)\n",
    "# for week in todrop:\n",
    "#     df_train = df_train[weeks!=week]\n",
    "#     y = y[weeks!=week]\n",
    "#     weeks = weeks[weeks!=week]\n",
    "# df_train[\"target\"]=y\n",
    "# df_train[\"WEEK_NUM\"]=weeks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef0c47a7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-12T18:30:17.220449Z",
     "iopub.status.busy": "2024-05-12T18:30:17.220108Z",
     "iopub.status.idle": "2024-05-12T18:30:17.228050Z",
     "shell.execute_reply": "2024-05-12T18:30:17.227256Z",
     "shell.execute_reply.started": "2024-05-12T18:30:17.220410Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# df_almost_val = stratified_sample(df_train, n_samples=n_samples)\n",
    "# weighted_model.fit(df_almost_val)\n",
    "# weighted_model.weights\n",
    "# small_train = stratified_sample(df_train, n_samples=n_samples)\n",
    "\n",
    "# small_train['score'] = weighted_model.predict_proba(small_train.drop(columns=[\"target\", \"WEEK_NUM\"]))[:, 1]\n",
    "# print(f\"n_samples: {n_samples} || gini_stability: {gini_stability(small_train)}\")\n",
    "# df_test = df_test.drop(columns=[\"WEEK_NUM\"])\n",
    "# df_test = df_test.set_index(\"case_id\")\n",
    "# y_pred = pd.Series(weighted_model.predict_proba(df_test)[:, 1], index=df_test.index)\n",
    "# df_subm = pd.read_csv(ROOT / \"sample_submission.csv\")\n",
    "# df_subm = df_subm.set_index(\"case_id\")\n",
    "\n",
    "# df_subm[\"score\"] = y_pred\n",
    "# df_subm.to_csv(\"submission.csv\")\n",
    "# df_subm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e87469ed",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# Submision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba59b490",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-12T18:30:17.229506Z",
     "iopub.status.busy": "2024-05-12T18:30:17.229151Z",
     "iopub.status.idle": "2024-05-12T18:30:18.125642Z",
     "shell.execute_reply": "2024-05-12T18:30:18.124649Z",
     "shell.execute_reply.started": "2024-05-12T18:30:17.229474Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_test = df_test.set_index(\"case_id\")\n",
    "\n",
    "\n",
    "y_pred = pd.Series(model.predict_proba(df_test)[:, 1], index=df_test.index)\n",
    "df_subm = pd.read_csv(ROOT / \"sample_submission.csv\")\n",
    "df_subm = df_subm.set_index(\"case_id\")\n",
    "\n",
    "df_subm[\"score\"] = y_pred\n",
    "df_subm.to_csv(\"submission.csv\")\n",
    "df_subm"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 7921029,
     "sourceId": 50160,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30699,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": null,
   "end_time": null,
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-05-12T18:31:41.634872",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}