{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf7e209a-3772-4e3c-a097-6783f98f8898",
   "metadata": {
    "executionInfo": {
     "elapsed": 9856,
     "status": "ok",
     "timestamp": 1727769190623,
     "user": {
      "displayName": "Trường Trương Quốc",
      "userId": "17805586224290040159"
     },
     "user_tz": -420
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers , activations , models , preprocessing , utils\n",
    "import pandas as pd\n",
    "from keras.models import load_model, Model\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import os\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import collections\n",
    "import math\n",
    "import string\n",
    "\n",
    "def fix_random_seed(seed_value = 42):\n",
    "    np.random.seed(seed_value)\n",
    "    random.seed(seed_value)\n",
    "    tf.random.set_seed(seed_value)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bec6966-fcae-48e7-913c-f5b80721fed0",
   "metadata": {},
   "source": [
    "## Chuẩn bị dữ liệu và cấu hình"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d60ddc7-443f-4a7d-8eb6-f2cf84c85a34",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 492
    },
    "executionInfo": {
     "elapsed": 58206,
     "status": "ok",
     "timestamp": 1727769252864,
     "user": {
      "displayName": "Trường Trương Quốc",
      "userId": "17805586224290040159"
     },
     "user_tz": -420
    },
    "outputId": "668d117d-0802-4291-c505-1226b28b8d1f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-10-01 07:53:14--  http://www.manythings.org/anki/vie-eng.zip\n",
      "Resolving www.manythings.org (www.manythings.org)... 173.254.30.110\n",
      "Connecting to www.manythings.org (www.manythings.org)|173.254.30.110|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 381617 (373K) [application/zip]\n",
      "Saving to: ‘vie-eng.zip’\n",
      "\n",
      "vie-eng.zip         100%[===================>] 372.67K  1.34MB/s    in 0.3s    \n",
      "\n",
      "2024-10-01 07:53:14 (1.34 MB/s) - ‘vie-eng.zip’ saved [381617/381617]\n",
      "\n",
      "Archive:  vie-eng.zip\n",
      "replace _about.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
      "  inflating: _about.txt              \n",
      "replace vie.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
      "  inflating: vie.txt                 \n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "summary": "{\n  \"name\": \"lines\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"eng\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"Who's your favorite movie star?\",\n          \"Why aren't you in your uniform?\",\n          \"Will he be coming this evening?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"vie\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"Ng\\u00f4i sao \\u0111i\\u1ec7n \\u1ea3nh m\\u00e0 b\\u1ea1n y\\u00eau th\\u00edch l\\u00e0 ai v\\u1eady?\",\n          \"T\\u1ed1i nay \\u00f4ng \\u1ea5y c\\u00f3 \\u0111\\u1ebfn kh\\u00f4ng?\",\n          \"T\\u1ea1i sao b\\u1ea1n kh\\u00f4ng m\\u1eb7c \\u0111\\u1ed3ng ph\\u1ee5c?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
       "type": "dataframe"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-faf74a7a-ddbf-4234-ba90-9f132daf9e44\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eng</th>\n",
       "      <th>vie</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>Who's your favorite movie star?</td>\n",
       "      <td>Ngôi sao điện ảnh mà bạn yêu thích là ai thế?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>Who's your favorite movie star?</td>\n",
       "      <td>Ngôi sao điện ảnh mà bạn yêu thích là ai vậy?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>Why aren't you in your uniform?</td>\n",
       "      <td>Tại sao bạn không mặc đồng phục?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>Will he be coming this evening?</td>\n",
       "      <td>Tối nay anh ấy có đến không?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>Will he be coming this evening?</td>\n",
       "      <td>Tối nay ông ấy có đến không?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-faf74a7a-ddbf-4234-ba90-9f132daf9e44')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-faf74a7a-ddbf-4234-ba90-9f132daf9e44 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-faf74a7a-ddbf-4234-ba90-9f132daf9e44');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "<div id=\"df-62e6fb04-1df0-402c-93eb-2a01879e5661\">\n",
       "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-62e6fb04-1df0-402c-93eb-2a01879e5661')\"\n",
       "            title=\"Suggest charts\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "  </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "  <script>\n",
       "    async function quickchart(key) {\n",
       "      const quickchartButtonEl =\n",
       "        document.querySelector('#' + key + ' button');\n",
       "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "      try {\n",
       "        const charts = await google.colab.kernel.invokeFunction(\n",
       "            'suggestCharts', [key], {});\n",
       "      } catch (error) {\n",
       "        console.error('Error during call to suggestCharts:', error);\n",
       "      }\n",
       "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "    }\n",
       "    (() => {\n",
       "      let quickchartButtonEl =\n",
       "        document.querySelector('#df-62e6fb04-1df0-402c-93eb-2a01879e5661 button');\n",
       "      quickchartButtonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "    })();\n",
       "  </script>\n",
       "</div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "                                  eng  \\\n",
       "4995  Who's your favorite movie star?   \n",
       "4996  Who's your favorite movie star?   \n",
       "4997  Why aren't you in your uniform?   \n",
       "4998  Will he be coming this evening?   \n",
       "4999  Will he be coming this evening?   \n",
       "\n",
       "                                                vie  \n",
       "4995  Ngôi sao điện ảnh mà bạn yêu thích là ai thế?  \n",
       "4996  Ngôi sao điện ảnh mà bạn yêu thích là ai vậy?  \n",
       "4997               Tại sao bạn không mặc đồng phục?  \n",
       "4998                   Tối nay anh ấy có đến không?  \n",
       "4999                   Tối nay ông ấy có đến không?  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!wget http://www.manythings.org/anki/vie-eng.zip -O vie-eng.zip\n",
    "#!unzip vie-eng.zip\n",
    "\n",
    "lines = None\n",
    "data_path = './data/vie.txt'\n",
    "lines = pd.read_table(data_path, names=['eng' , 'vie' , 'c' ] )\n",
    "lines = lines.drop(['c'] , axis=1 )[0:5000]\n",
    "lines.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0551827c-bcdc-43e3-a717-7f13d5a60bba",
   "metadata": {
    "executionInfo": {
     "elapsed": 457,
     "status": "ok",
     "timestamp": 1727769264348,
     "user": {
      "displayName": "Trường Trương Quốc",
      "userId": "17805586224290040159"
     },
     "user_tz": -420
    }
   },
   "outputs": [],
   "source": [
    "configs = {\n",
    "    \"file_name\": data_path,\n",
    "    \"batch_size\":8,\n",
    "    \"embedding_dim\": 64,\n",
    "    \"dff\": 128,\n",
    "    \"n_layers\": 2,\n",
    "    \"n_heads\": 2,\n",
    "    \"dropout\": 0.1,\n",
    "    \"n_epochs\": 12\n",
    "}\n",
    "\n",
    "def process_input(lines):\n",
    "    lines = lines.drop(['c'] , axis=1 )\n",
    "\n",
    "    eng_train_lines,vie_train_lines,eng_val_lines,vie_val_lines,eng_full_lines,vie_full_lines = [],[],[],[],[],[]\n",
    "\n",
    "    for line_eng, line_vie in zip(lines.eng, lines.vie):\n",
    "        eng_full_lines.append( line_eng )\n",
    "        vie_full_lines.append( '<START> ' + line_vie + ' <END>' )\n",
    "        if random.random()<0.9:\n",
    "            eng_train_lines.append( line_eng )\n",
    "            vie_train_lines.append( '<START> ' + line_vie + ' <END>' )\n",
    "        else:\n",
    "            eng_val_lines.append( line_eng )\n",
    "            vie_val_lines.append( '<START> ' + line_vie + ' <END>' )\n",
    "    eng_tokenizer = preprocessing.text.Tokenizer()\n",
    "    eng_tokenizer.fit_on_texts( eng_full_lines )\n",
    "    tokenized_full_eng_lines = eng_tokenizer.texts_to_sequences( eng_full_lines )\n",
    "    tokenized_train_eng_lines = eng_tokenizer.texts_to_sequences( eng_train_lines )\n",
    "    tokenized_val_eng_lines = eng_tokenizer.texts_to_sequences( eng_val_lines )\n",
    "    max_input_length = np.array( [len( token_seq ) for token_seq in tokenized_full_eng_lines] ).max()\n",
    "\n",
    "\n",
    "    vie_tokenizer = preprocessing.text.Tokenizer()\n",
    "    vie_tokenizer.fit_on_texts( vie_full_lines )\n",
    "    tokenized_full_vie_lines = vie_tokenizer.texts_to_sequences( vie_full_lines )\n",
    "    tokenized_train_vie_lines = vie_tokenizer.texts_to_sequences( vie_train_lines )\n",
    "    tokenized_val_vie_lines = vie_tokenizer.texts_to_sequences( vie_val_lines )\n",
    "    max_output_length = np.array( [len( token_seq ) for token_seq in tokenized_full_vie_lines] ).max()\n",
    "\n",
    "    padded_train_eng_lines = preprocessing.sequence.pad_sequences( tokenized_train_eng_lines, maxlen=max(max_input_length, max_output_length), padding='post' )\n",
    "    encoder_train_input_data = np.array( padded_train_eng_lines )\n",
    "    padded_val_eng_lines = preprocessing.sequence.pad_sequences( tokenized_val_eng_lines, maxlen=max(max_input_length, max_output_length) , padding='post' )\n",
    "    encoder_val_input_data = np.array( padded_val_eng_lines )\n",
    "\n",
    "    padded_train_vie_lines = preprocessing.sequence.pad_sequences( tokenized_train_vie_lines, maxlen=max(max_input_length, max_output_length) , padding='post' )\n",
    "    decoder_train_input_data = np.array( padded_train_vie_lines )\n",
    "    padded_val_vie_lines = preprocessing.sequence.pad_sequences( tokenized_val_vie_lines, maxlen=max(max_input_length, max_output_length) , padding='post' )\n",
    "    decoder_val_input_data = np.array( padded_val_vie_lines )\n",
    "\n",
    "    eng_word_dict = eng_tokenizer.word_index\n",
    "    num_eng_tokens = len( eng_word_dict )+1\n",
    "    vie_word_dict = vie_tokenizer.word_index\n",
    "    num_vie_tokens = len( vie_word_dict )+1\n",
    "\n",
    "    print( 'Độ dài lớn nhất của English là {}'.format( max_input_length ))\n",
    "    print( 'Kích thước dữ liệu của Encoder  -> {}'.format( encoder_train_input_data.shape ))\n",
    "    print( 'Số lượng English tokens = {}'.format( num_eng_tokens))\n",
    "\n",
    "    print( 'Độ dài lớn nhất của tiếng việt là {}'.format( max_output_length ))\n",
    "    print( 'kích thước dữ liệu đầu vào của Decoder -> {}'.format( decoder_train_input_data.shape ))\n",
    "    print( 'Số lượng Vietnamese tokens = {}'.format( num_vie_tokens))\n",
    "\n",
    "    input_decoder_target_data = []\n",
    "    for token_seq in tokenized_train_vie_lines:\n",
    "        input_decoder_target_data.append( token_seq[ 1 : ])\n",
    "\n",
    "    padded_vie_lines = preprocessing.sequence.pad_sequences(input_decoder_target_data , maxlen=max_output_length, padding='post' )\n",
    "    onehot_vie_lines = utils.to_categorical( padded_vie_lines , num_vie_tokens )\n",
    "    decoder_target_data = np.array( onehot_vie_lines )\n",
    "    return  {\n",
    "                \"encoder_train_input_data\":encoder_train_input_data,\n",
    "                \"encoder_val_input_data\":encoder_val_input_data,\n",
    "                \"decoder_train_input_data\":decoder_train_input_data,\n",
    "                \"decoder_target_data\":decoder_target_data,\n",
    "                \"eng_tokenizer\":eng_tokenizer,\n",
    "                \"vie_tokenizer\":vie_tokenizer,\n",
    "                \"num_eng_tokens\":num_eng_tokens,\n",
    "                \"num_vie_tokens\":num_vie_tokens,\n",
    "                \"max_input_length\":max_input_length,\n",
    "                \"max_output_length\":max_output_length,\n",
    "                \"tokenized_val_vie_lines\":tokenized_val_vie_lines,\n",
    "                \"eng_val_lines\":eng_val_lines,\n",
    "                \"encoder_val_input_data\":encoder_val_input_data\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3128f8d8-ddfe-4943-bd05-548761431724",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9138,
     "status": "ok",
     "timestamp": 1727769276486,
     "user": {
      "displayName": "Trường Trương Quốc",
      "userId": "17805586224290040159"
     },
     "user_tz": -420
    },
    "outputId": "6c3d94cf-dcd7-462e-ce84-615e79cef68d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Độ dài lớn nhất của English là 32\n",
      "Kích thước dữ liệu của Encoder  -> (8515, 43)\n",
      "Số lượng English tokens = 4115\n",
      "Độ dài lớn nhất của tiếng việt là 43\n",
      "kích thước dữ liệu đầu vào của Decoder -> (8515, 43)\n",
      "Số lượng Vietnamese tokens = 2486\n"
     ]
    }
   ],
   "source": [
    "lines = pd.read_table(configs['file_name'] , names=['eng' , 'vie' , 'c' ] )\n",
    "\n",
    "data_input = process_input(lines)\n",
    "\n",
    "\n",
    "num_layers = configs[\"n_layers\"]\n",
    "d_model = configs[\"embedding_dim\"]\n",
    "dff = configs[\"dff\"]\n",
    "num_heads = configs[\"n_heads\"]\n",
    "dropout_rate = configs[\"dropout\"]\n",
    "\n",
    "def masked_loss(label, pred):\n",
    "    mask = tf.argmax(label, axis=-1) != 0\n",
    "    loss_object = tf.keras.losses.CategoricalCrossentropy(\n",
    "        from_logits=False, reduction='none')\n",
    "    loss = loss_object(label, pred)\n",
    "    mask = tf.cast(mask, dtype=loss.dtype)\n",
    "    loss *= mask\n",
    "\n",
    "    loss = tf.reduce_sum(loss)/tf.reduce_sum(mask)\n",
    "    return loss\n",
    "\n",
    "def masked_accuracy(label, pred):\n",
    "    pred = tf.argmax(pred, axis=2)\n",
    "    label = tf.argmax(label, axis=2)\n",
    "    label = tf.cast(label, pred.dtype)\n",
    "    match = label == pred\n",
    "\n",
    "    mask = label != 0\n",
    "\n",
    "    match = match & mask\n",
    "\n",
    "    match = tf.cast(match, dtype=tf.float32)\n",
    "    mask = tf.cast(mask, dtype=tf.float32)\n",
    "    return tf.reduce_sum(match)/tf.reduce_sum(mask)\n",
    "\n",
    "def fix_random_seed(seed_value = 42):\n",
    "    np.random.seed(seed_value)\n",
    "    random.seed(seed_value)\n",
    "    tf.random.set_seed(seed_value)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed_value)\n",
    "\n",
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "    def __init__(self, d_model, warmup_steps=4000):\n",
    "        super().__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.d_model = tf.cast(self.d_model, tf.float32)\n",
    "\n",
    "        self.warmup_steps = warmup_steps\n",
    "\n",
    "    def __call__(self, step):\n",
    "        step = tf.cast(step, dtype=tf.float32)\n",
    "        arg1 = tf.math.rsqrt(step)\n",
    "        arg2 = step * (self.warmup_steps ** -1.5)\n",
    "\n",
    "        return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)\n",
    "    def get_config(self):\n",
    "        config = {\n",
    "        'd_model': self.d_model,\n",
    "        'warmup_steps': self.warmup_steps,\n",
    "\n",
    "        }\n",
    "        return config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca4c8d13-feed-4865-af68-3b7c5dce3a15",
   "metadata": {},
   "source": [
    "## Hàm thành phần của Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "807a19bf-af5f-47cb-9af0-8fcfd840df97",
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1727769278956,
     "user": {
      "displayName": "Trường Trương Quốc",
      "userId": "17805586224290040159"
     },
     "user_tz": -420
    }
   },
   "outputs": [],
   "source": [
    "def positional_encoding(length, depth):\n",
    "    depth = depth/2\n",
    "\n",
    "    positions = np.arange(length)[:, np.newaxis]     # (seq, 1)\n",
    "    depths = np.arange(depth)[np.newaxis, :]/depth   # (1, depth)\n",
    "    angle = 1 / (10000**depths)         # (1, depth)\n",
    "    angle = positions * angle      # (pos, depth)\n",
    "\n",
    "\n",
    "    pos_encoding = np.concatenate(\n",
    "        [np.sin(angle), np.cos(angle)],\n",
    "        axis=-1)\n",
    "\n",
    "    return tf.cast(pos_encoding, dtype=tf.float32)\n",
    "\n",
    "class PositionalEmbedding(tf.keras.layers.Layer):\n",
    "    def __init__(self, vocab_size, d_model):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, d_model, mask_zero=True)\n",
    "        self.pos_encoding = positional_encoding(length=2048, depth=d_model)\n",
    "\n",
    "    def compute_mask(self, *args, **kwargs):\n",
    "        return self.embedding.compute_mask(*args, **kwargs)\n",
    "\n",
    "    def call(self, x):\n",
    "        length = tf.shape(x)[1]\n",
    "        x = self.embedding(x)\n",
    "        # This factor sets the relative scale of the embedding and positonal_encoding.\n",
    "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "        x = x + self.pos_encoding[tf.newaxis, :length, :]\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "406d316e-ebce-4ea8-977f-6f0fdb0a81a2",
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1727769280101,
     "user": {
      "displayName": "Trường Trương Quốc",
      "userId": "17805586224290040159"
     },
     "user_tz": -420
    }
   },
   "outputs": [],
   "source": [
    "class EncoderLayer(tf.keras.layers.Layer):\n",
    "  def __init__(self,*, d_model, num_heads, dff, dropout_rate=0.1):\n",
    "    super().__init__()\n",
    "\n",
    "    self.self_attention = GlobalSelfAttention(\n",
    "        num_heads=num_heads,\n",
    "        key_dim=d_model,\n",
    "        dropout=dropout_rate)\n",
    "\n",
    "    self.ffn = FeedForward(d_model, dff)\n",
    "\n",
    "  def call(self, x):\n",
    "    x = self.self_attention(x)\n",
    "    x = self.ffn(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "class Encoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, *, num_layers, d_model, num_heads,\n",
    "                dff, vocab_size, dropout_rate=0.1):\n",
    "        super().__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.pos_embedding = PositionalEmbedding(\n",
    "            vocab_size=vocab_size, d_model=d_model)\n",
    "\n",
    "        self.enc_layers = [\n",
    "            EncoderLayer(d_model=d_model,\n",
    "                        num_heads=num_heads,\n",
    "                        dff=dff,\n",
    "                        dropout_rate=dropout_rate)\n",
    "            for _ in range(num_layers)]\n",
    "        self.dropout = tf.keras.layers.Dropout(dropout_rate)\n",
    "\n",
    "    def call(self, x):\n",
    "        # `x` is token-IDs shape: (batch, seq_len)\n",
    "        x = self.pos_embedding(x)  # Shape `(batch_size, seq_len, d_model)`.\n",
    "\n",
    "        # Add dropout.\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        for i in range(self.num_layers):\n",
    "            x = self.enc_layers[i](x)\n",
    "\n",
    "        return x  # Shape `(batch_size, seq_len, d_model)`.\n",
    "\n",
    "class DecoderLayer(tf.keras.layers.Layer):\n",
    "  def __init__(self,\n",
    "               *,\n",
    "               d_model,\n",
    "               num_heads,\n",
    "               dff,\n",
    "               dropout_rate=0.1):\n",
    "    super(DecoderLayer, self).__init__()\n",
    "\n",
    "    self.causal_self_attention = CausalSelfAttention(\n",
    "        num_heads=num_heads,\n",
    "        key_dim=d_model,\n",
    "        dropout=dropout_rate)\n",
    "\n",
    "    self.cross_attention = CrossAttention(\n",
    "        num_heads=num_heads,\n",
    "        key_dim=d_model,\n",
    "        dropout=dropout_rate)\n",
    "\n",
    "    self.ffn = FeedForward(d_model, dff)\n",
    "\n",
    "  def call(self, x, context):\n",
    "    x = self.causal_self_attention(x=x)\n",
    "    x = self.cross_attention(x=x, context=context)\n",
    "\n",
    "    # Cache the last attention scores for plotting later\n",
    "    self.last_attn_scores = self.cross_attention.last_attn_scores\n",
    "\n",
    "    x = self.ffn(x)  # Shape `(batch_size, seq_len, d_model)`.\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "class Decoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, *, num_layers, d_model, num_heads, dff, vocab_size,\n",
    "                dropout_rate=0.1):\n",
    "        super(Decoder, self).__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.pos_embedding = PositionalEmbedding(vocab_size=vocab_size,\n",
    "                                                d_model=d_model)\n",
    "        self.dropout = tf.keras.layers.Dropout(dropout_rate)\n",
    "        self.dec_layers = [\n",
    "            DecoderLayer(d_model=d_model, num_heads=num_heads,\n",
    "                        dff=dff, dropout_rate=dropout_rate)\n",
    "            for _ in range(num_layers)]\n",
    "\n",
    "        self.last_attn_scores = None\n",
    "\n",
    "    def call(self, x, context):\n",
    "        # `x` is token-IDs shape (batch, target_seq_len)\n",
    "        x = self.pos_embedding(x)  # (batch_size, target_seq_len, d_model)\n",
    "\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        for i in range(self.num_layers):\n",
    "            x  = self.dec_layers[i](x, context)\n",
    "\n",
    "        self.last_attn_scores = self.dec_layers[-1].last_attn_scores\n",
    "\n",
    "        # The shape of x is (batch_size, target_seq_len, d_model).\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cc5cadfc-b078-4bf2-b8ce-ad106b28b224",
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1727769280101,
     "user": {
      "displayName": "Trường Trương Quốc",
      "userId": "17805586224290040159"
     },
     "user_tz": -420
    }
   },
   "outputs": [],
   "source": [
    "class Translator:\n",
    "    def __init__(self, num_layers, d_model, num_heads, dff,\n",
    "               input_vocab_size, target_vocab_size, dropout_rate=0.0):\n",
    "        self.encoder = Encoder(num_layers=num_layers, d_model=d_model,\n",
    "                           num_heads=num_heads, dff=dff,\n",
    "                           vocab_size=input_vocab_size,\n",
    "                           dropout_rate=dropout_rate)\n",
    "\n",
    "        self.decoder = Decoder(num_layers=num_layers, d_model=d_model,\n",
    "                           num_heads=num_heads, dff=dff,\n",
    "                           vocab_size=target_vocab_size,\n",
    "                           dropout_rate=dropout_rate)\n",
    "        self.final_layer = tf.keras.layers.Dense(target_vocab_size, activation=tf.keras.activations.softmax)\n",
    "        self.d_model = d_model\n",
    "\n",
    "    def build(self):\n",
    "        encoder_inputs = tf.keras.layers.Input(shape=( None ,))\n",
    "        decoder_inputs = tf.keras.layers.Input(shape=( None ,))\n",
    "\n",
    "        context = self.encoder(encoder_inputs)  # (batch_size, context_len, d_model)\n",
    "\n",
    "        output = self.decoder(decoder_inputs, context)  # (batch_size, target_len, d_model)\n",
    "\n",
    "        # Final linear layer output.\n",
    "        output = self.final_layer(output)  # (batch_size, target_len, target_vocab_size)\n",
    "\n",
    "        try:\n",
    "            # Delete the keras mask, so keras doesn't scale the loss+accuracy.\n",
    "            del output._keras_mask\n",
    "        except AttributeError:\n",
    "            pass\n",
    "\n",
    "        self.model = tf.keras.models.Model([encoder_inputs, decoder_inputs], output )\n",
    "    def train(self, encoder_input_data , decoder_input_data, decoder_target_data,cfg):\n",
    "        learning_rate = CustomSchedule(self.d_model)\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98,\n",
    "                                        epsilon=1e-9)\n",
    "        self.model.compile(\n",
    "                loss=masked_loss,\n",
    "                optimizer=optimizer,\n",
    "                metrics=[masked_accuracy],\n",
    "                )\n",
    "        self.model.fit([encoder_input_data , decoder_input_data], decoder_target_data, batch_size=cfg[\"batch_size\"], epochs=cfg[\"n_epochs\"])\n",
    "\n",
    "    # Load mô hình từ file\n",
    "    def load_weights(self, model_file):\n",
    "        self.model.load_weights(model_file).expect_partial()\n",
    "\n",
    "    # Lưu mô hình hiện tại xuống file\n",
    "    def save_weights(self, model_file):\n",
    "        self.model.save_weights(model_file)\n",
    "\n",
    "    # Tóm tắt kiến trúc mạng\n",
    "    def summary(self):\n",
    "        self.model.summary()\n",
    "\n",
    "    # Thử nghiệm mô hình với dữ liệu ảnh đầu vào\n",
    "    def predict(self, x_test):\n",
    "        return self.model.predict(x_test)\n",
    "    def translate(self, input,max_output_length, vie_tokenizer, return_attention=False):\n",
    "        vie_word_dict=vie_tokenizer.word_index\n",
    "        map_i2w = {val: key for key, val in vie_word_dict.items()}\n",
    "        output_array = tf.TensorArray(dtype=tf.int64, size=0, dynamic_size=True)\n",
    "        start, end = vie_word_dict['start'], vie_word_dict['end']\n",
    "        output_array = output_array.write(0, [start])\n",
    "\n",
    "        for i in tf.range(max_output_length):\n",
    "            output = tf.transpose(output_array.stack())\n",
    "            predictions = self.model([input, output], training=False)\n",
    "\n",
    "            # Select the last token from the `seq_len` dimension.\n",
    "\n",
    "            predictions = predictions[:, -1:, :]  # Shape `(batch_size, 1, vocab_size)`.\n",
    "            predicted_id = tf.argmax(predictions, axis=-1)\n",
    "\n",
    "            # Concatenate the `predicted_id` to the output which is given to the\n",
    "            if predicted_id[0] == end or predicted_id[0]==0:\n",
    "                break\n",
    "\n",
    "            output_array = output_array.write(i+1, predicted_id[0])\n",
    "        output = tf.transpose(output_array.stack())\n",
    "        # print(output)\n",
    "        text = [map_i2w.get(i, '') for i in output[0].numpy()[1:]]  # Shape: `()`.\n",
    "        if return_attention:\n",
    "            self.model([input, output], training=False)\n",
    "            attention_weights = self.decoder.last_attn_scores\n",
    "            attention_heads = tf.squeeze(attention_weights, 0)\n",
    "            return text, attention_heads\n",
    "        return text\n",
    "    def plot_attention(self, text, **kwargs):\n",
    "        assert isinstance(text, str)\n",
    "\n",
    "        input = eng_tokenizer.texts_to_sequences([text])\n",
    "        input = preprocessing.sequence.pad_sequences(input, maxlen=max_input_length , padding='post' )\n",
    "        output, attention = self.translate(input, return_attention=True)\n",
    "        attention_weights = tf.concat(attention, 0)\n",
    "        context = text.split()\n",
    "\n",
    "        for i in range(len(attention_weights)):\n",
    "            attention = attention_weights[i]\n",
    "            fig = plt.figure(figsize=(10, 10))\n",
    "            ax = fig.add_subplot(1, 1, 1)\n",
    "\n",
    "            ax.matshow(attention, cmap='viridis', vmin=0.0)\n",
    "\n",
    "            fontdict = {'fontsize': 14}\n",
    "\n",
    "            ax.set_xticklabels([''] + context, fontdict=fontdict, rotation=90)\n",
    "            ax.set_yticklabels([''] + output, fontdict=fontdict)\n",
    "\n",
    "            ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "            ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "            ax.set_ylabel('Output text')\n",
    "            ax.set_xlabel(f'Head {i}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc340b52-6d30-412a-8208-b5404e3e96ce",
   "metadata": {},
   "source": [
    "## Kiến trúc Transformer tiêu chuẩn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50426d41-baf9-4183-8b9a-2cdd712b82aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__()\n",
    "        self.mha = tf.keras.layers.MultiHeadAttention(**kwargs)\n",
    "        self.layernorm = tf.keras.layers.LayerNormalization()\n",
    "        self.add = tf.keras.layers.Add()\n",
    "\n",
    "class CrossAttention(BaseAttention):\n",
    "    def call(self, x, context):\n",
    "        attn_output, attn_scores = self.mha(\n",
    "            query=x,\n",
    "            key=context,\n",
    "            value=context,\n",
    "            return_attention_scores=True)\n",
    "        # Cache the attention scores for plotting later.\n",
    "        self.last_attn_scores = attn_scores\n",
    "        x = self.add([x, attn_output])\n",
    "        x = self.layernorm(x)\n",
    "        return x\n",
    "\n",
    "class GlobalSelfAttention(BaseAttention):\n",
    "    def call(self, x):\n",
    "        attn_output = self.mha(\n",
    "            query=x,\n",
    "            value=x,\n",
    "            key=x)\n",
    "        x = self.add([x, attn_output])\n",
    "        x = self.layernorm(x)\n",
    "        return x\n",
    "\n",
    "class CausalSelfAttention(BaseAttention):\n",
    "    def call(self, x):\n",
    "        attn_output = self.mha(\n",
    "            query=x,\n",
    "            value=x,\n",
    "            key=x,\n",
    "            use_causal_mask = True)\n",
    "        x = self.add([x, attn_output])\n",
    "        x = self.layernorm(x)\n",
    "        return x\n",
    "\n",
    "class FeedForward(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, dff, dropout_rate=0.1):\n",
    "        super().__init__()\n",
    "        self.seq = None\n",
    "        self.add = None\n",
    "        self.layer_norm = None\n",
    "        self.seq = tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(dff, activation='relu'),\n",
    "        tf.keras.layers.Dense(d_model),\n",
    "        tf.keras.layers.Dropout(dropout_rate)])\n",
    "        self.add = tf.keras.layers.Add()\n",
    "        self.layer_norm = tf.keras.layers.LayerNormalization()\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.add([x, self.seq(x)])\n",
    "        x = self.layer_norm(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60302d04-afbe-4ca6-a2d2-31442c80e400",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3518,
     "status": "ok",
     "timestamp": 1722217339658,
     "user": {
      "displayName": "Trường Trương Quốc",
      "userId": "03437842081266241486"
     },
     "user_tz": -420
    },
    "outputId": "5e4261bd-0065-4cf6-dc7c-6cf50da08143"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)        [(None, None)]               0         []                            \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)        [(None, None)]               0         []                            \n",
      "                                                                                                  \n",
      " encoder (Encoder)           (None, None, 64)             363456    ['input_1[0][0]']             \n",
      "                                                                                                  \n",
      " decoder (Decoder)           (None, None, 64)             325888    ['input_2[0][0]',             \n",
      "                                                                     'encoder[0][0]']             \n",
      "                                                                                                  \n",
      " dense_8 (Dense)             (None, None, 2486)           161590    ['decoder[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 850934 (3.25 MB)\n",
      "Trainable params: 850934 (3.25 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "fix_random_seed(24)\n",
    "\n",
    "standard =Translator(\n",
    "    num_layers=num_layers,\n",
    "    d_model=d_model,\n",
    "    num_heads=num_heads,\n",
    "    dff=dff,\n",
    "    input_vocab_size=data_input[\"num_eng_tokens\"],\n",
    "    target_vocab_size=data_input[\"num_vie_tokens\"],\n",
    "    dropout_rate=dropout_rate)\n",
    "\n",
    "standard.build()\n",
    "standard.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffc5ddf7-1c53-48c3-b336-237b0d6bfa7c",
   "metadata": {},
   "source": [
    "## 5. Scaled Dot Product Attention --> Xoá phần Scale\n",
    "Trong phần này, chúng ta sẽ thử nghiệm phiên bản **Beta** của Transformer khi xoá phần **Scale** trong hàm Dot-Product của kiến trúc Attention.\n",
    "\n",
    "\n",
    "**TODO:** Cài đặt lại hàm **_compute_attention** của lớp MultiHeadAttention, và bỏ phần scale khi xử lý **query**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "34fe9e03-f039-4049-86dc-9f42b66b6221",
   "metadata": {
    "executionInfo": {
     "elapsed": 7912,
     "status": "ok",
     "timestamp": 1727769316620,
     "user": {
      "displayName": "Trường Trương Quốc",
      "userId": "17805586224290040159"
     },
     "user_tz": -420
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Embedding, MultiHeadAttention, Dense, Input, Dropout, LayerNormalization\n",
    "from transformers import DistilBertTokenizerFast\n",
    "from transformers import TFDistilBertForTokenClassification\n",
    "\n",
    "class custom_MultiHeadAttention(MultiHeadAttention):\n",
    "    def _compute_attention(self, query, key, value, attention_mask=None, training=None):\n",
    "\n",
    "        ### BEGIN SOLUTION\n",
    "        attention_scores = tf.einsum(self._dot_product_equation, key, query)\n",
    "        attention_scores = self._masked_softmax(\n",
    "            attention_scores, attention_mask\n",
    "        )\n",
    "        attention_scores_dropout = self._dropout_layer(\n",
    "            attention_scores, training=training\n",
    "        )\n",
    "        attention_output = tf.einsum(\n",
    "            self._combine_equation, attention_scores_dropout, value\n",
    "    )\n",
    "        ### END SOLUTION\n",
    "\n",
    "        return attention_output, attention_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "701e208a-544a-40be-a8f2-86168081445d",
   "metadata": {
    "executionInfo": {
     "elapsed": 438,
     "status": "ok",
     "timestamp": 1727769323913,
     "user": {
      "displayName": "Trường Trương Quốc",
      "userId": "17805586224290040159"
     },
     "user_tz": -420
    }
   },
   "outputs": [],
   "source": [
    "class BaseAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__()\n",
    "\n",
    "        self.mha  = None\n",
    "        self.layernorm = None\n",
    "        self.add = None\n",
    "\n",
    "        ### BEGIN SOLUTION\n",
    "        self.mha = tf.keras.layers.MultiHeadAttention(**kwargs)\n",
    "\n",
    "\n",
    "        ### END SOLUTION\n",
    "\n",
    "        self.layernorm = tf.keras.layers.LayerNormalization()\n",
    "        self.add = tf.keras.layers.Add()\n",
    "\n",
    "class CrossAttention(BaseAttention):\n",
    "    def call(self, x, context):\n",
    "        attn_output, attn_scores = self.mha(\n",
    "            query=x,\n",
    "            key=context,\n",
    "            value=context,\n",
    "            return_attention_scores=True)\n",
    "        # Cache the attention scores for plotting later.\n",
    "        self.last_attn_scores = attn_scores\n",
    "        x = self.add([x, attn_output])\n",
    "        x = self.layernorm(x)\n",
    "        return x\n",
    "\n",
    "class GlobalSelfAttention(BaseAttention):\n",
    "    def call(self, x):\n",
    "        attn_output = self.mha(\n",
    "            query=x,\n",
    "            value=x,\n",
    "            key=x)\n",
    "        x = self.add([x, attn_output])\n",
    "        x = self.layernorm(x)\n",
    "        return x\n",
    "\n",
    "class CausalSelfAttention(BaseAttention):\n",
    "    def call(self, x):\n",
    "        attn_output = self.mha(\n",
    "            query=x,\n",
    "            value=x,\n",
    "            key=x,\n",
    "            use_causal_mask = True)\n",
    "        x = self.add([x, attn_output])\n",
    "        x = self.layernorm(x)\n",
    "        return x\n",
    "\n",
    "class FeedForward(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, dff, dropout_rate=0.1):\n",
    "        super().__init__()\n",
    "        self.seq = None\n",
    "        self.add = None\n",
    "        self.layer_norm = None\n",
    "        self.seq = tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(dff, activation='relu'),\n",
    "        tf.keras.layers.Dense(d_model),\n",
    "        tf.keras.layers.Dropout(dropout_rate)])\n",
    "        self.add = tf.keras.layers.Add()\n",
    "        self.layer_norm = tf.keras.layers.LayerNormalization()\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.add([x, self.seq(x)])\n",
    "        x = self.layer_norm(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5b02d6ef-6e7a-48d8-b990-89480fddc67d",
   "metadata": {
    "executionInfo": {
     "elapsed": 428,
     "status": "ok",
     "timestamp": 1727770071417,
     "user": {
      "displayName": "Trường Trương Quốc",
      "userId": "17805586224290040159"
     },
     "user_tz": -420
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN PUBLIC TESTS\n",
    "fix_random_seed(42)\n",
    "batch_size = 1\n",
    "seq_len = 3\n",
    "d_model = 64\n",
    "num_heads= 2\n",
    "\n",
    "x = tf.random.uniform((1, 8, 64))\n",
    "context = tf.random.uniform((1, 8, 64))\n",
    "\n",
    "Test_FeedForward = FeedForward(d_model, dff, dropout_rate)\n",
    "Output_FeedForward = Test_FeedForward(x)\n",
    "\n",
    "attention_scores_sum = tf.reduce_sum(Output_FeedForward, axis=-1)\n",
    "assert tf.reduce_all(tf.not_equal(attention_scores_sum, 1.0)).numpy()\n",
    "\n",
    "### END PUBLIC TESTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04cdee53-c0b0-4fd1-b9d0-303434fe5fa4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2612,
     "status": "ok",
     "timestamp": 1722396671653,
     "user": {
      "displayName": "Trường Trương Quốc",
      "userId": "03437842081266241486"
     },
     "user_tz": -420
    },
    "outputId": "9e55b4cb-e946-4a14-e37e-4471dec0cd52"
   },
   "outputs": [],
   "source": [
    "fix_random_seed(24)\n",
    "\n",
    "beta=Translator(\n",
    "    num_layers=num_layers,\n",
    "    d_model=d_model,\n",
    "    num_heads=num_heads,\n",
    "    dff=dff,\n",
    "    input_vocab_size=data_input[\"num_eng_tokens\"],\n",
    "    target_vocab_size=data_input[\"num_vie_tokens\"],\n",
    "    dropout_rate=dropout_rate)\n",
    "\n",
    "beta.build()\n",
    "beta.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "328710c0-6b99-468c-9d83-295e655dc132",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 608,
     "status": "ok",
     "timestamp": 1727773827005,
     "user": {
      "displayName": "Trường Trương Quốc",
      "userId": "17805586224290040159"
     },
     "user_tz": -420
    },
    "outputId": "7254c404-1eff-4a16-ded1-18bb80b263dc"
   },
   "outputs": [],
   "source": [
    "options = {0: 'hiệu suất beta xấp xỉ mô hình gốc (không chêch lệch quá 1%)',\n",
    "           1: 'hiệu suất beta thấp hơn mô hình gốc k% (1<k<5)',\n",
    "           2: 'hiệu suất beta thấp hơn mô hình gốc k% (5<=k<10)',\n",
    "           3: 'hiệu suất beta thấp hơn mô hình gốc k% (10<=k<20)',\n",
    "           4: 'hiệu suất beta thấp hơn mô hình gốc trên 20%',\n",
    "           5: 'alpha gần như không học gì (hiệu suất thấp hơn 10%)'}\n",
    "your_choice = None\n",
    "### BEGIN SOLUTION\n",
    "your_choice = 1\n",
    "### END SOLUTION\n",
    "print(\"Theo mình thì: \", options[your_choice])"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
